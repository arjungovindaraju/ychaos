{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"YChaos \u00b6 YChaos is a self-serving chaos testing toolkit designed to provide you with all the capabilities of doing an end to end resilience testing of your service. YChaos is designed to give users a framework to validate, verify and attack your system to simulate real life failures that might cause outages in your service. The real life failures/attacks are termed as Agents in YChaos' terminology. Agents are the independent attack scenarios that perform one kind of attack on the system with a specified configuration. YChaos also provides a way to verify your system state before, during and after the completion of attack. This ensures that you as a user are in control when to perform attack and also provides you a detailed report as to what went wrong with your service during the attack so that you can apply corrective measures to ensure that your service is resilient. What is true about YChaos? \u00b6 YChaos is a resilience testing tool. YChaos is a self serving tool. You as a user of YChaos control the entire infrastructure of attacking your systems. Hence, you need not worry about a third party system controlling your systems. YChaos can be integrated with popular CI/CD platforms such as Screwdriver Some fact checks about YChaos! \u00b6 YChaos is not a Load testing tool. YChaos does not automatically address the issues in your service. YChaos provides you a way to identify issues in your service YChaos does not need any daemon running on your services. Project architecture \u00b6 View this diagram if you are interested in knowing the YChaos Project architecture. Installation \u00b6 You can install the package using pip or directly from Github Artifactory pip install ychaos [ chaos ] The above command will install the latest version of the chaos sub-package from artifactory. To install another subpackage of ychaos , pip install ychaos [ <subpackage> ] The following subpackages are available for usage agents : pip install ychaos[agents] chaos : pip install ychaos[chaos] Source You can also install the package directly from source. To do this, git clone https://github.com/yahoo/ychaos cd ychaos python setup.py develop easy_install ychaos [ <subpackage> ] If you are interested in installing all the above subpackages together, you can run pip install ychaos [ all ] YChaos tool can be used with python3.6+ and must have pip3 pre-installed Docker hub \u00b6 Python version specific YChaos images are published with each release of YChaos, at present Python 3.7 - 3.9 based images are available on Docker hub . Docker docker pull ychaos/ychaos Above command will pull the latest Python 3.6 based YChaos image. For any other Python version specific images use docker pull ychaos/ychaos:py<version>-latest Refer Docker tags for all the available Image tags","title":"Home"},{"location":"#ychaos","text":"YChaos is a self-serving chaos testing toolkit designed to provide you with all the capabilities of doing an end to end resilience testing of your service. YChaos is designed to give users a framework to validate, verify and attack your system to simulate real life failures that might cause outages in your service. The real life failures/attacks are termed as Agents in YChaos' terminology. Agents are the independent attack scenarios that perform one kind of attack on the system with a specified configuration. YChaos also provides a way to verify your system state before, during and after the completion of attack. This ensures that you as a user are in control when to perform attack and also provides you a detailed report as to what went wrong with your service during the attack so that you can apply corrective measures to ensure that your service is resilient.","title":"YChaos"},{"location":"#what-is-true-about-ychaos","text":"YChaos is a resilience testing tool. YChaos is a self serving tool. You as a user of YChaos control the entire infrastructure of attacking your systems. Hence, you need not worry about a third party system controlling your systems. YChaos can be integrated with popular CI/CD platforms such as Screwdriver","title":"What is true about YChaos?"},{"location":"#some-fact-checks-about-ychaos","text":"YChaos is not a Load testing tool. YChaos does not automatically address the issues in your service. YChaos provides you a way to identify issues in your service YChaos does not need any daemon running on your services.","title":"Some fact checks about YChaos!"},{"location":"#project-architecture","text":"View this diagram if you are interested in knowing the YChaos Project architecture.","title":"Project architecture"},{"location":"#installation","text":"You can install the package using pip or directly from Github Artifactory pip install ychaos [ chaos ] The above command will install the latest version of the chaos sub-package from artifactory. To install another subpackage of ychaos , pip install ychaos [ <subpackage> ] The following subpackages are available for usage agents : pip install ychaos[agents] chaos : pip install ychaos[chaos] Source You can also install the package directly from source. To do this, git clone https://github.com/yahoo/ychaos cd ychaos python setup.py develop easy_install ychaos [ <subpackage> ] If you are interested in installing all the above subpackages together, you can run pip install ychaos [ all ] YChaos tool can be used with python3.6+ and must have pip3 pre-installed","title":"Installation"},{"location":"#docker-hub","text":"Python version specific YChaos images are published with each release of YChaos, at present Python 3.7 - 3.9 based images are available on Docker hub . Docker docker pull ychaos/ychaos Above command will pull the latest Python 3.6 based YChaos image. For any other Python version specific images use docker pull ychaos/ychaos:py<version>-latest Refer Docker tags for all the available Image tags","title":"Docker hub"},{"location":"code_of_conduct/","text":"Yahoo Open Source Code of Conduct \u00b6 Summary \u00b6 This Code of Conduct is our way to encourage good behavior and discourage bad behavior in our open source projects. We invite participation from many people to bring different perspectives to our projects. We will do our part to foster a welcoming and professional environment free of harassment. We expect participants to communicate professionally and thoughtfully during their involvement with this project. Participants may lose their good standing by engaging in misconduct. For example: insulting, threatening, or conveying unwelcome sexual content. We ask participants who observe conduct issues to report the incident directly to the project's Response Team at opensource-conduct@yahooinc.com . Yahoo will assign a respondent to address the issue. We may remove harassers from this project. This code does not replace the terms of service or acceptable use policies of the websites used to support this project. We acknowledge that participants may be subject to additional conduct terms based on their employment which may govern their online expressions. Details \u00b6 This Code of Conduct makes our expectations of participants in this community explicit. * We forbid harassment and abusive speech within this community. * We request participants to report misconduct to the project\u2019s Response Team. * We urge participants to refrain from using discussion forums to play out a fight. Expected Behaviors \u00b6 We expect participants in this community to conduct themselves professionally. Since our primary mode of communication is text on an online forum (e.g. issues, pull requests, comments, emails, or chats) devoid of vocal tone, gestures, or other context that is often vital to understanding, it is important that participants are attentive to their interaction style. Assume positive intent. We ask community members to assume positive intent on the part of other people\u2019s communications. We may disagree on details, but we expect all suggestions to be supportive of the community goals. Respect participants. We expect occasional disagreements. Open Source projects are learning experiences. Ask, explore, challenge, and then respectfully state if you agree or disagree. If your idea is rejected, be more persuasive not bitter. Welcoming to new members. New members bring new perspectives. Some ask questions that have been addressed before. Kindly point to existing discussions. Everyone is new to every project once. Be kind to beginners. Beginners use open source projects to get experience. They might not be talented coders yet, and projects should not accept poor quality code. But we were all beginners once, and we need to engage kindly. Consider your impact on others. Your work will be used by others, and you depend on the work of others. We expect community members to be considerate and establish a balance their self-interest with communal interest. Use words carefully. We may not understand intent when you say something ironic. Often, people will misinterpret sarcasm in online communications. We ask community members to communicate plainly. Leave with class. When you wish to resign from participating in this project for any reason, you are free to fork the code and create a competitive project. Open Source explicitly allows this. Your exit should not be dramatic or bitter. Unacceptable Behaviors \u00b6 Participants remain in good standing when they do not engage in misconduct or harassment (some examples follow). We do not list all forms of harassment, nor imply some forms of harassment are not worthy of action. Any participant who feels harassed or observes harassment, should report the incident to the Response Team. * Don't be a bigot. Calling out project members by their identity or background in a negative or insulting manner. This includes, but is not limited to, slurs or insinuations related to protected or suspect classes e.g. race, color, citizenship, national origin, political belief, religion, sexual orientation, gender identity and expression, age, size, culture, ethnicity, genetic features, language, profession, national minority status, mental or physical ability. * Don't insult. Insulting remarks about a person\u2019s lifestyle practices. * Don't dox. Revealing private information about other participants without explicit permission. * Don't intimidate. Threats of violence or intimidation of any project member. * Don't creep. Unwanted sexual attention or content unsuited for the subject of this project. * Don't inflame. We ask that victim of harassment not address their grievances in the public forum, as this often intensifies the problem. Report it, and let us address it off-line. * Don't disrupt. Sustained disruptions in a discussion. Reporting Issues \u00b6 If you experience or witness misconduct, or have any other concerns about the conduct of members of this project, please report it by contacting our Response Team at opensource-conduct@yahooinc.com who will handle your report with discretion. Your report should include: * Your preferred contact information. We cannot process anonymous reports. * Names (real or usernames) of those involved in the incident. * Your account of what occurred, and if the incident is ongoing. Please provide links to or transcripts of the publicly available records (e.g. a mailing list archive or a public IRC logger), so that we can review it. * Any additional information that may be helpful to achieve resolution. After filing a report, a representative will contact you directly to review the incident and ask additional questions. If a member of the Yahoo Response Team is named in an incident report, that member will be recused from handling your incident. If the complaint originates from a member of the Response Team, it will be addressed by a different member of the Response Team. We will consider reports to be confidential for the purpose of protecting victims of abuse. Scope \u00b6 Yahoo will assign a Response Team member with admin rights on the project and legal rights on the project copyright. The Response Team is empowered to restrict some privileges to the project as needed. Since this project is governed by an open source license, any participant may fork the code under the terms of the project license. The Response Team\u2019s goal is to preserve the project if possible, and will restrict or remove participation from those who disrupt the project. This code does not replace the terms of service or acceptable use policies that are provided by the websites used to support this community. Nor does this code apply to communications or actions that take place outside of the context of this community. Many participants in this project are also subject to codes of conduct based on their employment. This code is a social-contract that informs participants of our social expectations. It is not a terms of service or legal contract. License and Acknowledgment. \u00b6 This text is shared under the CC-BY-4.0 license . This code is based on a study conducted by the TODO Group of many codes used in the open source community. If you have feedback about this code, contact our Response Team at the address listed above.","title":"Code Of Conduct"},{"location":"code_of_conduct/#yahoo-open-source-code-of-conduct","text":"","title":"Yahoo Open Source Code of Conduct"},{"location":"code_of_conduct/#summary","text":"This Code of Conduct is our way to encourage good behavior and discourage bad behavior in our open source projects. We invite participation from many people to bring different perspectives to our projects. We will do our part to foster a welcoming and professional environment free of harassment. We expect participants to communicate professionally and thoughtfully during their involvement with this project. Participants may lose their good standing by engaging in misconduct. For example: insulting, threatening, or conveying unwelcome sexual content. We ask participants who observe conduct issues to report the incident directly to the project's Response Team at opensource-conduct@yahooinc.com . Yahoo will assign a respondent to address the issue. We may remove harassers from this project. This code does not replace the terms of service or acceptable use policies of the websites used to support this project. We acknowledge that participants may be subject to additional conduct terms based on their employment which may govern their online expressions.","title":"Summary"},{"location":"code_of_conduct/#details","text":"This Code of Conduct makes our expectations of participants in this community explicit. * We forbid harassment and abusive speech within this community. * We request participants to report misconduct to the project\u2019s Response Team. * We urge participants to refrain from using discussion forums to play out a fight.","title":"Details"},{"location":"code_of_conduct/#expected-behaviors","text":"We expect participants in this community to conduct themselves professionally. Since our primary mode of communication is text on an online forum (e.g. issues, pull requests, comments, emails, or chats) devoid of vocal tone, gestures, or other context that is often vital to understanding, it is important that participants are attentive to their interaction style. Assume positive intent. We ask community members to assume positive intent on the part of other people\u2019s communications. We may disagree on details, but we expect all suggestions to be supportive of the community goals. Respect participants. We expect occasional disagreements. Open Source projects are learning experiences. Ask, explore, challenge, and then respectfully state if you agree or disagree. If your idea is rejected, be more persuasive not bitter. Welcoming to new members. New members bring new perspectives. Some ask questions that have been addressed before. Kindly point to existing discussions. Everyone is new to every project once. Be kind to beginners. Beginners use open source projects to get experience. They might not be talented coders yet, and projects should not accept poor quality code. But we were all beginners once, and we need to engage kindly. Consider your impact on others. Your work will be used by others, and you depend on the work of others. We expect community members to be considerate and establish a balance their self-interest with communal interest. Use words carefully. We may not understand intent when you say something ironic. Often, people will misinterpret sarcasm in online communications. We ask community members to communicate plainly. Leave with class. When you wish to resign from participating in this project for any reason, you are free to fork the code and create a competitive project. Open Source explicitly allows this. Your exit should not be dramatic or bitter.","title":"Expected Behaviors"},{"location":"code_of_conduct/#unacceptable-behaviors","text":"Participants remain in good standing when they do not engage in misconduct or harassment (some examples follow). We do not list all forms of harassment, nor imply some forms of harassment are not worthy of action. Any participant who feels harassed or observes harassment, should report the incident to the Response Team. * Don't be a bigot. Calling out project members by their identity or background in a negative or insulting manner. This includes, but is not limited to, slurs or insinuations related to protected or suspect classes e.g. race, color, citizenship, national origin, political belief, religion, sexual orientation, gender identity and expression, age, size, culture, ethnicity, genetic features, language, profession, national minority status, mental or physical ability. * Don't insult. Insulting remarks about a person\u2019s lifestyle practices. * Don't dox. Revealing private information about other participants without explicit permission. * Don't intimidate. Threats of violence or intimidation of any project member. * Don't creep. Unwanted sexual attention or content unsuited for the subject of this project. * Don't inflame. We ask that victim of harassment not address their grievances in the public forum, as this often intensifies the problem. Report it, and let us address it off-line. * Don't disrupt. Sustained disruptions in a discussion.","title":"Unacceptable Behaviors"},{"location":"code_of_conduct/#reporting-issues","text":"If you experience or witness misconduct, or have any other concerns about the conduct of members of this project, please report it by contacting our Response Team at opensource-conduct@yahooinc.com who will handle your report with discretion. Your report should include: * Your preferred contact information. We cannot process anonymous reports. * Names (real or usernames) of those involved in the incident. * Your account of what occurred, and if the incident is ongoing. Please provide links to or transcripts of the publicly available records (e.g. a mailing list archive or a public IRC logger), so that we can review it. * Any additional information that may be helpful to achieve resolution. After filing a report, a representative will contact you directly to review the incident and ask additional questions. If a member of the Yahoo Response Team is named in an incident report, that member will be recused from handling your incident. If the complaint originates from a member of the Response Team, it will be addressed by a different member of the Response Team. We will consider reports to be confidential for the purpose of protecting victims of abuse.","title":"Reporting Issues"},{"location":"code_of_conduct/#scope","text":"Yahoo will assign a Response Team member with admin rights on the project and legal rights on the project copyright. The Response Team is empowered to restrict some privileges to the project as needed. Since this project is governed by an open source license, any participant may fork the code under the terms of the project license. The Response Team\u2019s goal is to preserve the project if possible, and will restrict or remove participation from those who disrupt the project. This code does not replace the terms of service or acceptable use policies that are provided by the websites used to support this community. Nor does this code apply to communications or actions that take place outside of the context of this community. Many participants in this project are also subject to codes of conduct based on their employment. This code is a social-contract that informs participants of our social expectations. It is not a terms of service or legal contract.","title":"Scope"},{"location":"code_of_conduct/#license-and-acknowledgment","text":"This text is shared under the CC-BY-4.0 license . This code is based on a study conducted by the TODO Group of many codes used in the open source community. If you have feedback about this code, contact our Response Team at the address listed above.","title":"License and Acknowledgment."},{"location":"contribution/","text":"Contribution \u00b6 How to setup this repository on Local Machine? \u00b6 Clone the repository on your local machine git clone https://github.com/yahoo/ychaos Set up the project on an IDE (Preferably PyCharm). Note It is recommended to install pydantic plugin for Pycharm After creating a virtual environment for the project , install the editable version of the package pip install -e . [ debug ] Note If you are using zsh, you will have to run pip install -e \".[debug]\" Add your code changes in the required files and commit the changes to a branch. Include documentation to the code added using the Google docstrings format. Commit the file and include a meaningful name to the commit. If the changes to the code are more than huge, it is advised to split the commits into multiple. How to run Screwdriver validations locally? \u00b6 Note If you have installed the development package with debug extension, then all of these packages required for screwdriver validations will already be installed in your virtual environment. To run all the code analysis steps locally run make build . To run unittests locally, run make test . Coding standards \u00b6 This section of the document contains some of the coding standards followed in this package. It is recommended to read this and follow this for any contribution. This section of the document provides some of the preferred ways of writing code. Although, most of the subsections are provided with reasoning, this is not an official coding standard and can vary in special conditions. Hint Note that this is a constantly updating section of the document and will receive more items based on our experience. Imports \u00b6 Importing class \u00b6 If you are importing a class from a module, then import only the class from the module instead of importing the entire module. For example: Preferred from pathlib import Path mock_path = Path ( \"/home/awesomeuser/mockdirectory\" ) Avoid import pathlib mock_path = pathlib . Path ( \"/home/awesomeuser/mockdirectory\" ) Importing attributes/methods from module \u00b6 In case you want to import a method or an attribute from the module, whose name starts with a small alphabet, then import the module instead of method or attribute. Reasoning : If the module under change already has a variable named same as method/attribute, this will make you do an extra work of renaming all of those variables. For example: Preferred import os print ( os . cpu_count ()) Avoid from os import cpu_count print ( cpu_count ()) @staticmethod vs @classmethod \u00b6 We generally use class method to create factory methods. Factory methods return classobject (similar to a constructor) for different use cases. We generally use static methods to create utility functions. One Line if statements \u00b6 Use one line if statements if there is an else block defined and has some piece of code. If the else block just contains None , use a simple if statement Preferred if True : sum ([ 1 , 4 , - 3 , 19 ]) Avoid sum ([ 12 , 4 , - 3 , 10 ]) if True else None Path operations \u00b6 Use pathlib for path operation instead of os.path as this has better methods of operating on path. It also has utility methods to resolve expand user etc.","title":"Contribution"},{"location":"contribution/#contribution","text":"","title":"Contribution"},{"location":"contribution/#how-to-setup-this-repository-on-local-machine","text":"Clone the repository on your local machine git clone https://github.com/yahoo/ychaos Set up the project on an IDE (Preferably PyCharm). Note It is recommended to install pydantic plugin for Pycharm After creating a virtual environment for the project , install the editable version of the package pip install -e . [ debug ] Note If you are using zsh, you will have to run pip install -e \".[debug]\" Add your code changes in the required files and commit the changes to a branch. Include documentation to the code added using the Google docstrings format. Commit the file and include a meaningful name to the commit. If the changes to the code are more than huge, it is advised to split the commits into multiple.","title":"How to setup this repository on Local Machine?"},{"location":"contribution/#how-to-run-screwdriver-validations-locally","text":"Note If you have installed the development package with debug extension, then all of these packages required for screwdriver validations will already be installed in your virtual environment. To run all the code analysis steps locally run make build . To run unittests locally, run make test .","title":"How to run Screwdriver validations locally?"},{"location":"contribution/#coding-standards","text":"This section of the document contains some of the coding standards followed in this package. It is recommended to read this and follow this for any contribution. This section of the document provides some of the preferred ways of writing code. Although, most of the subsections are provided with reasoning, this is not an official coding standard and can vary in special conditions. Hint Note that this is a constantly updating section of the document and will receive more items based on our experience.","title":"Coding standards"},{"location":"contribution/#imports","text":"","title":"Imports"},{"location":"contribution/#staticmethod-vs-classmethod","text":"We generally use class method to create factory methods. Factory methods return classobject (similar to a constructor) for different use cases. We generally use static methods to create utility functions.","title":"@staticmethod vs @classmethod"},{"location":"contribution/#one-line-if-statements","text":"Use one line if statements if there is an else block defined and has some piece of code. If the else block just contains None , use a simple if statement Preferred if True : sum ([ 1 , 4 , - 3 , 19 ]) Avoid sum ([ 12 , 4 , - 3 , 10 ]) if True else None","title":"One Line if statements"},{"location":"contribution/#path-operations","text":"Use pathlib for path operation instead of os.path as this has better methods of operating on path. It also has utility methods to resolve expand user etc.","title":"Path operations"},{"location":"dependencies/","text":"Package Dependencies \u00b6 Installation Dependencies \u00b6 To install the latest version of the package, run pip install ychaos The above command will install the package and also all the required dependencies of the project. Project Dependencies Project Link License Type License URL pydantic LINK MIT LINK rich LINK MIT LINK pyyaml LINK MIT LINK psutil * LINK BSD-3-Clause LINK pyOpenSSL * LINK Apache 2.0 LINK ^* Optional dependencies Test and Code Analysis dependencies (for developers only) \u00b6 The following section contains the dependencies required for the development of the project. All these dependencies are bundled in a separate configuration called \"debug\" To install all the dependencies at once you can run pip install -e \".[debug]\" Or you can also make use of the bash script available in the develop directory, ./develop/make.sh Unittest \u00b6 Project Dependencies Project Link License Type License URL mockito LINK MIT LINK pytest LINK MIT LINK pytest-cov LINK MIT LINK pytest-timeout LINK MIT LINK cryptography LINK Apache/BSD LINK Code styling and validation \u00b6 Project Dependencies Project Link License Type License URL black LINK MIT LINK flake8 LINK MIT LINK isort LINK MIT LINK Code Analysis \u00b6 Project Dependencies Project Link License Type License URL mypy LINK MIT LINK bandit LINK Apache 2.0 LINK Documentation build/publish dependencies \u00b6 Project Dependencies Project Link License Type License URL mkdocs LINK BSD-2-Clause LINK mkdocs-material LINK MIT LINK mkdocs-awesome-pages-plugin LINK MIT LINK mike LINK BSD-3-Clause LINK","title":"Project Dependencies"},{"location":"dependencies/#package-dependencies","text":"","title":"Package Dependencies"},{"location":"dependencies/#installation-dependencies","text":"To install the latest version of the package, run pip install ychaos The above command will install the package and also all the required dependencies of the project. Project Dependencies Project Link License Type License URL pydantic LINK MIT LINK rich LINK MIT LINK pyyaml LINK MIT LINK psutil * LINK BSD-3-Clause LINK pyOpenSSL * LINK Apache 2.0 LINK ^* Optional dependencies","title":"Installation Dependencies"},{"location":"dependencies/#test-and-code-analysis-dependencies-for-developers-only","text":"The following section contains the dependencies required for the development of the project. All these dependencies are bundled in a separate configuration called \"debug\" To install all the dependencies at once you can run pip install -e \".[debug]\" Or you can also make use of the bash script available in the develop directory, ./develop/make.sh","title":"Test and Code Analysis dependencies (for developers only)"},{"location":"dependencies/#unittest","text":"Project Dependencies Project Link License Type License URL mockito LINK MIT LINK pytest LINK MIT LINK pytest-cov LINK MIT LINK pytest-timeout LINK MIT LINK cryptography LINK Apache/BSD LINK","title":"Unittest"},{"location":"dependencies/#code-styling-and-validation","text":"Project Dependencies Project Link License Type License URL black LINK MIT LINK flake8 LINK MIT LINK isort LINK MIT LINK","title":"Code styling and validation"},{"location":"dependencies/#code-analysis","text":"Project Dependencies Project Link License Type License URL mypy LINK MIT LINK bandit LINK Apache 2.0 LINK","title":"Code Analysis"},{"location":"dependencies/#documentation-buildpublish-dependencies","text":"Project Dependencies Project Link License Type License URL mkdocs LINK BSD-2-Clause LINK mkdocs-material LINK MIT LINK mkdocs-awesome-pages-plugin LINK MIT LINK mike LINK BSD-3-Clause LINK","title":"Documentation build/publish dependencies"},{"location":"faq/","text":"FAQ (Frequently Asked questions) \u00b6 I have no idea why I am here! \u00b6 Great! You can start with YChaos here . I am a YChaos user \u00b6 What version of YChaos should I install? \u00b6 It is always recommended to install the latest version(PATCH) of YChaos for the chaos testing. Although we test the package thoroughly for each PATCH update, there might be unknown regressions/bugs introduced in the new PATCH versions. To avoid this, you can install the latest MINOR version. Does YChaos run with Python3.6 \u00b6 As of YChaos version 0.5.x, (Released in January 2022), Python 3.6 support is removed for YChaos. The framework might still be fully functional on Python 3.6, we do not guarantee its functionality in Python3.6 in the future releases. Note YChaos is currently tested & released for Python3.7 to Python3.10 I am running YChaos and ... \u00b6 The console is not able to emit control codes and ended up printing gibberish \u00b6 It seems the console you are running the CLI is not interactive. To disable interactive mode, in YChaos CLI output, set the TERM environment variable to \"dumb\"/\"unknown\". This will disable features that require movement of cursor. Example: TERM = unknown ychaos validate testplan_folder/ You can also disable the colors emitted by the YChaos CLI by either setting NO_COLOR environment variable or calling YChaos CLI with --no-color . Example: The two commands mentioned below are equivalent. NO_COLOR = true ychaos validate testplan_folder/ ychaos --no-color validate testplan_folder/ I am a YChaos Contributor \u00b6 I do not like the way something is coded in this package. How do I bring the attention of this to the maintainers? \u00b6 It's not wrong to design things better than they are right now. Create a Github issue explaining what you do not like and how you would change it. If the change is approved, you can always contribute to the repository. We would likely not make this change to the repo. This is the same for suggesting adding a new feature to YChaos. Discuss and contribute. In the case of new features, we might actually contribute if it's worthwhile. How do I add a new optional 3 rd party package to the tool. \u00b6 Discuss the usecase you are trying to solve by creating a Github issue with us. Once approved to add new package to the repository, add the package at the right place in setup.cfg . install_requires are the list of PyPi packages that are installed by default. options.extras_require are the optional dependencies that contains subpackages and also dev packages. How do I run a single Unittest from command line? \u00b6 We recommend you to use an IDE for development (preferably PyCharm), which will provide you the feature of running a single unittest suite or a single test out of the box. If you still like to run it via the command line, you can use the below command. pytest <TEST_SUITE> -k \"<TEST_NAME>\" For example, pytest tests/test_settings.py -k \"test_settings_with_no_config_creates_ProdSettings_configuration\" I am a YChaos Maintainer \u00b6 When do I need to release new minor versions? \u00b6 New subcommand is added to YChaos CLI * Backward incompatible testplan New Verification Plugin * New YChaos Agent * Backward incompatible CLI changes (Arguments etc.) For the items marked with *, the PR with the changes can go in first and a new patch release can be released. After that, the package can be bumped to new minor version. For the items without *, the changes and the new version should go in as a same release. A patch version with this update should not be released. How do I release a backward incompatible YChaos Testplan? \u00b6 It's always ideal to keep the testplan backward compatible as much as possible. This may not be possible based on the new usecases coming in. All the changes that break the current setup should be part of one Pull Request. The PR owner should also update the minor version of the package in this PR. A new minor version should be released upon merging this PR. Do I need to release all the commits as a new patch version? \u00b6 Yes. This is part of the repository pipeline and this behaviour should not be changed. Every single commit should automatically release a new version of the package.","title":"FAQ"},{"location":"faq/#faq-frequently-asked-questions","text":"","title":"FAQ (Frequently Asked questions)"},{"location":"faq/#i-have-no-idea-why-i-am-here","text":"Great! You can start with YChaos here .","title":"I have no idea why I am here!"},{"location":"faq/#i-am-a-ychaos-user","text":"","title":"I am a YChaos user"},{"location":"faq/#does-ychaos-run-with-python36","text":"As of YChaos version 0.5.x, (Released in January 2022), Python 3.6 support is removed for YChaos. The framework might still be fully functional on Python 3.6, we do not guarantee its functionality in Python3.6 in the future releases. Note YChaos is currently tested & released for Python3.7 to Python3.10","title":"Does YChaos run with Python3.6"},{"location":"faq/#i-am-running-ychaos-and","text":"","title":"I am running YChaos and ..."},{"location":"faq/#i-am-a-ychaos-contributor","text":"","title":"I am a YChaos Contributor"},{"location":"faq/#i-am-a-ychaos-maintainer","text":"","title":"I am a YChaos Maintainer"},{"location":"get_started/","text":"This section of the document contains the steps to get started with YChaos. Install ychaos pip install ychaos [ chaos ] Create a valid test plan. (Refer Ychaos test plan schema ) Ensure the target hosts selected for testing have python3.6+ and pip3 package pre-installed Execute the test plan ychaos execute -t ./testplan.json Final report, log file will be stored in the path specified in the test plan Simple test plan configured to perform CPU burn for 60 seconds \u00b6 description : A simple test plan with CPU burn configured attack : target_type : machine target_config : blast_radius : 100 ssh_config : user : testUser password : testUserPassword hostnames : - mocktargethost.namespace.cloud report_dir : \"./\" agents : - type : cpu_burn config : start_delay : 0 duration : 60 Ensure ssh user specified in test plan has access to the host. Ychaos supports private key or password based authentication for sshing to target hosts.","title":"Get Started"},{"location":"releases/","text":"Changelog \u00b6 Version 0.x.x \u00b6 Next Version (0.6.0) \u00b6 Fix Regression with OpenTSDB Verification Plugin by Shashank Sharma Version 0.5.0 \u00b6 Add MachineTargetExecutor support for contrib agents by Alfin S Thomas Version 0.4.0 \u00b6 Add SelfTargetExecutor , that runs the agents on the same machine from where YChaos is triggered by Alfin S Thomas Publish docker image with ychaos pre-installed by Vijay Babu Add support to SSH common args in TestPlan, make SSH config optional by Shashank Sharma Version 0.3.0 \u00b6 Add Disk Fill Agent by Lakshmi Kannan Fix importing non-required PyOpenSSL module by Shashank Sharma and Vijay Babu Dependabot integration to the repository by Irfan Mohammad Integrate codespell to the repository by Shashank Sharma Add No-Color Docs to FAQ by Shashank Sharma Python3.10 validation in CI build by Shashank Sharma Fix importing not-needed PyOpenSSL dependency by Shashank Sharma Add Callable Mapping to Hooks by Shashank Sharma Add documentation for HTTP Request & SDv4 verification plugin by Shashank Sharma refactor delay_before after checking state by Alfin S Thomas Handle dump yaml/json File not found error by Sushil Karimbumkara Implement and documentation of OpenTSDB Verification Plugin by Shashank Sharma Version 0.2.0 \u00b6 Fix throwing error when a verification plugin implementation is not found or in development stage by Shashank Sharma Remove the requirement of virtualenv package on remote host by using venv by Alfin S Thomas Version 0.1.0 \u00b6 Add documentation to YChaos by Shashank Sharma Minor Bug Fixes for MachineTarget Executor by Alfin S Thomas , Shashank Sharma Add Machine Target Executor to connect to targets and execute attack by Shashank Sharma Add Coordinator module by Vijay Babu Introduce Event Hooks for circling back useful information from core components to client code (CLI) by Shashank Sharma Add System state verification to YChaos by Shashank Sharma Add Python Module Verification Module. Add HTTP Verification Plugin. Add verify subcommand to YChaos CLI. Add Screwdriver job verification to YChaos (Beta). Add Chaos Agent Definition to YChaos by Shashank Sharma Add system agents. Add Ping disable agent. Add IPTables block agent by Rahul R Add Traffic block agent. Add DNS Block agent. Add Contrib agent that enables users to write their own agents. Add CLI subcommands for testplan validation, manual, agent to YChaos by Shashank Sharma , Vijay Babu Add Testplan Schema and schema documentation to YChaos by Shashank Sharma Other improvements (CI/Documentation/Package/Dev) Add Optional dependency handler by Shashank Sharma Add Logging module for YChaos by Vijay Babu Add Log Agent Lifecycle decorator by Shashank Sharma Allow custom log file via CLI by Shashank Sharma","title":"Changelog"},{"location":"releases/#changelog","text":"","title":"Changelog"},{"location":"releases/#version-0xx","text":"","title":"Version 0.x.x"},{"location":"releases/#next-version-060","text":"Fix Regression with OpenTSDB Verification Plugin by Shashank Sharma","title":"Next Version (0.6.0)"},{"location":"releases/#version-050","text":"Add MachineTargetExecutor support for contrib agents by Alfin S Thomas","title":"Version 0.5.0"},{"location":"releases/#version-040","text":"Add SelfTargetExecutor , that runs the agents on the same machine from where YChaos is triggered by Alfin S Thomas Publish docker image with ychaos pre-installed by Vijay Babu Add support to SSH common args in TestPlan, make SSH config optional by Shashank Sharma","title":"Version 0.4.0"},{"location":"releases/#version-030","text":"Add Disk Fill Agent by Lakshmi Kannan Fix importing non-required PyOpenSSL module by Shashank Sharma and Vijay Babu Dependabot integration to the repository by Irfan Mohammad Integrate codespell to the repository by Shashank Sharma Add No-Color Docs to FAQ by Shashank Sharma Python3.10 validation in CI build by Shashank Sharma Fix importing not-needed PyOpenSSL dependency by Shashank Sharma Add Callable Mapping to Hooks by Shashank Sharma Add documentation for HTTP Request & SDv4 verification plugin by Shashank Sharma refactor delay_before after checking state by Alfin S Thomas Handle dump yaml/json File not found error by Sushil Karimbumkara Implement and documentation of OpenTSDB Verification Plugin by Shashank Sharma","title":"Version 0.3.0"},{"location":"releases/#version-020","text":"Fix throwing error when a verification plugin implementation is not found or in development stage by Shashank Sharma Remove the requirement of virtualenv package on remote host by using venv by Alfin S Thomas","title":"Version 0.2.0"},{"location":"releases/#version-010","text":"Add documentation to YChaos by Shashank Sharma Minor Bug Fixes for MachineTarget Executor by Alfin S Thomas , Shashank Sharma Add Machine Target Executor to connect to targets and execute attack by Shashank Sharma Add Coordinator module by Vijay Babu Introduce Event Hooks for circling back useful information from core components to client code (CLI) by Shashank Sharma Add System state verification to YChaos by Shashank Sharma Add Python Module Verification Module. Add HTTP Verification Plugin. Add verify subcommand to YChaos CLI. Add Screwdriver job verification to YChaos (Beta). Add Chaos Agent Definition to YChaos by Shashank Sharma Add system agents. Add Ping disable agent. Add IPTables block agent by Rahul R Add Traffic block agent. Add DNS Block agent. Add Contrib agent that enables users to write their own agents. Add CLI subcommands for testplan validation, manual, agent to YChaos by Shashank Sharma , Vijay Babu Add Testplan Schema and schema documentation to YChaos by Shashank Sharma Other improvements (CI/Documentation/Package/Dev) Add Optional dependency handler by Shashank Sharma Add Logging module for YChaos by Vijay Babu Add Log Agent Lifecycle decorator by Shashank Sharma Allow custom log file via CLI by Shashank Sharma","title":"Version 0.1.0"},{"location":"agents/","text":"YChaos Agents \u00b6 Agents are the actual attack modules that are responsible to perform monitored attack onto the system. Installation \u00b6 To install the required dependencies to run agents, you can use the agents extras. pip install ychaos [ agents ] The above command will install the core requirements of ychaos along with the optional requirements needed to run chaos agents on the system. Configuration \u00b6 The only input to any agent is a configuration object. This is usually supplied from the test plan. The testplan supplied to the framework is parsed to arrive at the configuration for a particular agent. Any custom configuration needed can be defined by implementing the AgentConfig class. Lifecycle \u00b6 The agents defined in the package (and the extensions) follow a simple lifecycle. These lifecycle define what the agent does before, during and after the attack. The lifecycle of the agents are defined by these methods setup : Responsible for setting up the system, environment for the minion to run run : The actual attack on the system teardown : Bringing back the system back to how it was before the attack monitor : A special method that tracks the system, agent and its current status. Each and every agent that is defined should implement each of these lifecycle methods to define their behaviour in the particular scenario. The base Agent is defined here . Any extending agent can implement this interface.","title":"Home"},{"location":"agents/#ychaos-agents","text":"Agents are the actual attack modules that are responsible to perform monitored attack onto the system.","title":"YChaos Agents"},{"location":"agents/#installation","text":"To install the required dependencies to run agents, you can use the agents extras. pip install ychaos [ agents ] The above command will install the core requirements of ychaos along with the optional requirements needed to run chaos agents on the system.","title":"Installation"},{"location":"agents/#configuration","text":"The only input to any agent is a configuration object. This is usually supplied from the test plan. The testplan supplied to the framework is parsed to arrive at the configuration for a particular agent. Any custom configuration needed can be defined by implementing the AgentConfig class.","title":"Configuration"},{"location":"agents/#lifecycle","text":"The agents defined in the package (and the extensions) follow a simple lifecycle. These lifecycle define what the agent does before, during and after the attack. The lifecycle of the agents are defined by these methods setup : Responsible for setting up the system, environment for the minion to run run : The actual attack on the system teardown : Bringing back the system back to how it was before the attack monitor : A special method that tracks the system, agent and its current status. Each and every agent that is defined should implement each of these lifecycle methods to define their behaviour in the particular scenario. The base Agent is defined here . Any extending agent can implement this interface.","title":"Lifecycle"},{"location":"agents/contrib/","text":"Contrib Agent \u00b6 Warning This feature is in Beta. YChaos allows the users to define their own chaos agents to be run on their targets to test the resiliency of the system. The principal concept of contrib agent is to have users write their own chaos modules and eventually contribute back to the framework. Quickstart \u00b6 To develop a simple YChaos agent, create a python file say /tmp/awesome_agent.py , with a sample structure given below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 from ychaos.agents.agent import Agent , AgentConfig from ychaos.agents.utils.annotations import log_agent_lifecycle from queue import LifoQueue class MyAwesomeAgentConfig ( AgentConfig ): name : str = \"my_awesome_agent\" description : str = \"This is an invincible agent\" # Define the pydantic model with configuration that can be # sent to the agent during initialization class MyAwesomeAgent ( Agent ): \"\"\" An agent of unimaginable capabilities. \"\"\" def __init__ ( self , config ): assert isinstance ( config , AgentConfig ) super ( MyAwesomeAgent , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( MyAwesomeAgent , self ) . monitor () # Monitor the agent and the system as to # how the agent is performing return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( MyAwesomeAgent , self ) . setup () # Set up the system to perform an attack @log_agent_lifecycle def run ( self ) -> None : super ( MyAwesomeAgent , self ) . run () # Define the program Logic here as to what needs # to be done during attack, say delete an important file @log_agent_lifecycle def teardown ( self ) -> None : super ( MyAwesomeAgent , self ) . teardown () # Bring back the system's state to normal # by reverting all the changes you have done during the attack # Define these 2 Global constants for the framework to import # these classes. AgentClass = MyAwesomeAgent AgentConfigClass = MyAwesomeAgentConfig Once the python module is created, all that is needed to be done is to import this file in testplan. Configure the attack configuration in the testplan as mentioned below by changing relevant parameters. Refer to the Testplan schema for more details. JSON { \"attack\" : { \"target_type\" : \"self\" , \"agents\" : [ { \"type\" : \"contrib\" , \"config\" : { \"path\" : \"/tmp/awesome_agent.py\" , \"contrib_agent_config\" : { \"key1\" : \"value1\" , \"key2\" : \"value2\" } } } ] } } YAML --- attack : target_type : self # Your preferred target type agents : - type : contrib config : path : \"/tmp/awesome_agent.py\" contrib_agent_config : key1 : value1 key2 : value2","title":"Contrib"},{"location":"agents/contrib/#contrib-agent","text":"Warning This feature is in Beta. YChaos allows the users to define their own chaos agents to be run on their targets to test the resiliency of the system. The principal concept of contrib agent is to have users write their own chaos modules and eventually contribute back to the framework.","title":"Contrib Agent"},{"location":"agents/contrib/#quickstart","text":"To develop a simple YChaos agent, create a python file say /tmp/awesome_agent.py , with a sample structure given below. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 from ychaos.agents.agent import Agent , AgentConfig from ychaos.agents.utils.annotations import log_agent_lifecycle from queue import LifoQueue class MyAwesomeAgentConfig ( AgentConfig ): name : str = \"my_awesome_agent\" description : str = \"This is an invincible agent\" # Define the pydantic model with configuration that can be # sent to the agent during initialization class MyAwesomeAgent ( Agent ): \"\"\" An agent of unimaginable capabilities. \"\"\" def __init__ ( self , config ): assert isinstance ( config , AgentConfig ) super ( MyAwesomeAgent , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( MyAwesomeAgent , self ) . monitor () # Monitor the agent and the system as to # how the agent is performing return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( MyAwesomeAgent , self ) . setup () # Set up the system to perform an attack @log_agent_lifecycle def run ( self ) -> None : super ( MyAwesomeAgent , self ) . run () # Define the program Logic here as to what needs # to be done during attack, say delete an important file @log_agent_lifecycle def teardown ( self ) -> None : super ( MyAwesomeAgent , self ) . teardown () # Bring back the system's state to normal # by reverting all the changes you have done during the attack # Define these 2 Global constants for the framework to import # these classes. AgentClass = MyAwesomeAgent AgentConfigClass = MyAwesomeAgentConfig Once the python module is created, all that is needed to be done is to import this file in testplan. Configure the attack configuration in the testplan as mentioned below by changing relevant parameters. Refer to the Testplan schema for more details. JSON { \"attack\" : { \"target_type\" : \"self\" , \"agents\" : [ { \"type\" : \"contrib\" , \"config\" : { \"path\" : \"/tmp/awesome_agent.py\" , \"contrib_agent_config\" : { \"key1\" : \"value1\" , \"key2\" : \"value2\" } } } ] } } YAML --- attack : target_type : self # Your preferred target type agents : - type : contrib config : path : \"/tmp/awesome_agent.py\" contrib_agent_config : key1 : value1 key2 : value2","title":"Quickstart"},{"location":"cli/","text":"YChaos CLI \u00b6 YChaos CLI provides a set of commands that can be run from your console to perform various operations with YChaos. Starting with the testplan validation and up to performing attack is a part of YChaos CLI. YChaos CLI's structure is defined below ychaos --<GLOBAL_ARGUMENTS> [ <SUBCOMMAND> --<SUBCOMMAND_ARGUMENTS> ] ... The GLOBAL_ARGUMENTS refer to the arguments that mostly configures how the YChaos CLI runs. SUBCOMMAND refers to the individual operations that can be performed with like verify , testplan etc. Each subcommand can contain commands under those. The SUBCOMMAND_ARGUMENTS basically configures they way each subcommand runs. To view the usage of YChaos CLI visit the documentation or run ychaos manual on command line. To view the documentation of Individual components of YChaos CLI, visit package_docs","title":"YChaos CLI"},{"location":"cli/#ychaos-cli","text":"YChaos CLI provides a set of commands that can be run from your console to perform various operations with YChaos. Starting with the testplan validation and up to performing attack is a part of YChaos CLI. YChaos CLI's structure is defined below ychaos --<GLOBAL_ARGUMENTS> [ <SUBCOMMAND> --<SUBCOMMAND_ARGUMENTS> ] ... The GLOBAL_ARGUMENTS refer to the arguments that mostly configures how the YChaos CLI runs. SUBCOMMAND refers to the individual operations that can be performed with like verify , testplan etc. Each subcommand can contain commands under those. The SUBCOMMAND_ARGUMENTS basically configures they way each subcommand runs. To view the usage of YChaos CLI visit the documentation or run ychaos manual on command line. To view the documentation of Individual components of YChaos CLI, visit package_docs","title":"YChaos CLI"},{"location":"cli/manual/","text":"ychaos \u00b6 usage: ychaos [-h] [-v] [-V] [--debug] [-c config] [--no-color] [--text-report path] [--html-report path] [--log-file path] {testplan,manual,agent,verify,execute} ... positional arguments: {testplan,manual,agent,verify,execute} testplan sub command for test plan operations manual Print the manual for YChaos CLI agent The agent subcommand of YChaos verify The verification subcommand of YChaos execute The execute subcommand of YChaos optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit -c config, --config config Set YChaos CLI configuration (prod) (default: prod) --no-color Disable color on console output ($NO_COLOR) (default: False) verbosity: -V, --verbose Increase verbosity of logs (INFO) (default: 0) --debug Enable debug mode (default: False) reports: --text-report path Generate a text report from the YChaos execution (default: None) --html-report path Generate a HTML report from YChaos execution (default: None) --log-file path The file to store application logs. ($YCHAOS_LOG_FILE) (default: None) ychaos testplan \u00b6 usage: ychaos testplan [-h] {validate} ... positional arguments: {validate} validate Validate YChaos Test plans optional arguments: -h, --help show this help message and exit ychaos testplan validate \u00b6 usage: ychaos testplan validate [-h] path [path ...] positional arguments: path Space separated list of file/directory paths to validate optional arguments: -h, --help show this help message and exit ychaos manual \u00b6 usage: ychaos manual [-h] [-f path] optional arguments: -h, --help show this help message and exit -f path, --file path Print YChaos CLI Manual to a file (default: None) ychaos agent \u00b6 usage: ychaos agent [-h] {attack} ... positional arguments: {attack} attack YChaos Agent Attack Subcommand optional arguments: -h, --help show this help message and exit ychaos agent attack \u00b6 usage: ychaos agent attack [-h] -t path [--attack-report-yaml path] optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None) --attack-report-yaml path File Path to store attack report in YAML format (default: None) ychaos verify \u00b6 usage: ychaos verify [-h] -t path [-s state] [--dump-yaml path] [--dump-json path] [--state-data path] optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None) -s state, --state state System state to verify (default: steady) --state-data path The path of the verification data state file (JSON/YAML) (default: None) verification reports: --dump-yaml path Store the verification data in YAML format (default: None) --dump-json path Store the verification data in JSON format (default: None) ychaos execute \u00b6 usage: ychaos execute [-h] -t path optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None)","title":"CLI Usage"},{"location":"cli/manual/#ychaos","text":"usage: ychaos [-h] [-v] [-V] [--debug] [-c config] [--no-color] [--text-report path] [--html-report path] [--log-file path] {testplan,manual,agent,verify,execute} ... positional arguments: {testplan,manual,agent,verify,execute} testplan sub command for test plan operations manual Print the manual for YChaos CLI agent The agent subcommand of YChaos verify The verification subcommand of YChaos execute The execute subcommand of YChaos optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit -c config, --config config Set YChaos CLI configuration (prod) (default: prod) --no-color Disable color on console output ($NO_COLOR) (default: False) verbosity: -V, --verbose Increase verbosity of logs (INFO) (default: 0) --debug Enable debug mode (default: False) reports: --text-report path Generate a text report from the YChaos execution (default: None) --html-report path Generate a HTML report from YChaos execution (default: None) --log-file path The file to store application logs. ($YCHAOS_LOG_FILE) (default: None)","title":"ychaos"},{"location":"cli/manual/#ychaos-testplan","text":"usage: ychaos testplan [-h] {validate} ... positional arguments: {validate} validate Validate YChaos Test plans optional arguments: -h, --help show this help message and exit","title":"ychaos testplan"},{"location":"cli/manual/#ychaos-testplan-validate","text":"usage: ychaos testplan validate [-h] path [path ...] positional arguments: path Space separated list of file/directory paths to validate optional arguments: -h, --help show this help message and exit","title":"ychaos testplan validate"},{"location":"cli/manual/#ychaos-manual","text":"usage: ychaos manual [-h] [-f path] optional arguments: -h, --help show this help message and exit -f path, --file path Print YChaos CLI Manual to a file (default: None)","title":"ychaos manual"},{"location":"cli/manual/#ychaos-agent","text":"usage: ychaos agent [-h] {attack} ... positional arguments: {attack} attack YChaos Agent Attack Subcommand optional arguments: -h, --help show this help message and exit","title":"ychaos agent"},{"location":"cli/manual/#ychaos-agent-attack","text":"usage: ychaos agent attack [-h] -t path [--attack-report-yaml path] optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None) --attack-report-yaml path File Path to store attack report in YAML format (default: None)","title":"ychaos agent attack"},{"location":"cli/manual/#ychaos-verify","text":"usage: ychaos verify [-h] -t path [-s state] [--dump-yaml path] [--dump-json path] [--state-data path] optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None) -s state, --state state System state to verify (default: steady) --state-data path The path of the verification data state file (JSON/YAML) (default: None) verification reports: --dump-yaml path Store the verification data in YAML format (default: None) --dump-json path Store the verification data in JSON format (default: None)","title":"ychaos verify"},{"location":"cli/manual/#ychaos-execute","text":"usage: ychaos execute [-h] -t path optional arguments: -h, --help show this help message and exit -t path, --testplan path The testplan path. This can be relative path from where the CLI is initiated (default: None)","title":"ychaos execute"},{"location":"package_docs/agents/agent/","text":"Agent ( ABC ) \u00b6 An agent is an attack module that is configured to cause some kind of chaos on the target. A very simple of agent is the CPU Burn agent that is responsible for consuming CPU resources during the time interval its run. Each agent takes in one configuration object that is a subclass of AgentConfig. The agents have a lifecycle defined in AgentState each of them indicating the state in which the agent is currently in. The agent is advanced to the next state before executing any of the lifecycle methods. Source code in agents/agent.py class Agent ( ABC ): \"\"\" An agent is an attack module that is configured to cause some kind of chaos on the target. A very simple of agent is the CPU Burn agent that is responsible for consuming CPU resources during the time interval its run. Each agent takes in one configuration object that is a subclass of AgentConfig. The agents have a lifecycle defined in `AgentState` each of them indicating the state in which the agent is currently in. The agent is advanced to the next state before executing any of the lifecycle methods. \"\"\" def __init__ ( self , config ): \"\"\" Initialize an agent with a configuration Raises: InsufficientPermissionError: When the agent is configured to be sudo, but the agent is not run as root. Args: config: Agent configuration. \"\"\" self . config = config self . _runner = Thread ( target = self . __run_exc_wrapper , name = config . name ) self . _stopper = Thread ( target = self . __teardown_exc_wrapper , name = config . name + \"_teardown\" ) self . stop_async_run : bool = False # can be used as a flag to stop the attack and return from `run` method self . exception = Queue ( - 1 ) self . _status = LifoQueue () self . _state_history = list () self . preserved_state = SimpleNamespace ( has_error = False , is_aborted = False ) self . advance_state ( AgentState . INIT ) @abstractmethod def monitor ( self ) -> LifoQueue : # pragma: no cover \"\"\" Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: A Queue of the status for this agent. \"\"\" pass @abstractmethod def setup ( self ) -> None : \"\"\" Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: None \"\"\" self . advance_state ( AgentState . SETUP ) @abstractmethod def run ( self ) -> None : \"\"\" Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use `start` or `start_async` for a better usage. Raises: AgentError: if `config.error_on_state_mismatch` is True and current state is not SETUP Returns: None \"\"\" if self . current_state != AgentState . SETUP : if self . config . raise_on_state_mismatch : self . advance_state ( AgentState . ABORTED ) raise AgentError ( \"Agent state is not in SETUP state. Bailing out\" ) warnings . warn ( \"Agent is currently not in the SETUP state. Proceeding anyway\" ) if not self . is_runnable (): raise AgentError ( \"Agent not in executable state. Bailing out\" ) self . advance_state ( AgentState . RUNNING ) def start ( self , coro = BuiltinUtils . pass_coroutine , args : Tuple [ Any , ... ] = tuple (), interval = None , ) -> None : \"\"\" A blocking start call. This method waits for the agent process to complete/exit. Calls a `coro` coroutine every `interval` seconds Also sets the agent state on COMPLETED/ERROR. Use `start_async()` method for the runner thread to run in background Args: coro: A function to call every `interval` seconds when the _runner is alive args: Arguments interval: Interval between 2 coroutine calls Returns: None \"\"\" self . _runner . start () while self . _runner . is_alive (): coro ( * args ) self . _runner . join ( interval ) if self . exception . empty (): self . advance_state ( AgentState . COMPLETED ) else : self . advance_state ( AgentState . ERROR ) def start_async ( self ) -> Thread : # pragma: no cover \"\"\" Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. \"\"\" self . _runner . start () return self . _runner def teardown_async ( self ) -> Thread : # pragma: no cover \"\"\" Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: teardown_async Thread instance \"\"\" self . _stopper . start () return self . _stopper @abstractmethod def teardown ( self ) -> None : \"\"\" This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: None \"\"\" self . advance_state ( AgentState . TEARDOWN ) self . stop_async_run = True if self . _runner . is_alive (): self . _runner . join () def is_runnable ( self ) -> bool : \"\"\" Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: True if able to proceed, False otherwise \"\"\" if self . current_state < 0 : return False if not self . exception . empty (): return False if self . config . is_sudo and os . geteuid () != 0 : return False return True def advance_state ( self , state : AgentState ): if self . _state_history and self . _state_history [ - 1 ] == state : return self . _state_history . append ( state ) @property def current_state ( self ) -> AgentState : \"\"\" Gets the current state of the agent. Returns: current state \"\"\" if not self . _state_history : # Never possible self . _state_history = list () self . advance_state ( AgentState . UNDEFINED ) return self . _state_history [ - 1 ] def __run_exc_wrapper ( self ): try : self . run () except Exception as e : self . exception . put ( e ) self . advance_state ( AgentState . ERROR ) def __teardown_exc_wrapper ( self ): try : self . teardown () self . advance_state ( AgentState . DONE ) except Exception as e : self . exception . put ( e ) self . advance_state ( AgentState . ERROR ) current_state : AgentState property readonly \u00b6 Gets the current state of the agent. Returns: Type Description AgentState current state __init__ ( self , config ) special \u00b6 Initialize an agent with a configuration Exceptions: Type Description InsufficientPermissionError When the agent is configured to be sudo, but the agent is not run as root. Parameters: Name Type Description Default config Agent configuration. required Source code in agents/agent.py def __init__ ( self , config ): \"\"\" Initialize an agent with a configuration Raises: InsufficientPermissionError: When the agent is configured to be sudo, but the agent is not run as root. Args: config: Agent configuration. \"\"\" self . config = config self . _runner = Thread ( target = self . __run_exc_wrapper , name = config . name ) self . _stopper = Thread ( target = self . __teardown_exc_wrapper , name = config . name + \"_teardown\" ) self . stop_async_run : bool = False # can be used as a flag to stop the attack and return from `run` method self . exception = Queue ( - 1 ) self . _status = LifoQueue () self . _state_history = list () self . preserved_state = SimpleNamespace ( has_error = False , is_aborted = False ) self . advance_state ( AgentState . INIT ) is_runnable ( self ) \u00b6 Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: Type Description bool True if able to proceed, False otherwise Source code in agents/agent.py def is_runnable ( self ) -> bool : \"\"\" Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: True if able to proceed, False otherwise \"\"\" if self . current_state < 0 : return False if not self . exception . empty (): return False if self . config . is_sudo and os . geteuid () != 0 : return False return True monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/agent.py @abstractmethod def monitor ( self ) -> LifoQueue : # pragma: no cover \"\"\" Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: A Queue of the status for this agent. \"\"\" pass run ( self ) \u00b6 Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use start or start_async for a better usage. Exceptions: Type Description AgentError if config.error_on_state_mismatch is True and current state is not SETUP Returns: Type Description None None Source code in agents/agent.py @abstractmethod def run ( self ) -> None : \"\"\" Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use `start` or `start_async` for a better usage. Raises: AgentError: if `config.error_on_state_mismatch` is True and current state is not SETUP Returns: None \"\"\" if self . current_state != AgentState . SETUP : if self . config . raise_on_state_mismatch : self . advance_state ( AgentState . ABORTED ) raise AgentError ( \"Agent state is not in SETUP state. Bailing out\" ) warnings . warn ( \"Agent is currently not in the SETUP state. Proceeding anyway\" ) if not self . is_runnable (): raise AgentError ( \"Agent not in executable state. Bailing out\" ) self . advance_state ( AgentState . RUNNING ) setup ( self ) \u00b6 Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: Type Description None None Source code in agents/agent.py @abstractmethod def setup ( self ) -> None : \"\"\" Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: None \"\"\" self . advance_state ( AgentState . SETUP ) start ( self , coro =< bound method BuiltinUtils . pass_coroutine of < class ' ychaos . utils . builtins . BuiltinUtils '>>, args=(), interval=None) \u00b6 A blocking start call. This method waits for the agent process to complete/exit. Calls a coro coroutine every interval seconds Also sets the agent state on COMPLETED/ERROR. Use start_async() method for the runner thread to run in background Parameters: Name Type Description Default coro A function to call every interval seconds when the _runner is alive <bound method BuiltinUtils.pass_coroutine of <class 'ychaos.utils.builtins.BuiltinUtils'>> args Tuple[Any, ...] Arguments () interval Interval between 2 coroutine calls None Returns: Type Description None None Source code in agents/agent.py def start ( self , coro = BuiltinUtils . pass_coroutine , args : Tuple [ Any , ... ] = tuple (), interval = None , ) -> None : \"\"\" A blocking start call. This method waits for the agent process to complete/exit. Calls a `coro` coroutine every `interval` seconds Also sets the agent state on COMPLETED/ERROR. Use `start_async()` method for the runner thread to run in background Args: coro: A function to call every `interval` seconds when the _runner is alive args: Arguments interval: Interval between 2 coroutine calls Returns: None \"\"\" self . _runner . start () while self . _runner . is_alive (): coro ( * args ) self . _runner . join ( interval ) if self . exception . empty (): self . advance_state ( AgentState . COMPLETED ) else : self . advance_state ( AgentState . ERROR ) start_async ( self ) \u00b6 Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. Source code in agents/agent.py def start_async ( self ) -> Thread : # pragma: no cover \"\"\" Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. \"\"\" self . _runner . start () return self . _runner teardown ( self ) \u00b6 This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: Type Description None None Source code in agents/agent.py @abstractmethod def teardown ( self ) -> None : \"\"\" This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: None \"\"\" self . advance_state ( AgentState . TEARDOWN ) self . stop_async_run = True if self . _runner . is_alive (): self . _runner . join () teardown_async ( self ) \u00b6 Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: Type Description Thread teardown_async Thread instance Source code in agents/agent.py def teardown_async ( self ) -> Thread : # pragma: no cover \"\"\" Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: teardown_async Thread instance \"\"\" self . _stopper . start () return self . _stopper AgentConfig ( BaseModel ) pydantic-model \u00b6 The configuration of the agent that is to be run. This is the base configuration for any agent. Custom configuration attributes can be added to individual agent by inheriting this model. Source code in agents/agent.py class AgentConfig ( BaseModel ): \"\"\" The configuration of the agent that is to be run. This is the base configuration for any agent. Custom configuration attributes can be added to individual agent by inheriting this model. \"\"\" name : str = Field ( ... , description = \"A one word identifier for the Agent.\" ) description : str = Field ( default = \"An awesome YChaos agent.\" , description = \"Multiline description of the agent in consideration\" , ) priority : AgentPriority = Field ( default = AgentPriority . UNDEFINED_PRIORITY , description = \"A priority assigned to the agent.\" , ) # Runner configurations (Advanced configuration parameters) is_sudo : bool = Field ( default = False , description = \"Setting this to true, requires the agent to run as root.\" , ) # Be very careful when setting this key to False. # If you are aware of what you are doing, then go ahead. raise_on_state_mismatch : bool = Field ( default = True , description = \"Raise error on state mismatch\" ) start_delay : int = Field ( default = 10 , description = \"Give a delay of few seconds before running this agent\" ) def get_agent ( self ): \"\"\" The Fallback factory method to use where the Agent instance depends on the configuration Returns: An agent subclass of Agent \"\"\" pass description : str pydantic-field \u00b6 Multiline description of the agent in consideration is_sudo : bool pydantic-field \u00b6 Setting this to true, requires the agent to run as root. name : str pydantic-field required \u00b6 A one word identifier for the Agent. priority : AgentPriority pydantic-field \u00b6 A priority assigned to the agent. raise_on_state_mismatch : bool pydantic-field \u00b6 Raise error on state mismatch start_delay : int pydantic-field \u00b6 Give a delay of few seconds before running this agent get_agent ( self ) \u00b6 The Fallback factory method to use where the Agent instance depends on the configuration Returns: Type Description An agent subclass of Agent Source code in agents/agent.py def get_agent ( self ): \"\"\" The Fallback factory method to use where the Agent instance depends on the configuration Returns: An agent subclass of Agent \"\"\" pass AgentMonitoringDataPoint ( BaseModel ) pydantic-model \u00b6 Source code in agents/agent.py class AgentMonitoringDataPoint ( BaseModel ): timestamp : datetime = Field ( default_factory = datetime . utcnow ) data : Dict [ str , Any ] = Field ( ... , description = \"Data from the agent at `timestamp` instant\" ) state : AgentState = Field ( description = \"The state of the agent at `timestamp` instant\" ) data : Dict [ str , Any ] pydantic-field required \u00b6 Data from the agent at timestamp instant state : AgentState pydantic-field required \u00b6 The state of the agent at timestamp instant AgentPriority ( IntEnum ) \u00b6 An enumeration. Source code in agents/agent.py class AgentPriority ( IntEnum ): VERY_HIGH_PRIORITY = 0 HIGH_PRIORITY = 1 MODERATE_PRIORITY = 2 LOW_PRIORITY = 3 VERY_LOW_PRIORITY = 4 UNDEFINED_PRIORITY = - 1 AgentState ( IntEnum ) \u00b6 An enumeration. Source code in agents/agent.py class AgentState ( IntEnum ): SKIPPED = - 3 ABORTED = - 2 ERROR = - 1 UNDEFINED = 0 INIT = 1 SETUP = 2 RUNNING = 3 COMPLETED = 4 TEARDOWN = 5 DONE = 6 TimedAgentConfig ( AgentConfig ) pydantic-model \u00b6 The configuration of the agent which is constrained by a duration. This configuration is used for agents that are supposed to run for a particular amount of time before going to teardown state. Source code in agents/agent.py class TimedAgentConfig ( AgentConfig ): \"\"\" The configuration of the agent which is constrained by a duration. This configuration is used for agents that are supposed to run for a particular amount of time before going to teardown state. \"\"\" duration : int = Field ( default = 300 , description = \"The duration for which this agent should run\" , ) duration : int pydantic-field \u00b6 The duration for which this agent should run","title":"agent"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent","text":"An agent is an attack module that is configured to cause some kind of chaos on the target. A very simple of agent is the CPU Burn agent that is responsible for consuming CPU resources during the time interval its run. Each agent takes in one configuration object that is a subclass of AgentConfig. The agents have a lifecycle defined in AgentState each of them indicating the state in which the agent is currently in. The agent is advanced to the next state before executing any of the lifecycle methods. Source code in agents/agent.py class Agent ( ABC ): \"\"\" An agent is an attack module that is configured to cause some kind of chaos on the target. A very simple of agent is the CPU Burn agent that is responsible for consuming CPU resources during the time interval its run. Each agent takes in one configuration object that is a subclass of AgentConfig. The agents have a lifecycle defined in `AgentState` each of them indicating the state in which the agent is currently in. The agent is advanced to the next state before executing any of the lifecycle methods. \"\"\" def __init__ ( self , config ): \"\"\" Initialize an agent with a configuration Raises: InsufficientPermissionError: When the agent is configured to be sudo, but the agent is not run as root. Args: config: Agent configuration. \"\"\" self . config = config self . _runner = Thread ( target = self . __run_exc_wrapper , name = config . name ) self . _stopper = Thread ( target = self . __teardown_exc_wrapper , name = config . name + \"_teardown\" ) self . stop_async_run : bool = False # can be used as a flag to stop the attack and return from `run` method self . exception = Queue ( - 1 ) self . _status = LifoQueue () self . _state_history = list () self . preserved_state = SimpleNamespace ( has_error = False , is_aborted = False ) self . advance_state ( AgentState . INIT ) @abstractmethod def monitor ( self ) -> LifoQueue : # pragma: no cover \"\"\" Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: A Queue of the status for this agent. \"\"\" pass @abstractmethod def setup ( self ) -> None : \"\"\" Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: None \"\"\" self . advance_state ( AgentState . SETUP ) @abstractmethod def run ( self ) -> None : \"\"\" Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use `start` or `start_async` for a better usage. Raises: AgentError: if `config.error_on_state_mismatch` is True and current state is not SETUP Returns: None \"\"\" if self . current_state != AgentState . SETUP : if self . config . raise_on_state_mismatch : self . advance_state ( AgentState . ABORTED ) raise AgentError ( \"Agent state is not in SETUP state. Bailing out\" ) warnings . warn ( \"Agent is currently not in the SETUP state. Proceeding anyway\" ) if not self . is_runnable (): raise AgentError ( \"Agent not in executable state. Bailing out\" ) self . advance_state ( AgentState . RUNNING ) def start ( self , coro = BuiltinUtils . pass_coroutine , args : Tuple [ Any , ... ] = tuple (), interval = None , ) -> None : \"\"\" A blocking start call. This method waits for the agent process to complete/exit. Calls a `coro` coroutine every `interval` seconds Also sets the agent state on COMPLETED/ERROR. Use `start_async()` method for the runner thread to run in background Args: coro: A function to call every `interval` seconds when the _runner is alive args: Arguments interval: Interval between 2 coroutine calls Returns: None \"\"\" self . _runner . start () while self . _runner . is_alive (): coro ( * args ) self . _runner . join ( interval ) if self . exception . empty (): self . advance_state ( AgentState . COMPLETED ) else : self . advance_state ( AgentState . ERROR ) def start_async ( self ) -> Thread : # pragma: no cover \"\"\" Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. \"\"\" self . _runner . start () return self . _runner def teardown_async ( self ) -> Thread : # pragma: no cover \"\"\" Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: teardown_async Thread instance \"\"\" self . _stopper . start () return self . _stopper @abstractmethod def teardown ( self ) -> None : \"\"\" This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: None \"\"\" self . advance_state ( AgentState . TEARDOWN ) self . stop_async_run = True if self . _runner . is_alive (): self . _runner . join () def is_runnable ( self ) -> bool : \"\"\" Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: True if able to proceed, False otherwise \"\"\" if self . current_state < 0 : return False if not self . exception . empty (): return False if self . config . is_sudo and os . geteuid () != 0 : return False return True def advance_state ( self , state : AgentState ): if self . _state_history and self . _state_history [ - 1 ] == state : return self . _state_history . append ( state ) @property def current_state ( self ) -> AgentState : \"\"\" Gets the current state of the agent. Returns: current state \"\"\" if not self . _state_history : # Never possible self . _state_history = list () self . advance_state ( AgentState . UNDEFINED ) return self . _state_history [ - 1 ] def __run_exc_wrapper ( self ): try : self . run () except Exception as e : self . exception . put ( e ) self . advance_state ( AgentState . ERROR ) def __teardown_exc_wrapper ( self ): try : self . teardown () self . advance_state ( AgentState . DONE ) except Exception as e : self . exception . put ( e ) self . advance_state ( AgentState . ERROR )","title":"Agent"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.current_state","text":"Gets the current state of the agent. Returns: Type Description AgentState current state","title":"current_state"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.__init__","text":"Initialize an agent with a configuration Exceptions: Type Description InsufficientPermissionError When the agent is configured to be sudo, but the agent is not run as root. Parameters: Name Type Description Default config Agent configuration. required Source code in agents/agent.py def __init__ ( self , config ): \"\"\" Initialize an agent with a configuration Raises: InsufficientPermissionError: When the agent is configured to be sudo, but the agent is not run as root. Args: config: Agent configuration. \"\"\" self . config = config self . _runner = Thread ( target = self . __run_exc_wrapper , name = config . name ) self . _stopper = Thread ( target = self . __teardown_exc_wrapper , name = config . name + \"_teardown\" ) self . stop_async_run : bool = False # can be used as a flag to stop the attack and return from `run` method self . exception = Queue ( - 1 ) self . _status = LifoQueue () self . _state_history = list () self . preserved_state = SimpleNamespace ( has_error = False , is_aborted = False ) self . advance_state ( AgentState . INIT )","title":"__init__()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.is_runnable","text":"Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: Type Description bool True if able to proceed, False otherwise Source code in agents/agent.py def is_runnable ( self ) -> bool : \"\"\" Fail Fast approach to find if the agent will be able to proceed to the next step. It is advised to run this method before running, start, run or start_async to avoid any mishaps in testing. Returns: True if able to proceed, False otherwise \"\"\" if self . current_state < 0 : return False if not self . exception . empty (): return False if self . config . is_sudo and os . geteuid () != 0 : return False return True","title":"is_runnable()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/agent.py @abstractmethod def monitor ( self ) -> LifoQueue : # pragma: no cover \"\"\" Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: A Queue of the status for this agent. \"\"\" pass","title":"monitor()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.run","text":"Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use start or start_async for a better usage. Exceptions: Type Description AgentError if config.error_on_state_mismatch is True and current state is not SETUP Returns: Type Description None None Source code in agents/agent.py @abstractmethod def run ( self ) -> None : \"\"\" Define what the agent does for the attack. Calling this method will block the calling thread. Caller has to take responsibility of updating the state of the agent once it is done. Use `start` or `start_async` for a better usage. Raises: AgentError: if `config.error_on_state_mismatch` is True and current state is not SETUP Returns: None \"\"\" if self . current_state != AgentState . SETUP : if self . config . raise_on_state_mismatch : self . advance_state ( AgentState . ABORTED ) raise AgentError ( \"Agent state is not in SETUP state. Bailing out\" ) warnings . warn ( \"Agent is currently not in the SETUP state. Proceeding anyway\" ) if not self . is_runnable (): raise AgentError ( \"Agent not in executable state. Bailing out\" ) self . advance_state ( AgentState . RUNNING )","title":"run()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.setup","text":"Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: Type Description None None Source code in agents/agent.py @abstractmethod def setup ( self ) -> None : \"\"\" Defines the setup method. Used to set up the resources required for the agent. This is usually called before start Returns: None \"\"\" self . advance_state ( AgentState . SETUP )","title":"setup()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.start","text":"A blocking start call. This method waits for the agent process to complete/exit. Calls a coro coroutine every interval seconds Also sets the agent state on COMPLETED/ERROR. Use start_async() method for the runner thread to run in background Parameters: Name Type Description Default coro A function to call every interval seconds when the _runner is alive <bound method BuiltinUtils.pass_coroutine of <class 'ychaos.utils.builtins.BuiltinUtils'>> args Tuple[Any, ...] Arguments () interval Interval between 2 coroutine calls None Returns: Type Description None None Source code in agents/agent.py def start ( self , coro = BuiltinUtils . pass_coroutine , args : Tuple [ Any , ... ] = tuple (), interval = None , ) -> None : \"\"\" A blocking start call. This method waits for the agent process to complete/exit. Calls a `coro` coroutine every `interval` seconds Also sets the agent state on COMPLETED/ERROR. Use `start_async()` method for the runner thread to run in background Args: coro: A function to call every `interval` seconds when the _runner is alive args: Arguments interval: Interval between 2 coroutine calls Returns: None \"\"\" self . _runner . start () while self . _runner . is_alive (): coro ( * args ) self . _runner . join ( interval ) if self . exception . empty (): self . advance_state ( AgentState . COMPLETED ) else : self . advance_state ( AgentState . ERROR )","title":"start()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.start_async","text":"Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. Source code in agents/agent.py def start_async ( self ) -> Thread : # pragma: no cover \"\"\" Unblocking call to start the run method. It is the responsibility of the caller to update the agent with its state, handle exceptions, etc. \"\"\" self . _runner . start () return self . _runner","title":"start_async()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.teardown","text":"This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: Type Description None None Source code in agents/agent.py @abstractmethod def teardown ( self ) -> None : \"\"\" This is called once the execute method is done to ensure a rollback is done to the state the agent entered.It wait for start_async thread to stop if its alive. Returns: None \"\"\" self . advance_state ( AgentState . TEARDOWN ) self . stop_async_run = True if self . _runner . is_alive (): self . _runner . join ()","title":"teardown()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.Agent.teardown_async","text":"Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: Type Description Thread teardown_async Thread instance Source code in agents/agent.py def teardown_async ( self ) -> Thread : # pragma: no cover \"\"\" Non blocking call to start the teardown method. The caller takes full responsibility of handing Returns: teardown_async Thread instance \"\"\" self . _stopper . start () return self . _stopper","title":"teardown_async()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig","text":"The configuration of the agent that is to be run. This is the base configuration for any agent. Custom configuration attributes can be added to individual agent by inheriting this model. Source code in agents/agent.py class AgentConfig ( BaseModel ): \"\"\" The configuration of the agent that is to be run. This is the base configuration for any agent. Custom configuration attributes can be added to individual agent by inheriting this model. \"\"\" name : str = Field ( ... , description = \"A one word identifier for the Agent.\" ) description : str = Field ( default = \"An awesome YChaos agent.\" , description = \"Multiline description of the agent in consideration\" , ) priority : AgentPriority = Field ( default = AgentPriority . UNDEFINED_PRIORITY , description = \"A priority assigned to the agent.\" , ) # Runner configurations (Advanced configuration parameters) is_sudo : bool = Field ( default = False , description = \"Setting this to true, requires the agent to run as root.\" , ) # Be very careful when setting this key to False. # If you are aware of what you are doing, then go ahead. raise_on_state_mismatch : bool = Field ( default = True , description = \"Raise error on state mismatch\" ) start_delay : int = Field ( default = 10 , description = \"Give a delay of few seconds before running this agent\" ) def get_agent ( self ): \"\"\" The Fallback factory method to use where the Agent instance depends on the configuration Returns: An agent subclass of Agent \"\"\" pass","title":"AgentConfig"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.description","text":"Multiline description of the agent in consideration","title":"description"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.is_sudo","text":"Setting this to true, requires the agent to run as root.","title":"is_sudo"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.name","text":"A one word identifier for the Agent.","title":"name"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.priority","text":"A priority assigned to the agent.","title":"priority"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.raise_on_state_mismatch","text":"Raise error on state mismatch","title":"raise_on_state_mismatch"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.start_delay","text":"Give a delay of few seconds before running this agent","title":"start_delay"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentConfig.get_agent","text":"The Fallback factory method to use where the Agent instance depends on the configuration Returns: Type Description An agent subclass of Agent Source code in agents/agent.py def get_agent ( self ): \"\"\" The Fallback factory method to use where the Agent instance depends on the configuration Returns: An agent subclass of Agent \"\"\" pass","title":"get_agent()"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentMonitoringDataPoint","text":"Source code in agents/agent.py class AgentMonitoringDataPoint ( BaseModel ): timestamp : datetime = Field ( default_factory = datetime . utcnow ) data : Dict [ str , Any ] = Field ( ... , description = \"Data from the agent at `timestamp` instant\" ) state : AgentState = Field ( description = \"The state of the agent at `timestamp` instant\" )","title":"AgentMonitoringDataPoint"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentMonitoringDataPoint.data","text":"Data from the agent at timestamp instant","title":"data"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentMonitoringDataPoint.state","text":"The state of the agent at timestamp instant","title":"state"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentPriority","text":"An enumeration. Source code in agents/agent.py class AgentPriority ( IntEnum ): VERY_HIGH_PRIORITY = 0 HIGH_PRIORITY = 1 MODERATE_PRIORITY = 2 LOW_PRIORITY = 3 VERY_LOW_PRIORITY = 4 UNDEFINED_PRIORITY = - 1","title":"AgentPriority"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.AgentState","text":"An enumeration. Source code in agents/agent.py class AgentState ( IntEnum ): SKIPPED = - 3 ABORTED = - 2 ERROR = - 1 UNDEFINED = 0 INIT = 1 SETUP = 2 RUNNING = 3 COMPLETED = 4 TEARDOWN = 5 DONE = 6","title":"AgentState"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.TimedAgentConfig","text":"The configuration of the agent which is constrained by a duration. This configuration is used for agents that are supposed to run for a particular amount of time before going to teardown state. Source code in agents/agent.py class TimedAgentConfig ( AgentConfig ): \"\"\" The configuration of the agent which is constrained by a duration. This configuration is used for agents that are supposed to run for a particular amount of time before going to teardown state. \"\"\" duration : int = Field ( default = 300 , description = \"The duration for which this agent should run\" , )","title":"TimedAgentConfig"},{"location":"package_docs/agents/agent/#ychaos.agents.agent.TimedAgentConfig.duration","text":"The duration for which this agent should run","title":"duration"},{"location":"package_docs/agents/contrib/","text":"ContribAgentConfig ( AgentConfig ) pydantic-model \u00b6 Source code in agents/contrib.py class ContribAgentConfig ( AgentConfig ): name = \"contrib\" path : Path = Field ( ... , description = \"The path of the agent python file\" ) agent_class : str = Field ( default = \"AgentClass\" , description = \"The class name of the contributed Agent\" ) agent_config_class : str = Field ( default = \"AgentConfigClass\" , description = \"The class name of the contributed Agent config\" , ) contrib_agent_config : Optional [ Dict [ Any , Any ]] = Field ( default = dict (), description = \"The configuration that will be passed to the community agent\" , ) # For storing imported module # Initialized late in the _import_module() method _module : Any = PrivateAttr () def __init__ ( self , ** kwargs ): super ( ContribAgentConfig , self ) . __init__ ( ** kwargs ) self . _import_module () # Validate that `config` adheres to the schema of the contrib agent self . contrib_agent_config = self . get_agent_config_class ()( ** self . contrib_agent_config ) def _import_module ( self ): specification = importlib . util . spec_from_file_location ( name = \"\" , location = self . path ) self . _module = importlib . util . module_from_spec ( specification ) assert self . _module is not None assert specification . loader is not None specification . loader . exec_module ( module = self . _module ) # type: ignore def get_agent_class ( self ) -> Any : agent_klass = getattr ( self . _module , self . agent_class ) assert issubclass ( agent_klass , Agent ) return agent_klass def get_agent_config_class ( self ) -> Any : agent_config_klass = getattr ( self . _module , self . agent_config_class ) assert issubclass ( agent_config_klass , AgentConfig ) return agent_config_klass def get_agent ( self ): return self . get_agent_class ()( self . contrib_agent_config ) agent_class : str pydantic-field \u00b6 The class name of the contributed Agent agent_config_class : str pydantic-field \u00b6 The class name of the contributed Agent config contrib_agent_config : Dict [ Any , Any ] pydantic-field \u00b6 The configuration that will be passed to the community agent path : Path pydantic-field required \u00b6 The path of the agent python file get_agent ( self ) \u00b6 The Fallback factory method to use where the Agent instance depends on the configuration Returns: Type Description An agent subclass of Agent Source code in agents/contrib.py def get_agent ( self ): return self . get_agent_class ()( self . contrib_agent_config )","title":"contrib"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig","text":"Source code in agents/contrib.py class ContribAgentConfig ( AgentConfig ): name = \"contrib\" path : Path = Field ( ... , description = \"The path of the agent python file\" ) agent_class : str = Field ( default = \"AgentClass\" , description = \"The class name of the contributed Agent\" ) agent_config_class : str = Field ( default = \"AgentConfigClass\" , description = \"The class name of the contributed Agent config\" , ) contrib_agent_config : Optional [ Dict [ Any , Any ]] = Field ( default = dict (), description = \"The configuration that will be passed to the community agent\" , ) # For storing imported module # Initialized late in the _import_module() method _module : Any = PrivateAttr () def __init__ ( self , ** kwargs ): super ( ContribAgentConfig , self ) . __init__ ( ** kwargs ) self . _import_module () # Validate that `config` adheres to the schema of the contrib agent self . contrib_agent_config = self . get_agent_config_class ()( ** self . contrib_agent_config ) def _import_module ( self ): specification = importlib . util . spec_from_file_location ( name = \"\" , location = self . path ) self . _module = importlib . util . module_from_spec ( specification ) assert self . _module is not None assert specification . loader is not None specification . loader . exec_module ( module = self . _module ) # type: ignore def get_agent_class ( self ) -> Any : agent_klass = getattr ( self . _module , self . agent_class ) assert issubclass ( agent_klass , Agent ) return agent_klass def get_agent_config_class ( self ) -> Any : agent_config_klass = getattr ( self . _module , self . agent_config_class ) assert issubclass ( agent_config_klass , AgentConfig ) return agent_config_klass def get_agent ( self ): return self . get_agent_class ()( self . contrib_agent_config )","title":"ContribAgentConfig"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig.agent_class","text":"The class name of the contributed Agent","title":"agent_class"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig.agent_config_class","text":"The class name of the contributed Agent config","title":"agent_config_class"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig.contrib_agent_config","text":"The configuration that will be passed to the community agent","title":"contrib_agent_config"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig.path","text":"The path of the agent python file","title":"path"},{"location":"package_docs/agents/contrib/#ychaos.agents.contrib.ContribAgentConfig.get_agent","text":"The Fallback factory method to use where the Agent instance depends on the configuration Returns: Type Description An agent subclass of Agent Source code in agents/contrib.py def get_agent ( self ): return self . get_agent_class ()( self . contrib_agent_config )","title":"get_agent()"},{"location":"package_docs/agents/coordinator/","text":"ConfiguredAgent \u00b6 Class to hold the configured Agent Source code in agents/coordinator.py class ConfiguredAgent : \"\"\" Class to hold the configured Agent \"\"\" def __init__ ( self , agent : Agent , start_time : Optional [ datetime ], end_time : Optional [ datetime ] ): \"\"\" Initialize ConfiguredAgent Args: agent: Agent object start_time: Agent execution start time end_time: Agent execution end time \"\"\" self . agent : Agent = agent self . start_time = start_time self . end_time = end_time self . agent_start_thread : Optional [ Thread ] = None self . agent_teardown_thread : Optional [ Thread ] = None __init__ ( self , agent , start_time , end_time ) special \u00b6 Initialize ConfiguredAgent Parameters: Name Type Description Default agent Agent Agent object required start_time Optional[datetime.datetime] Agent execution start time required end_time Optional[datetime.datetime] Agent execution end time required Source code in agents/coordinator.py def __init__ ( self , agent : Agent , start_time : Optional [ datetime ], end_time : Optional [ datetime ] ): \"\"\" Initialize ConfiguredAgent Args: agent: Agent object start_time: Agent execution start time end_time: Agent execution end time \"\"\" self . agent : Agent = agent self . start_time = start_time self . end_time = end_time self . agent_start_thread : Optional [ Thread ] = None self . agent_teardown_thread : Optional [ Thread ] = None Coordinator ( EventHook ) \u00b6 The coordinator is responsible for setting up the chaos agents, running the agents and monitor the agent currently being run. It also takes care of completing the attack by bringing back to the system to its original state. Coordinator Event Hooks \u00b6 on_attack_start called when attack is started on the host def callable_hook (): ... on_attack_completed called when attack is completed def callable_hook (): ... on_each_agent_start called when a Agent start executing def callable_hook ( agent_name : str ): ... on_each_agent_teardown called when a Agent Teardown is started def callable_hook ( agent_name : str ): ... on_each_agent_stop called when a Agent completes its execution and teardown step def callable_hook ( agent_name : str ): ... Source code in agents/coordinator.py class Coordinator ( EventHook ): \"\"\" The coordinator is responsible for setting up the chaos agents, running the agents and monitor the agent currently being run. It also takes care of completing the attack by bringing back to the system to its original state. ## Coordinator Event Hooks === \"on_attack_start\" called when attack is started on the host ```python def callable_hook(): ... ``` === \"on_attack_completed\" called when attack is completed ```python def callable_hook(): ... ``` === \"on_each_agent_start\" called when a Agent start executing ```python def callable_hook(agent_name: str): ... ``` === \"on_each_agent_teardown\" called when a Agent Teardown is started ```python def callable_hook(agent_name: str): ... ``` === \"on_each_agent_stop\" called when a Agent completes its execution and teardown step ```python def callable_hook(agent_name: str): ... ``` --- \"\"\" __hook_events__ = { \"on_attack_start\" : EventHook . CallableType (), \"on_attack_completed\" : EventHook . CallableType (), \"on_each_agent_start\" : EventHook . CallableType ( str ), \"on_each_agent_teardown\" : EventHook . CallableType ( str ), \"on_each_agent_stop\" : EventHook . CallableType ( str ), } DEFAULT_DURATION = 3 THREAD_TIMEOUT = 300 def __init__ ( self , test_plan : TestPlan ): super ( Coordinator , self ) . __init__ () self . test_plan : TestPlan = test_plan self . configured_agents : List [ ConfiguredAgent ] = [] self . attack_end_time : Optional [ datetime ] = None self . attack_start_time : Optional [ datetime ] = None self . exit_code = 0 self . log : Logger = AppLogger . get_logger ( __name__ ) def configure_agent_in_test_plan ( self ) -> List [ ConfiguredAgent ]: \"\"\" Configure all the Agents as specified in the test plan Returns: list of configured agents \"\"\" for agent in self . test_plan . attack . agents : next_start_time = datetime . now ( timezone . utc ) configured_agent : Agent if self . test_plan . attack . mode . value == AttackMode . SEQUENTIAL . value and len ( self . configured_agents ): assert self . configured_agents [ - 1 ] . end_time is not None next_start_time = self . configured_agents [ - 1 ] . end_time agent_config = agent . type . metadata . schema ( ** agent . config ) # type: ignore configured_agent = agent . type . metadata . agent_defn ( agent_config ) # type: ignore start_time : datetime = next_start_time + timedelta ( seconds = configured_agent . config . start_delay ) end_time : datetime = start_time + timedelta ( seconds = getattr ( configured_agent . config , \"duration\" , self . DEFAULT_DURATION ) ) self . configured_agents . append ( ConfiguredAgent ( configured_agent , start_time = start_time , end_time = end_time ) ) if self . test_plan . attack . mode . value != AttackMode . SEQUENTIAL . value : self . configured_agents . sort ( key = lambda current_agent : current_agent . end_time # type: ignore ) self . attack_end_time = self . configured_agents [ - 1 ] . end_time self . configured_agents . sort ( key = lambda current_agent : current_agent . start_time # type: ignore ) self . attack_start_time = self . configured_agents [ 0 ] . start_time else : self . attack_start_time = self . configured_agents [ 0 ] . start_time self . attack_end_time = self . configured_agents [ - 1 ] . end_time return self . configured_agents def get_exit_status ( self ) -> int : return self . exit_code def get_next_agent_for_attack ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for execution as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . INIT and current_time > configured_agent . start_time ): try : configured_agent . agent . setup () except Exception as e : configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) self . exit_code = 1 break else : return configured_agent return None def get_next_agent_for_teardown ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for teardown as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . RUNNING and current_time > configured_agent . end_time and not configured_agent . agent_teardown_thread ): return configured_agent return None def check_for_failed_agents ( self , agent : Optional [ Agent ] = None ) -> bool : \"\"\" check if any Agent has error Args: agent: check only this Agent has error Returns: True if Agent has error else False \"\"\" for configured_agent in self . configured_agents : if agent and agent != configured_agent . agent : continue if ( configured_agent . agent . current_state == AgentState . ERROR or not configured_agent . agent . exception . empty () ): configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True return True return False def stop_all_running_agents_in_sync ( self ): \"\"\" waits for all agents to complete teardown step \"\"\" for configured_agent in self . configured_agents : if ( configured_agent . agent . current_state == AgentState . SETUP or configured_agent . agent . current_state == AgentState . INIT ): configured_agent . agent . advance_state ( AgentState . SKIPPED ) elif configured_agent . agent . current_state == AgentState . ERROR : configured_agent . agent . preserved_state . has_error = True self . exit_code = 1 elif ( configured_agent . agent_start_thread and configured_agent . agent_start_thread . is_alive () and self . get_exit_status () ): configured_agent . agent . preserved_state . is_aborted = True configured_agent . agent . advance_state ( AgentState . ABORTED ) if ( not configured_agent . agent . current_state == AgentState . DONE and not configured_agent . agent . current_state == AgentState . SKIPPED ): try : if configured_agent . agent_teardown_thread : configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) else : configured_agent . agent_teardown_thread = ( configured_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , configured_agent . agent . config . name , ) configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) if ( configured_agent . agent_teardown_thread and configured_agent . agent_teardown_thread . is_alive () ): # pragma: no cover raise Exception ( f \"Agent: { configured_agent . agent . config . name } Teardown step failed to complete in { self . THREAD_TIMEOUT } \" ) if self . check_for_failed_agents ( configured_agent . agent ): raise configured_agent . agent . exception . get () except Exception as e : self . exit_code = 1 configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True self . execute_hooks ( \"on_each_agent_stop\" , configured_agent . agent . config . name , ) temp_exception_queue = Queue () while not configured_agent . agent . exception . empty (): # print all exceptions error = configured_agent . agent . exception . get () temp_exception_queue . put ( error ) self . log . error ( f \"Error occurred for the Agent= { configured_agent . agent . config . name } \" , exc_info = error , ) configured_agent . agent . exception = temp_exception_queue def get_all_exceptions ( self ) -> list : \"\"\" Get all the Exceptions occurred during the attack Returns: list of Exceptions \"\"\" all_exceptions = [] for configured_agent in self . configured_agents : temp_exception_queue : Queue = Queue () while not configured_agent . agent . exception . empty (): e = configured_agent . agent . exception . get () temp_exception_queue . put ( e ) all_exceptions . append ( e ) configured_agent . agent . exception = temp_exception_queue return all_exceptions def generate_attack_report ( self ) -> Dict : \"\"\" Generates attack report \"\"\" class AgentStatus ( BaseModel ): agent_name : str start_time : str end_time : str status : str class AttackReport ( BaseModel ): \"\"\" Attack Report Structure \"\"\" id : str host : str start_time : str expected_end_time : str mode : str agents : List [ AgentStatus ] report : AttackReport = AttackReport ( id = str ( self . test_plan . id ), host = os . uname ()[ 1 ], start_time = str ( self . attack_start_time ), expected_end_time = str ( self . attack_end_time ), mode = self . test_plan . attack . mode . value , agents = [], ) for configured_agent in self . configured_agents : agent = dict () agent [ \"agent_name\" ] = configured_agent . agent . config . name agent [ \"start_time\" ] = str ( configured_agent . start_time ) if hasattr ( configured_agent . agent . config , \"duration\" ): agent [ \"end_time\" ] = str ( configured_agent . end_time ) else : agent [ \"end_time\" ] = \"NaN\" if configured_agent . agent . preserved_state . has_error : agent [ \"status\" ] = AgentState . ERROR . name self . exit_code = 1 elif configured_agent . agent . preserved_state . is_aborted : agent [ \"status\" ] = AgentState . ABORTED . name else : agent [ \"status\" ] = configured_agent . agent . current_state . name report . agents . append ( AgentStatus ( ** agent )) return report . dict () def start_attack ( self ) -> int : \"\"\" Performs the attack as configured in testplan Returns: attack status - 0 if successful else 1 \"\"\" self . log . info ( \"Attack started\" ) self . execute_hooks ( \"on_attack_start\" ) assert self . attack_end_time is not None assert self . configured_agents is not None while datetime . now ( timezone . utc ) <= self . attack_end_time : current_agent = self . get_next_agent_for_attack () if current_agent : current_agent . agent_start_thread = current_agent . agent . start_async () self . execute_hooks ( \"on_each_agent_start\" , current_agent . agent . config . name , ) current_agent = self . get_next_agent_for_teardown () if current_agent : current_agent . agent_teardown_thread = ( current_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , current_agent . agent . config . name , ) sleep ( 1 ) if self . check_for_failed_agents (): self . exit_code = 1 break self . stop_all_running_agents_in_sync () if self . exit_code : self . log . info ( \"Attack failed\" ) else : self . log . info ( \"Attack Completed\" ) self . execute_hooks ( \"on_attack_completed\" ) return self . exit_code __hook_events__ : Dict [ str , Callable [ ... , NoneType ]] special \u00b6 Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered. check_for_failed_agents ( self , agent = None ) \u00b6 check if any Agent has error Parameters: Name Type Description Default agent Optional[ychaos.agents.agent.Agent] check only this Agent has error None Returns: Type Description bool True if Agent has error else False Source code in agents/coordinator.py def check_for_failed_agents ( self , agent : Optional [ Agent ] = None ) -> bool : \"\"\" check if any Agent has error Args: agent: check only this Agent has error Returns: True if Agent has error else False \"\"\" for configured_agent in self . configured_agents : if agent and agent != configured_agent . agent : continue if ( configured_agent . agent . current_state == AgentState . ERROR or not configured_agent . agent . exception . empty () ): configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True return True return False configure_agent_in_test_plan ( self ) \u00b6 Configure all the Agents as specified in the test plan Returns: Type Description List[ychaos.agents.coordinator.ConfiguredAgent] list of configured agents Source code in agents/coordinator.py def configure_agent_in_test_plan ( self ) -> List [ ConfiguredAgent ]: \"\"\" Configure all the Agents as specified in the test plan Returns: list of configured agents \"\"\" for agent in self . test_plan . attack . agents : next_start_time = datetime . now ( timezone . utc ) configured_agent : Agent if self . test_plan . attack . mode . value == AttackMode . SEQUENTIAL . value and len ( self . configured_agents ): assert self . configured_agents [ - 1 ] . end_time is not None next_start_time = self . configured_agents [ - 1 ] . end_time agent_config = agent . type . metadata . schema ( ** agent . config ) # type: ignore configured_agent = agent . type . metadata . agent_defn ( agent_config ) # type: ignore start_time : datetime = next_start_time + timedelta ( seconds = configured_agent . config . start_delay ) end_time : datetime = start_time + timedelta ( seconds = getattr ( configured_agent . config , \"duration\" , self . DEFAULT_DURATION ) ) self . configured_agents . append ( ConfiguredAgent ( configured_agent , start_time = start_time , end_time = end_time ) ) if self . test_plan . attack . mode . value != AttackMode . SEQUENTIAL . value : self . configured_agents . sort ( key = lambda current_agent : current_agent . end_time # type: ignore ) self . attack_end_time = self . configured_agents [ - 1 ] . end_time self . configured_agents . sort ( key = lambda current_agent : current_agent . start_time # type: ignore ) self . attack_start_time = self . configured_agents [ 0 ] . start_time else : self . attack_start_time = self . configured_agents [ 0 ] . start_time self . attack_end_time = self . configured_agents [ - 1 ] . end_time return self . configured_agents generate_attack_report ( self ) \u00b6 Generates attack report Source code in agents/coordinator.py def generate_attack_report ( self ) -> Dict : \"\"\" Generates attack report \"\"\" class AgentStatus ( BaseModel ): agent_name : str start_time : str end_time : str status : str class AttackReport ( BaseModel ): \"\"\" Attack Report Structure \"\"\" id : str host : str start_time : str expected_end_time : str mode : str agents : List [ AgentStatus ] report : AttackReport = AttackReport ( id = str ( self . test_plan . id ), host = os . uname ()[ 1 ], start_time = str ( self . attack_start_time ), expected_end_time = str ( self . attack_end_time ), mode = self . test_plan . attack . mode . value , agents = [], ) for configured_agent in self . configured_agents : agent = dict () agent [ \"agent_name\" ] = configured_agent . agent . config . name agent [ \"start_time\" ] = str ( configured_agent . start_time ) if hasattr ( configured_agent . agent . config , \"duration\" ): agent [ \"end_time\" ] = str ( configured_agent . end_time ) else : agent [ \"end_time\" ] = \"NaN\" if configured_agent . agent . preserved_state . has_error : agent [ \"status\" ] = AgentState . ERROR . name self . exit_code = 1 elif configured_agent . agent . preserved_state . is_aborted : agent [ \"status\" ] = AgentState . ABORTED . name else : agent [ \"status\" ] = configured_agent . agent . current_state . name report . agents . append ( AgentStatus ( ** agent )) return report . dict () get_all_exceptions ( self ) \u00b6 Get all the Exceptions occurred during the attack Returns: Type Description list list of Exceptions Source code in agents/coordinator.py def get_all_exceptions ( self ) -> list : \"\"\" Get all the Exceptions occurred during the attack Returns: list of Exceptions \"\"\" all_exceptions = [] for configured_agent in self . configured_agents : temp_exception_queue : Queue = Queue () while not configured_agent . agent . exception . empty (): e = configured_agent . agent . exception . get () temp_exception_queue . put ( e ) all_exceptions . append ( e ) configured_agent . agent . exception = temp_exception_queue return all_exceptions get_next_agent_for_attack ( self ) \u00b6 Get the next Agent for execution as configured in test plan Returns: Type Description Optional[ychaos.agents.coordinator.ConfiguredAgent] An Agent or None Source code in agents/coordinator.py def get_next_agent_for_attack ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for execution as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . INIT and current_time > configured_agent . start_time ): try : configured_agent . agent . setup () except Exception as e : configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) self . exit_code = 1 break else : return configured_agent return None get_next_agent_for_teardown ( self ) \u00b6 Get the next Agent for teardown as configured in test plan Returns: Type Description Optional[ychaos.agents.coordinator.ConfiguredAgent] An Agent or None Source code in agents/coordinator.py def get_next_agent_for_teardown ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for teardown as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . RUNNING and current_time > configured_agent . end_time and not configured_agent . agent_teardown_thread ): return configured_agent return None start_attack ( self ) \u00b6 Performs the attack as configured in testplan Returns: Type Description int attack status - 0 if successful else 1 Source code in agents/coordinator.py def start_attack ( self ) -> int : \"\"\" Performs the attack as configured in testplan Returns: attack status - 0 if successful else 1 \"\"\" self . log . info ( \"Attack started\" ) self . execute_hooks ( \"on_attack_start\" ) assert self . attack_end_time is not None assert self . configured_agents is not None while datetime . now ( timezone . utc ) <= self . attack_end_time : current_agent = self . get_next_agent_for_attack () if current_agent : current_agent . agent_start_thread = current_agent . agent . start_async () self . execute_hooks ( \"on_each_agent_start\" , current_agent . agent . config . name , ) current_agent = self . get_next_agent_for_teardown () if current_agent : current_agent . agent_teardown_thread = ( current_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , current_agent . agent . config . name , ) sleep ( 1 ) if self . check_for_failed_agents (): self . exit_code = 1 break self . stop_all_running_agents_in_sync () if self . exit_code : self . log . info ( \"Attack failed\" ) else : self . log . info ( \"Attack Completed\" ) self . execute_hooks ( \"on_attack_completed\" ) return self . exit_code stop_all_running_agents_in_sync ( self ) \u00b6 waits for all agents to complete teardown step Source code in agents/coordinator.py def stop_all_running_agents_in_sync ( self ): \"\"\" waits for all agents to complete teardown step \"\"\" for configured_agent in self . configured_agents : if ( configured_agent . agent . current_state == AgentState . SETUP or configured_agent . agent . current_state == AgentState . INIT ): configured_agent . agent . advance_state ( AgentState . SKIPPED ) elif configured_agent . agent . current_state == AgentState . ERROR : configured_agent . agent . preserved_state . has_error = True self . exit_code = 1 elif ( configured_agent . agent_start_thread and configured_agent . agent_start_thread . is_alive () and self . get_exit_status () ): configured_agent . agent . preserved_state . is_aborted = True configured_agent . agent . advance_state ( AgentState . ABORTED ) if ( not configured_agent . agent . current_state == AgentState . DONE and not configured_agent . agent . current_state == AgentState . SKIPPED ): try : if configured_agent . agent_teardown_thread : configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) else : configured_agent . agent_teardown_thread = ( configured_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , configured_agent . agent . config . name , ) configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) if ( configured_agent . agent_teardown_thread and configured_agent . agent_teardown_thread . is_alive () ): # pragma: no cover raise Exception ( f \"Agent: { configured_agent . agent . config . name } Teardown step failed to complete in { self . THREAD_TIMEOUT } \" ) if self . check_for_failed_agents ( configured_agent . agent ): raise configured_agent . agent . exception . get () except Exception as e : self . exit_code = 1 configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True self . execute_hooks ( \"on_each_agent_stop\" , configured_agent . agent . config . name , ) temp_exception_queue = Queue () while not configured_agent . agent . exception . empty (): # print all exceptions error = configured_agent . agent . exception . get () temp_exception_queue . put ( error ) self . log . error ( f \"Error occurred for the Agent= { configured_agent . agent . config . name } \" , exc_info = error , ) configured_agent . agent . exception = temp_exception_queue","title":"coordinator"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.ConfiguredAgent","text":"Class to hold the configured Agent Source code in agents/coordinator.py class ConfiguredAgent : \"\"\" Class to hold the configured Agent \"\"\" def __init__ ( self , agent : Agent , start_time : Optional [ datetime ], end_time : Optional [ datetime ] ): \"\"\" Initialize ConfiguredAgent Args: agent: Agent object start_time: Agent execution start time end_time: Agent execution end time \"\"\" self . agent : Agent = agent self . start_time = start_time self . end_time = end_time self . agent_start_thread : Optional [ Thread ] = None self . agent_teardown_thread : Optional [ Thread ] = None","title":"ConfiguredAgent"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.ConfiguredAgent.__init__","text":"Initialize ConfiguredAgent Parameters: Name Type Description Default agent Agent Agent object required start_time Optional[datetime.datetime] Agent execution start time required end_time Optional[datetime.datetime] Agent execution end time required Source code in agents/coordinator.py def __init__ ( self , agent : Agent , start_time : Optional [ datetime ], end_time : Optional [ datetime ] ): \"\"\" Initialize ConfiguredAgent Args: agent: Agent object start_time: Agent execution start time end_time: Agent execution end time \"\"\" self . agent : Agent = agent self . start_time = start_time self . end_time = end_time self . agent_start_thread : Optional [ Thread ] = None self . agent_teardown_thread : Optional [ Thread ] = None","title":"__init__()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator","text":"The coordinator is responsible for setting up the chaos agents, running the agents and monitor the agent currently being run. It also takes care of completing the attack by bringing back to the system to its original state.","title":"Coordinator"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.__hook_events__","text":"Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered.","title":"__hook_events__"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.check_for_failed_agents","text":"check if any Agent has error Parameters: Name Type Description Default agent Optional[ychaos.agents.agent.Agent] check only this Agent has error None Returns: Type Description bool True if Agent has error else False Source code in agents/coordinator.py def check_for_failed_agents ( self , agent : Optional [ Agent ] = None ) -> bool : \"\"\" check if any Agent has error Args: agent: check only this Agent has error Returns: True if Agent has error else False \"\"\" for configured_agent in self . configured_agents : if agent and agent != configured_agent . agent : continue if ( configured_agent . agent . current_state == AgentState . ERROR or not configured_agent . agent . exception . empty () ): configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True return True return False","title":"check_for_failed_agents()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.configure_agent_in_test_plan","text":"Configure all the Agents as specified in the test plan Returns: Type Description List[ychaos.agents.coordinator.ConfiguredAgent] list of configured agents Source code in agents/coordinator.py def configure_agent_in_test_plan ( self ) -> List [ ConfiguredAgent ]: \"\"\" Configure all the Agents as specified in the test plan Returns: list of configured agents \"\"\" for agent in self . test_plan . attack . agents : next_start_time = datetime . now ( timezone . utc ) configured_agent : Agent if self . test_plan . attack . mode . value == AttackMode . SEQUENTIAL . value and len ( self . configured_agents ): assert self . configured_agents [ - 1 ] . end_time is not None next_start_time = self . configured_agents [ - 1 ] . end_time agent_config = agent . type . metadata . schema ( ** agent . config ) # type: ignore configured_agent = agent . type . metadata . agent_defn ( agent_config ) # type: ignore start_time : datetime = next_start_time + timedelta ( seconds = configured_agent . config . start_delay ) end_time : datetime = start_time + timedelta ( seconds = getattr ( configured_agent . config , \"duration\" , self . DEFAULT_DURATION ) ) self . configured_agents . append ( ConfiguredAgent ( configured_agent , start_time = start_time , end_time = end_time ) ) if self . test_plan . attack . mode . value != AttackMode . SEQUENTIAL . value : self . configured_agents . sort ( key = lambda current_agent : current_agent . end_time # type: ignore ) self . attack_end_time = self . configured_agents [ - 1 ] . end_time self . configured_agents . sort ( key = lambda current_agent : current_agent . start_time # type: ignore ) self . attack_start_time = self . configured_agents [ 0 ] . start_time else : self . attack_start_time = self . configured_agents [ 0 ] . start_time self . attack_end_time = self . configured_agents [ - 1 ] . end_time return self . configured_agents","title":"configure_agent_in_test_plan()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.generate_attack_report","text":"Generates attack report Source code in agents/coordinator.py def generate_attack_report ( self ) -> Dict : \"\"\" Generates attack report \"\"\" class AgentStatus ( BaseModel ): agent_name : str start_time : str end_time : str status : str class AttackReport ( BaseModel ): \"\"\" Attack Report Structure \"\"\" id : str host : str start_time : str expected_end_time : str mode : str agents : List [ AgentStatus ] report : AttackReport = AttackReport ( id = str ( self . test_plan . id ), host = os . uname ()[ 1 ], start_time = str ( self . attack_start_time ), expected_end_time = str ( self . attack_end_time ), mode = self . test_plan . attack . mode . value , agents = [], ) for configured_agent in self . configured_agents : agent = dict () agent [ \"agent_name\" ] = configured_agent . agent . config . name agent [ \"start_time\" ] = str ( configured_agent . start_time ) if hasattr ( configured_agent . agent . config , \"duration\" ): agent [ \"end_time\" ] = str ( configured_agent . end_time ) else : agent [ \"end_time\" ] = \"NaN\" if configured_agent . agent . preserved_state . has_error : agent [ \"status\" ] = AgentState . ERROR . name self . exit_code = 1 elif configured_agent . agent . preserved_state . is_aborted : agent [ \"status\" ] = AgentState . ABORTED . name else : agent [ \"status\" ] = configured_agent . agent . current_state . name report . agents . append ( AgentStatus ( ** agent )) return report . dict ()","title":"generate_attack_report()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.get_all_exceptions","text":"Get all the Exceptions occurred during the attack Returns: Type Description list list of Exceptions Source code in agents/coordinator.py def get_all_exceptions ( self ) -> list : \"\"\" Get all the Exceptions occurred during the attack Returns: list of Exceptions \"\"\" all_exceptions = [] for configured_agent in self . configured_agents : temp_exception_queue : Queue = Queue () while not configured_agent . agent . exception . empty (): e = configured_agent . agent . exception . get () temp_exception_queue . put ( e ) all_exceptions . append ( e ) configured_agent . agent . exception = temp_exception_queue return all_exceptions","title":"get_all_exceptions()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.get_next_agent_for_attack","text":"Get the next Agent for execution as configured in test plan Returns: Type Description Optional[ychaos.agents.coordinator.ConfiguredAgent] An Agent or None Source code in agents/coordinator.py def get_next_agent_for_attack ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for execution as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . INIT and current_time > configured_agent . start_time ): try : configured_agent . agent . setup () except Exception as e : configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) self . exit_code = 1 break else : return configured_agent return None","title":"get_next_agent_for_attack()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.get_next_agent_for_teardown","text":"Get the next Agent for teardown as configured in test plan Returns: Type Description Optional[ychaos.agents.coordinator.ConfiguredAgent] An Agent or None Source code in agents/coordinator.py def get_next_agent_for_teardown ( self ) -> Optional [ ConfiguredAgent ]: \"\"\" Get the next Agent for teardown as configured in test plan Returns: An Agent or None \"\"\" current_time : datetime = datetime . now ( timezone . utc ) for configured_agent in self . configured_agents : assert configured_agent . start_time is not None assert configured_agent . end_time is not None if ( configured_agent . agent . current_state == AgentState . RUNNING and current_time > configured_agent . end_time and not configured_agent . agent_teardown_thread ): return configured_agent return None","title":"get_next_agent_for_teardown()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.start_attack","text":"Performs the attack as configured in testplan Returns: Type Description int attack status - 0 if successful else 1 Source code in agents/coordinator.py def start_attack ( self ) -> int : \"\"\" Performs the attack as configured in testplan Returns: attack status - 0 if successful else 1 \"\"\" self . log . info ( \"Attack started\" ) self . execute_hooks ( \"on_attack_start\" ) assert self . attack_end_time is not None assert self . configured_agents is not None while datetime . now ( timezone . utc ) <= self . attack_end_time : current_agent = self . get_next_agent_for_attack () if current_agent : current_agent . agent_start_thread = current_agent . agent . start_async () self . execute_hooks ( \"on_each_agent_start\" , current_agent . agent . config . name , ) current_agent = self . get_next_agent_for_teardown () if current_agent : current_agent . agent_teardown_thread = ( current_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , current_agent . agent . config . name , ) sleep ( 1 ) if self . check_for_failed_agents (): self . exit_code = 1 break self . stop_all_running_agents_in_sync () if self . exit_code : self . log . info ( \"Attack failed\" ) else : self . log . info ( \"Attack Completed\" ) self . execute_hooks ( \"on_attack_completed\" ) return self . exit_code","title":"start_attack()"},{"location":"package_docs/agents/coordinator/#ychaos.agents.coordinator.Coordinator.stop_all_running_agents_in_sync","text":"waits for all agents to complete teardown step Source code in agents/coordinator.py def stop_all_running_agents_in_sync ( self ): \"\"\" waits for all agents to complete teardown step \"\"\" for configured_agent in self . configured_agents : if ( configured_agent . agent . current_state == AgentState . SETUP or configured_agent . agent . current_state == AgentState . INIT ): configured_agent . agent . advance_state ( AgentState . SKIPPED ) elif configured_agent . agent . current_state == AgentState . ERROR : configured_agent . agent . preserved_state . has_error = True self . exit_code = 1 elif ( configured_agent . agent_start_thread and configured_agent . agent_start_thread . is_alive () and self . get_exit_status () ): configured_agent . agent . preserved_state . is_aborted = True configured_agent . agent . advance_state ( AgentState . ABORTED ) if ( not configured_agent . agent . current_state == AgentState . DONE and not configured_agent . agent . current_state == AgentState . SKIPPED ): try : if configured_agent . agent_teardown_thread : configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) else : configured_agent . agent_teardown_thread = ( configured_agent . agent . teardown_async () ) self . execute_hooks ( \"on_each_agent_teardown\" , configured_agent . agent . config . name , ) configured_agent . agent_teardown_thread . join ( timeout = self . THREAD_TIMEOUT ) if ( configured_agent . agent_teardown_thread and configured_agent . agent_teardown_thread . is_alive () ): # pragma: no cover raise Exception ( f \"Agent: { configured_agent . agent . config . name } Teardown step failed to complete in { self . THREAD_TIMEOUT } \" ) if self . check_for_failed_agents ( configured_agent . agent ): raise configured_agent . agent . exception . get () except Exception as e : self . exit_code = 1 configured_agent . agent . exception . put ( e ) configured_agent . agent . advance_state ( AgentState . ERROR ) configured_agent . agent . preserved_state . has_error = True self . execute_hooks ( \"on_each_agent_stop\" , configured_agent . agent . config . name , ) temp_exception_queue = Queue () while not configured_agent . agent . exception . empty (): # print all exceptions error = configured_agent . agent . exception . get () temp_exception_queue . put ( error ) self . log . error ( f \"Error occurred for the Agent= { configured_agent . agent . config . name } \" , exc_info = error , ) configured_agent . agent . exception = temp_exception_queue","title":"stop_all_running_agents_in_sync()"},{"location":"package_docs/agents/network/iptables/","text":"DNSBlock ( Agent ) \u00b6 Source code in agents/network/iptables.py class DNSBlock ( Agent ): DNS_PORT = 53 @validate_arguments def __init__ ( self , config : DNSBlockConfig ): super ( DNSBlock , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( DNSBlock , self ) . setup () @staticmethod def raise_io_error_on_iptables_failure ( proc : subprocess . CompletedProcess , message ): if proc . returncode != 0 : raise IOError ( message ) @log_agent_lifecycle def run ( self ): super ( DNSBlock , self ) . run () _cmd = f \"sudo iptables -I OUTPUT -p udp --dport { self . DNS_PORT } -j DROP -w { shlex . quote ( str ( self . config . iptables_wait )) } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , \"Error While Adding IPTables Rule: DROP udp port: 53 to OUTPUT chain\" ) _cmd = f \"sudo iptables -I OUTPUT -p tcp --dport { self . DNS_PORT } -j DROP -w { shlex . quote ( str ( self . config . iptables_wait )) } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , \"Error While Adding IpTable Rule: DROP tcp port: 53 to OUTPUT Chain\" ) @log_agent_lifecycle def teardown ( self ) -> None : _current_state_temporary = self . current_state super ( DNSBlock , self ) . teardown () error = False if _current_state_temporary in ( AgentState . RUNNING , AgentState . ERROR , AgentState . ABORTED , ): _cmd = f \"sudo iptables -D OUTPUT -p udp --dport { self . DNS_PORT } -j DROP -w { self . config . iptables_wait } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error _cmd = f \"sudo iptables -D OUTPUT -p tcp --dport { self . DNS_PORT } -j DROP -w { self . config . iptables_wait } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error if error : raise AgentError ( \"Error Occurred while removing iptables rule\" ) monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/iptables.py def monitor ( self ) -> LifoQueue : return self . _status DNSBlockConfig ( TimedAgentConfig ) pydantic-model \u00b6 Source code in agents/network/iptables.py class DNSBlockConfig ( TimedAgentConfig ): name = \"dns_block\" desc = \"This agent modifies the iptables rules to block traffic to DNS ports\" is_sudo = True iptables_wait : int = Field ( description = ( \"The duration(in secs) for the agent waits to achieve the wait for the iptables command to achieve exclusive lock. \" \"This corresponds to -w option in iptables command\" ), default = 3 , lt = 60 , gt = 0 , ) iptables_wait : ConstrainedIntValue pydantic-field \u00b6 The duration(in secs) for the agent waits to achieve the wait for the iptables command to achieve exclusive lock. This corresponds to -w option in iptables command IPTablesBlock ( Agent ) \u00b6 Source code in agents/network/iptables.py class IPTablesBlock ( Agent ): @validate_arguments def __init__ ( self , config : IPTablesBlockConfig ): super ( IPTablesBlock , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( IPTablesBlock , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( IPTablesBlock , self ) . setup () @staticmethod def raise_io_error_on_iptables_failure ( proc : subprocess . CompletedProcess , message ): if proc . returncode != 0 : raise IOError ( message ) @log_agent_lifecycle def run ( self ) -> None : super ( IPTablesBlock , self ) . run () for port in self . config . incoming_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { port } to INPUT Chain\" ) for port in self . config . destination_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { port } to OUTPUT Chain\" ) for endpoint in self . config . incoming_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) for endpoint in self . config . outgoing_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) @log_agent_lifecycle def teardown ( self ) -> None : super ( IPTablesBlock , self ) . teardown () error = False for port in self . config . incoming_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . INPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error for port in self . config . destination_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . OUTPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error for endpoint in self . config . incoming_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . INPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . OUTPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error if error : raise AgentError ( \"Error Occurred while removing IpTable rule\" ) monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/iptables.py def monitor ( self ) -> LifoQueue : super ( IPTablesBlock , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), state = self . current_state , ) ) return self . _status IPTablesBlockConfig ( TimedAgentConfig ) pydantic-model \u00b6 Source code in agents/network/iptables.py class IPTablesBlockConfig ( TimedAgentConfig ): name = \"iptables_block\" desc = \"This agent modifies the iptables rules to block traffic to specified ports or endpoint\" is_sudo = True incoming_ports : Optional [ List [ int ]] = Field ( description = \"List of incoming ports to block\" , default = list (), examples = [[ 3000 , 4443 ]], ) iptables_wait : int = Field ( description = ( \"Wait for the lock in seconds. To prevent multiple instances of the program from running concurrently, \" \"an attempt will be made to obtain an exclusive lock at launch\" ), default = 3 , examples = [ 500 , 450 , 120 ], lt = 1800 , gt = 0 , ) destination_ports : Optional [ List [ int ]] = Field ( description = \"List of destination ports to block\" , default = list (), examples = [[ 3000 , 4443 ]], ) incoming_endpoints : List [ Union [ IPvAnyNetwork , AnyHttpUrl , IPvAnyAddress ]] = Field ( description = \"List of incoming endpoint to block\" , default = list (), examples = [ \"203.0.113.0\" , \"https://yahoo.com:443\" ], ) outgoing_endpoints : Optional [ List [ Union [ IPvAnyNetwork , AnyHttpUrl , IPvAnyAddress ]] ] = Field ( description = \"List of outgoing endpoint to block\" , default = list (), examples = [ \"203.0.113.0\" , \"https://yahoo.com:443\" ], ) destination_ports : List [ int ] pydantic-field \u00b6 List of destination ports to block incoming_endpoints : List [ Union [ pydantic . networks . IPvAnyNetwork , pydantic . networks . AnyHttpUrl , pydantic . networks . IPvAnyAddress ]] pydantic-field \u00b6 List of incoming endpoint to block incoming_ports : List [ int ] pydantic-field \u00b6 List of incoming ports to block iptables_wait : ConstrainedIntValue pydantic-field \u00b6 Wait for the lock in seconds. To prevent multiple instances of the program from running concurrently, an attempt will be made to obtain an exclusive lock at launch outgoing_endpoints : List [ Union [ pydantic . networks . IPvAnyNetwork , pydantic . networks . AnyHttpUrl , pydantic . networks . IPvAnyAddress ]] pydantic-field \u00b6 List of outgoing endpoint to block IptablesChain ( Enum ) \u00b6 An enumeration. Source code in agents/network/iptables.py class IptablesChain ( Enum ): OUTPUT = \"OUTPUT\" INPUT = \"INPUT\" IptablesRuleOperation ( Enum ) \u00b6 An enumeration. Source code in agents/network/iptables.py class IptablesRuleOperation ( Enum ): INSERT = \"-I\" DELETE = \"-D\"","title":"iptables"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.DNSBlock","text":"Source code in agents/network/iptables.py class DNSBlock ( Agent ): DNS_PORT = 53 @validate_arguments def __init__ ( self , config : DNSBlockConfig ): super ( DNSBlock , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( DNSBlock , self ) . setup () @staticmethod def raise_io_error_on_iptables_failure ( proc : subprocess . CompletedProcess , message ): if proc . returncode != 0 : raise IOError ( message ) @log_agent_lifecycle def run ( self ): super ( DNSBlock , self ) . run () _cmd = f \"sudo iptables -I OUTPUT -p udp --dport { self . DNS_PORT } -j DROP -w { shlex . quote ( str ( self . config . iptables_wait )) } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , \"Error While Adding IPTables Rule: DROP udp port: 53 to OUTPUT chain\" ) _cmd = f \"sudo iptables -I OUTPUT -p tcp --dport { self . DNS_PORT } -j DROP -w { shlex . quote ( str ( self . config . iptables_wait )) } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , \"Error While Adding IpTable Rule: DROP tcp port: 53 to OUTPUT Chain\" ) @log_agent_lifecycle def teardown ( self ) -> None : _current_state_temporary = self . current_state super ( DNSBlock , self ) . teardown () error = False if _current_state_temporary in ( AgentState . RUNNING , AgentState . ERROR , AgentState . ABORTED , ): _cmd = f \"sudo iptables -D OUTPUT -p udp --dport { self . DNS_PORT } -j DROP -w { self . config . iptables_wait } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error _cmd = f \"sudo iptables -D OUTPUT -p tcp --dport { self . DNS_PORT } -j DROP -w { self . config . iptables_wait } \" . split () proc = subprocess . run ( # nosec _cmd , stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error if error : raise AgentError ( \"Error Occurred while removing iptables rule\" )","title":"DNSBlock"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.DNSBlock.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/iptables.py def monitor ( self ) -> LifoQueue : return self . _status","title":"monitor()"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.DNSBlockConfig","text":"Source code in agents/network/iptables.py class DNSBlockConfig ( TimedAgentConfig ): name = \"dns_block\" desc = \"This agent modifies the iptables rules to block traffic to DNS ports\" is_sudo = True iptables_wait : int = Field ( description = ( \"The duration(in secs) for the agent waits to achieve the wait for the iptables command to achieve exclusive lock. \" \"This corresponds to -w option in iptables command\" ), default = 3 , lt = 60 , gt = 0 , )","title":"DNSBlockConfig"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.DNSBlockConfig.iptables_wait","text":"The duration(in secs) for the agent waits to achieve the wait for the iptables command to achieve exclusive lock. This corresponds to -w option in iptables command","title":"iptables_wait"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlock","text":"Source code in agents/network/iptables.py class IPTablesBlock ( Agent ): @validate_arguments def __init__ ( self , config : IPTablesBlockConfig ): super ( IPTablesBlock , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( IPTablesBlock , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( IPTablesBlock , self ) . setup () @staticmethod def raise_io_error_on_iptables_failure ( proc : subprocess . CompletedProcess , message ): if proc . returncode != 0 : raise IOError ( message ) @log_agent_lifecycle def run ( self ) -> None : super ( IPTablesBlock , self ) . run () for port in self . config . incoming_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { port } to INPUT Chain\" ) for port in self . config . destination_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { port } to OUTPUT Chain\" ) for endpoint in self . config . incoming_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . INPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) for endpoint in self . config . outgoing_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . INSERT . value , IptablesChain . OUTPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) self . raise_io_error_on_iptables_failure ( proc , f \"Error While Adding IpTable Rule: DROP { endpoint } to INPUT Chain\" , ) @log_agent_lifecycle def teardown ( self ) -> None : super ( IPTablesBlock , self ) . teardown () error = False for port in self . config . incoming_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . INPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error for port in self . config . destination_ports : proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . OUTPUT . value , port , None , self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error for endpoint in self . config . incoming_endpoints : if isinstance ( endpoint , AnyHttpUrl ): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . INPUT . value , endpoint . port , str ( endpoint . host ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error elif isinstance ( endpoint , ( IPv4Network , IPv4Address )): proc = subprocess . run ( # nosec using shlex iptables_command_builder ( IptablesRuleOperation . DELETE . value , IptablesChain . OUTPUT . value , None , str ( endpoint ), self . config . iptables_wait , ) . split (), stdout = subprocess . PIPE , stderr = subprocess . PIPE , ) error = proc . returncode != 0 or error if error : raise AgentError ( \"Error Occurred while removing IpTable rule\" )","title":"IPTablesBlock"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlock.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/iptables.py def monitor ( self ) -> LifoQueue : super ( IPTablesBlock , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), state = self . current_state , ) ) return self . _status","title":"monitor()"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig","text":"Source code in agents/network/iptables.py class IPTablesBlockConfig ( TimedAgentConfig ): name = \"iptables_block\" desc = \"This agent modifies the iptables rules to block traffic to specified ports or endpoint\" is_sudo = True incoming_ports : Optional [ List [ int ]] = Field ( description = \"List of incoming ports to block\" , default = list (), examples = [[ 3000 , 4443 ]], ) iptables_wait : int = Field ( description = ( \"Wait for the lock in seconds. To prevent multiple instances of the program from running concurrently, \" \"an attempt will be made to obtain an exclusive lock at launch\" ), default = 3 , examples = [ 500 , 450 , 120 ], lt = 1800 , gt = 0 , ) destination_ports : Optional [ List [ int ]] = Field ( description = \"List of destination ports to block\" , default = list (), examples = [[ 3000 , 4443 ]], ) incoming_endpoints : List [ Union [ IPvAnyNetwork , AnyHttpUrl , IPvAnyAddress ]] = Field ( description = \"List of incoming endpoint to block\" , default = list (), examples = [ \"203.0.113.0\" , \"https://yahoo.com:443\" ], ) outgoing_endpoints : Optional [ List [ Union [ IPvAnyNetwork , AnyHttpUrl , IPvAnyAddress ]] ] = Field ( description = \"List of outgoing endpoint to block\" , default = list (), examples = [ \"203.0.113.0\" , \"https://yahoo.com:443\" ], )","title":"IPTablesBlockConfig"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig.destination_ports","text":"List of destination ports to block","title":"destination_ports"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig.incoming_endpoints","text":"List of incoming endpoint to block","title":"incoming_endpoints"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig.incoming_ports","text":"List of incoming ports to block","title":"incoming_ports"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig.iptables_wait","text":"Wait for the lock in seconds. To prevent multiple instances of the program from running concurrently, an attempt will be made to obtain an exclusive lock at launch","title":"iptables_wait"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IPTablesBlockConfig.outgoing_endpoints","text":"List of outgoing endpoint to block","title":"outgoing_endpoints"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IptablesChain","text":"An enumeration. Source code in agents/network/iptables.py class IptablesChain ( Enum ): OUTPUT = \"OUTPUT\" INPUT = \"INPUT\"","title":"IptablesChain"},{"location":"package_docs/agents/network/iptables/#ychaos.agents.network.iptables.IptablesRuleOperation","text":"An enumeration. Source code in agents/network/iptables.py class IptablesRuleOperation ( Enum ): INSERT = \"-I\" DELETE = \"-D\"","title":"IptablesRuleOperation"},{"location":"package_docs/agents/network/traffic/","text":"TrafficBlock ( Agent ) \u00b6 Source code in agents/network/traffic.py class TrafficBlock ( Agent ): LOCALHOST = \"127.0.0.1\" permission = int () @validate_arguments def __init__ ( self , config : TrafficBlockConfig ): super ( TrafficBlock , self ) . __init__ ( config ) if config . backup_hostsfile is None : config . backup_hostsfile = Path ( NamedTemporaryFile ( mode = \"w+\" , delete = False ) . name ) def monitor ( self ) -> LifoQueue : super ( TrafficBlock , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( TrafficBlock , self ) . setup () shutil . copy ( self . config . hostsfile , self . config . backup_hostsfile ) # Makes the Backup File as Read Only. This is a protection from # backup file getting deleted/modified accidentally. The file can still # be modified with root access. self . permission = Path ( self . config . backup_hostsfile ) . lstat () . st_mode Path ( self . config . backup_hostsfile ) . chmod ( S_IREAD | S_IRGRP | S_IROTH ) @log_agent_lifecycle def run ( self ) -> None : super ( TrafficBlock , self ) . run () with open ( self . config . hostsfile , \"a\" ) as hosts_file : hosts_file . write ( \" \\n \" ) for host in self . config . hosts : hosts_file . write ( f \" { self . LOCALHOST } \\t { host } \\n \" ) @log_agent_lifecycle def teardown ( self ) -> None : super ( TrafficBlock , self ) . teardown () # Restore the permissions for the file and move it to original location self . config . backup_hostsfile . chmod ( self . permission ) shutil . copy ( self . config . backup_hostsfile , self . config . hostsfile ) # Delete the backup hostsfile self . config . backup_hostsfile . unlink () monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/traffic.py def monitor ( self ) -> LifoQueue : super ( TrafficBlock , self ) . monitor () return self . _status TrafficBlockConfig ( TimedAgentConfig ) pydantic-model \u00b6 Source code in agents/network/traffic.py class TrafficBlockConfig ( TimedAgentConfig ): name = \"traffic_block\" description = \"This agent modifies the the hosts /etc/hosts file to block traffic to certain hostnames\" is_sudo = True hostsfile : Path = Field ( description = \"The Filepath of hosts file\" , default = Path ( \"/etc/hosts\" ) ) backup_hostsfile : Optional [ Path ] = Field ( description = \"The filepath to store backup of hosts file. By default, the agent will create temporary file\" , default = None , ) hosts : List [ str ] = Field ( description = \"List of destination outbound hostnames to block\" , default = list (), examples = [[ \"yahoo.com\" , \"google.com\" ]], ) backup_hostsfile : Path pydantic-field \u00b6 The filepath to store backup of hosts file. By default, the agent will create temporary file hosts : List [ str ] pydantic-field \u00b6 List of destination outbound hostnames to block hostsfile : Path pydantic-field \u00b6 The Filepath of hosts file","title":"traffic"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlock","text":"Source code in agents/network/traffic.py class TrafficBlock ( Agent ): LOCALHOST = \"127.0.0.1\" permission = int () @validate_arguments def __init__ ( self , config : TrafficBlockConfig ): super ( TrafficBlock , self ) . __init__ ( config ) if config . backup_hostsfile is None : config . backup_hostsfile = Path ( NamedTemporaryFile ( mode = \"w+\" , delete = False ) . name ) def monitor ( self ) -> LifoQueue : super ( TrafficBlock , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( TrafficBlock , self ) . setup () shutil . copy ( self . config . hostsfile , self . config . backup_hostsfile ) # Makes the Backup File as Read Only. This is a protection from # backup file getting deleted/modified accidentally. The file can still # be modified with root access. self . permission = Path ( self . config . backup_hostsfile ) . lstat () . st_mode Path ( self . config . backup_hostsfile ) . chmod ( S_IREAD | S_IRGRP | S_IROTH ) @log_agent_lifecycle def run ( self ) -> None : super ( TrafficBlock , self ) . run () with open ( self . config . hostsfile , \"a\" ) as hosts_file : hosts_file . write ( \" \\n \" ) for host in self . config . hosts : hosts_file . write ( f \" { self . LOCALHOST } \\t { host } \\n \" ) @log_agent_lifecycle def teardown ( self ) -> None : super ( TrafficBlock , self ) . teardown () # Restore the permissions for the file and move it to original location self . config . backup_hostsfile . chmod ( self . permission ) shutil . copy ( self . config . backup_hostsfile , self . config . hostsfile ) # Delete the backup hostsfile self . config . backup_hostsfile . unlink ()","title":"TrafficBlock"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlock.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/network/traffic.py def monitor ( self ) -> LifoQueue : super ( TrafficBlock , self ) . monitor () return self . _status","title":"monitor()"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlockConfig","text":"Source code in agents/network/traffic.py class TrafficBlockConfig ( TimedAgentConfig ): name = \"traffic_block\" description = \"This agent modifies the the hosts /etc/hosts file to block traffic to certain hostnames\" is_sudo = True hostsfile : Path = Field ( description = \"The Filepath of hosts file\" , default = Path ( \"/etc/hosts\" ) ) backup_hostsfile : Optional [ Path ] = Field ( description = \"The filepath to store backup of hosts file. By default, the agent will create temporary file\" , default = None , ) hosts : List [ str ] = Field ( description = \"List of destination outbound hostnames to block\" , default = list (), examples = [[ \"yahoo.com\" , \"google.com\" ]], )","title":"TrafficBlockConfig"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlockConfig.backup_hostsfile","text":"The filepath to store backup of hosts file. By default, the agent will create temporary file","title":"backup_hostsfile"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlockConfig.hosts","text":"List of destination outbound hostnames to block","title":"hosts"},{"location":"package_docs/agents/network/traffic/#ychaos.agents.network.traffic.TrafficBlockConfig.hostsfile","text":"The Filepath of hosts file","title":"hostsfile"},{"location":"package_docs/agents/system/cpu/","text":"CPUBurn ( Agent ) \u00b6 Source code in agents/system/cpu.py class CPUBurn ( Agent ): _psutil = None @validate_arguments def __init__ ( self , config : CPUBurnConfig ): super ( CPUBurn , self ) . __init__ ( config ) self . _psutil = DependencyUtils . import_module ( \"psutil\" , raise_error = False ) if self . _psutil is None : warnings . warn ( \"psutil is not installed. The agent cannot monitor the metrics related to the system.\" \"You can install psutil if you are interested in getting the system data\" , category = ImportWarning , ) def monitor ( self ) -> LifoQueue : # If `psutil` is installed, the agent will be able to monitor the system metrics within # the agent. If the `psutil` package is not installed, the agent will not able to monitor # the system metrics. The agent will not throw an error because of a missing package. # Instead the output of the monitoring data will be NaN. cpu_usage = BuiltinUtils . Float . NAN if self . _psutil is not None and hasattr ( self . _psutil , \"cpu_percent\" ): cpu_usage = sum ( self . _psutil . cpu_percent ( 0.5 , True )) // cpu_count () # type: ignore # TODO: Reason for type ignore - https://github.com/python/mypy/issues/1424 self . _status . put ( AgentMonitoringDataPoint ( data = dict ( cpu_count = self . config . effective_cpu_count (), cpu_usage = cpu_usage ), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( CPUBurn , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( CPUBurn , self ) . run () end = datetime . now () + timedelta ( seconds = self . config . duration ) if self . config . effective_cpu_count () == 0 : return process_pool = Pool ( self . config . effective_cpu_count ()) process_pool . map_async ( _burn , ( end ,) * self . config . effective_cpu_count ()) @log_agent_lifecycle def teardown ( self ) -> None : super ( CPUBurn , self ) . teardown () monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/cpu.py def monitor ( self ) -> LifoQueue : # If `psutil` is installed, the agent will be able to monitor the system metrics within # the agent. If the `psutil` package is not installed, the agent will not able to monitor # the system metrics. The agent will not throw an error because of a missing package. # Instead the output of the monitoring data will be NaN. cpu_usage = BuiltinUtils . Float . NAN if self . _psutil is not None and hasattr ( self . _psutil , \"cpu_percent\" ): cpu_usage = sum ( self . _psutil . cpu_percent ( 0.5 , True )) // cpu_count () # type: ignore # TODO: Reason for type ignore - https://github.com/python/mypy/issues/1424 self . _status . put ( AgentMonitoringDataPoint ( data = dict ( cpu_count = self . config . effective_cpu_count (), cpu_usage = cpu_usage ), state = self . current_state , ) ) return self . _status CPUBurnConfig ( TimedAgentConfig ) pydantic-model \u00b6 Defines the CPU Burn configuration to initiate a CPU burn attack. The framework will attack only a percentage of cores that is defined in the cores_pct attribute. By default, cores_pct is set to 100, implying all the CPU cores are targeted simultaneously. Source code in agents/system/cpu.py class CPUBurnConfig ( TimedAgentConfig ): \"\"\" Defines the CPU Burn configuration to initiate a CPU burn attack. The framework will attack only a percentage of cores that is defined in the `cores_pct` attribute. By default, `cores_pct` is set to 100, implying all the CPU cores are targeted simultaneously. \"\"\" name = \"cpu_burn\" description = \"This agent is responsible to consume the CPU resources for the `duration` amount of seconds.\" cores_pct : float = Field ( default = 100 , description = ( \"Percentage of all the cores to use. \" \"This will burn CPU only on a percentage of cores available in the system\" ), ge = 0 , le = 100 , ) def effective_cpu_count ( self ) -> int : \"\"\" Calculates the number of cores to be used from the cores_pct information Returns: number of cores that fits in the `cores_pct` percentage \"\"\" return math . floor ( self . cores_pct * cpu_count () / 100 ) cores_pct : ConstrainedFloatValue pydantic-field \u00b6 Percentage of all the cores to use. This will burn CPU only on a percentage of cores available in the system effective_cpu_count ( self ) \u00b6 Calculates the number of cores to be used from the cores_pct information Returns: Type Description int number of cores that fits in the cores_pct percentage Source code in agents/system/cpu.py def effective_cpu_count ( self ) -> int : \"\"\" Calculates the number of cores to be used from the cores_pct information Returns: number of cores that fits in the `cores_pct` percentage \"\"\" return math . floor ( self . cores_pct * cpu_count () / 100 )","title":"cpu"},{"location":"package_docs/agents/system/cpu/#ychaos.agents.system.cpu.CPUBurn","text":"Source code in agents/system/cpu.py class CPUBurn ( Agent ): _psutil = None @validate_arguments def __init__ ( self , config : CPUBurnConfig ): super ( CPUBurn , self ) . __init__ ( config ) self . _psutil = DependencyUtils . import_module ( \"psutil\" , raise_error = False ) if self . _psutil is None : warnings . warn ( \"psutil is not installed. The agent cannot monitor the metrics related to the system.\" \"You can install psutil if you are interested in getting the system data\" , category = ImportWarning , ) def monitor ( self ) -> LifoQueue : # If `psutil` is installed, the agent will be able to monitor the system metrics within # the agent. If the `psutil` package is not installed, the agent will not able to monitor # the system metrics. The agent will not throw an error because of a missing package. # Instead the output of the monitoring data will be NaN. cpu_usage = BuiltinUtils . Float . NAN if self . _psutil is not None and hasattr ( self . _psutil , \"cpu_percent\" ): cpu_usage = sum ( self . _psutil . cpu_percent ( 0.5 , True )) // cpu_count () # type: ignore # TODO: Reason for type ignore - https://github.com/python/mypy/issues/1424 self . _status . put ( AgentMonitoringDataPoint ( data = dict ( cpu_count = self . config . effective_cpu_count (), cpu_usage = cpu_usage ), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( CPUBurn , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( CPUBurn , self ) . run () end = datetime . now () + timedelta ( seconds = self . config . duration ) if self . config . effective_cpu_count () == 0 : return process_pool = Pool ( self . config . effective_cpu_count ()) process_pool . map_async ( _burn , ( end ,) * self . config . effective_cpu_count ()) @log_agent_lifecycle def teardown ( self ) -> None : super ( CPUBurn , self ) . teardown ()","title":"CPUBurn"},{"location":"package_docs/agents/system/cpu/#ychaos.agents.system.cpu.CPUBurn.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/cpu.py def monitor ( self ) -> LifoQueue : # If `psutil` is installed, the agent will be able to monitor the system metrics within # the agent. If the `psutil` package is not installed, the agent will not able to monitor # the system metrics. The agent will not throw an error because of a missing package. # Instead the output of the monitoring data will be NaN. cpu_usage = BuiltinUtils . Float . NAN if self . _psutil is not None and hasattr ( self . _psutil , \"cpu_percent\" ): cpu_usage = sum ( self . _psutil . cpu_percent ( 0.5 , True )) // cpu_count () # type: ignore # TODO: Reason for type ignore - https://github.com/python/mypy/issues/1424 self . _status . put ( AgentMonitoringDataPoint ( data = dict ( cpu_count = self . config . effective_cpu_count (), cpu_usage = cpu_usage ), state = self . current_state , ) ) return self . _status","title":"monitor()"},{"location":"package_docs/agents/system/cpu/#ychaos.agents.system.cpu.CPUBurnConfig","text":"Defines the CPU Burn configuration to initiate a CPU burn attack. The framework will attack only a percentage of cores that is defined in the cores_pct attribute. By default, cores_pct is set to 100, implying all the CPU cores are targeted simultaneously. Source code in agents/system/cpu.py class CPUBurnConfig ( TimedAgentConfig ): \"\"\" Defines the CPU Burn configuration to initiate a CPU burn attack. The framework will attack only a percentage of cores that is defined in the `cores_pct` attribute. By default, `cores_pct` is set to 100, implying all the CPU cores are targeted simultaneously. \"\"\" name = \"cpu_burn\" description = \"This agent is responsible to consume the CPU resources for the `duration` amount of seconds.\" cores_pct : float = Field ( default = 100 , description = ( \"Percentage of all the cores to use. \" \"This will burn CPU only on a percentage of cores available in the system\" ), ge = 0 , le = 100 , ) def effective_cpu_count ( self ) -> int : \"\"\" Calculates the number of cores to be used from the cores_pct information Returns: number of cores that fits in the `cores_pct` percentage \"\"\" return math . floor ( self . cores_pct * cpu_count () / 100 )","title":"CPUBurnConfig"},{"location":"package_docs/agents/system/cpu/#ychaos.agents.system.cpu.CPUBurnConfig.cores_pct","text":"Percentage of all the cores to use. This will burn CPU only on a percentage of cores available in the system","title":"cores_pct"},{"location":"package_docs/agents/system/cpu/#ychaos.agents.system.cpu.CPUBurnConfig.effective_cpu_count","text":"Calculates the number of cores to be used from the cores_pct information Returns: Type Description int number of cores that fits in the cores_pct percentage Source code in agents/system/cpu.py def effective_cpu_count ( self ) -> int : \"\"\" Calculates the number of cores to be used from the cores_pct information Returns: number of cores that fits in the `cores_pct` percentage \"\"\" return math . floor ( self . cores_pct * cpu_count () / 100 )","title":"effective_cpu_count()"},{"location":"package_docs/agents/system/disk/","text":"DiskFill ( Agent ) \u00b6 Source code in agents/system/disk.py class DiskFill ( Agent ): def monitor ( self ) -> LifoQueue : super ( DiskFill , self ) . monitor () available_space = shutil . disk_usage ( self . config . partition ) . free self . _status . put ( AgentMonitoringDataPoint ( data = dict ( disk_space_to_fill = self . config . effective_disk_to_fill (), disk_free_space = available_space , ), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( DiskFill , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( DiskFill , self ) . run () size = self . config . effective_disk_to_fill () if size <= 0 : return disk_fill_dir = Path ( self . config . partition / self . config . disk_fill_dir ) disk_fill_dir . mkdir ( parents = True , exist_ok = True ) space_remaining = size index = 0 while space_remaining > 0 : if self . stop_async_run : break tmp = space_remaining cur_file_size = self . config . max_file_size space_remaining -= self . config . max_file_size if space_remaining <= 0 : cur_file_size = tmp with open ( disk_fill_dir / f \"filler { index } .txt\" , \"wb\" ) as f : f . seek ( cur_file_size - 1 ) f . write ( b \" \\0 \" ) index += 1 @log_agent_lifecycle def teardown ( self ) -> None : super ( DiskFill , self ) . teardown () tmp_dir = self . config . partition / self . config . disk_fill_dir if tmp_dir . exists (): shutil . rmtree ( tmp_dir ) monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/disk.py def monitor ( self ) -> LifoQueue : super ( DiskFill , self ) . monitor () available_space = shutil . disk_usage ( self . config . partition ) . free self . _status . put ( AgentMonitoringDataPoint ( data = dict ( disk_space_to_fill = self . config . effective_disk_to_fill (), disk_free_space = available_space , ), state = self . current_state , ) ) return self . _status DiskFillConfig ( TimedAgentConfig ) pydantic-model \u00b6 Defines the Disk Fill configuration to consume the disk space. The framework will fill the disk space of a directory defined in partition and fill only a percentage of available space, as defined in the partition_pct attribute. By default, partition_pct is set to 100, implying the complete disk space of that partition will be filled. Source code in agents/system/disk.py class DiskFillConfig ( TimedAgentConfig ): \"\"\" Defines the Disk Fill configuration to consume the disk space. The framework will fill the disk space of a directory defined in `partition` and fill only a percentage of available space, as defined in the `partition_pct` attribute. By default, `partition_pct` is set to 100, implying the complete disk space of that partition will be filled. \"\"\" name = \"disk_fill\" description = \"This agent fills up disk space.\" priority = AgentPriority . MODERATE_PRIORITY partition : Path = Field ( description = \"The Filepath of directory or partition to fill\" , default = Path ( \"/etc/\" ), examples = [ \"/etc/tmp\" , \"/home/tmpuser\" ], ) partition_pct : float = Field ( default = 80 , description = ( \"Percentage of the disk partition to fill\" \"This will fill a percentage of the disk space on the partition\" ), gt = 0 , le = 100 , ) max_file_size : int = Field ( default = ( 1024 * 1024 * 1024 * 20 ), # Max file size is 20GB, description = ( \"Maximum size of each disk fill file. If the size to be filled exceeds this max file size, multiple\" \"disk fill files will be used\" ), gt = 1024 , ) disk_fill_dir : str = Field ( default = \"ychaos_diskfill\" , description = ( \"Name of the temporary directory in which to store the disk fill files.\" \"This will be the path relative to the partition to fill\" ), ) def effective_disk_to_fill ( self ) -> int : \"\"\" Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: disk space to fill in given partition. \"\"\" stat = shutil . disk_usage ( self . partition ) partition_size_available = stat . free return math . floor ( self . partition_pct / 100 * partition_size_available ) disk_fill_dir : str pydantic-field \u00b6 Name of the temporary directory in which to store the disk fill files.This will be the path relative to the partition to fill max_file_size : ConstrainedIntValue pydantic-field \u00b6 Maximum size of each disk fill file. If the size to be filled exceeds this max file size, multipledisk fill files will be used partition : Path pydantic-field \u00b6 The Filepath of directory or partition to fill partition_pct : ConstrainedFloatValue pydantic-field \u00b6 Percentage of the disk partition to fillThis will fill a percentage of the disk space on the partition effective_disk_to_fill ( self ) \u00b6 Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: Type Description int disk space to fill in given partition. Source code in agents/system/disk.py def effective_disk_to_fill ( self ) -> int : \"\"\" Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: disk space to fill in given partition. \"\"\" stat = shutil . disk_usage ( self . partition ) partition_size_available = stat . free return math . floor ( self . partition_pct / 100 * partition_size_available )","title":"disk"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFill","text":"Source code in agents/system/disk.py class DiskFill ( Agent ): def monitor ( self ) -> LifoQueue : super ( DiskFill , self ) . monitor () available_space = shutil . disk_usage ( self . config . partition ) . free self . _status . put ( AgentMonitoringDataPoint ( data = dict ( disk_space_to_fill = self . config . effective_disk_to_fill (), disk_free_space = available_space , ), state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( DiskFill , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( DiskFill , self ) . run () size = self . config . effective_disk_to_fill () if size <= 0 : return disk_fill_dir = Path ( self . config . partition / self . config . disk_fill_dir ) disk_fill_dir . mkdir ( parents = True , exist_ok = True ) space_remaining = size index = 0 while space_remaining > 0 : if self . stop_async_run : break tmp = space_remaining cur_file_size = self . config . max_file_size space_remaining -= self . config . max_file_size if space_remaining <= 0 : cur_file_size = tmp with open ( disk_fill_dir / f \"filler { index } .txt\" , \"wb\" ) as f : f . seek ( cur_file_size - 1 ) f . write ( b \" \\0 \" ) index += 1 @log_agent_lifecycle def teardown ( self ) -> None : super ( DiskFill , self ) . teardown () tmp_dir = self . config . partition / self . config . disk_fill_dir if tmp_dir . exists (): shutil . rmtree ( tmp_dir )","title":"DiskFill"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFill.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/disk.py def monitor ( self ) -> LifoQueue : super ( DiskFill , self ) . monitor () available_space = shutil . disk_usage ( self . config . partition ) . free self . _status . put ( AgentMonitoringDataPoint ( data = dict ( disk_space_to_fill = self . config . effective_disk_to_fill (), disk_free_space = available_space , ), state = self . current_state , ) ) return self . _status","title":"monitor()"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig","text":"Defines the Disk Fill configuration to consume the disk space. The framework will fill the disk space of a directory defined in partition and fill only a percentage of available space, as defined in the partition_pct attribute. By default, partition_pct is set to 100, implying the complete disk space of that partition will be filled. Source code in agents/system/disk.py class DiskFillConfig ( TimedAgentConfig ): \"\"\" Defines the Disk Fill configuration to consume the disk space. The framework will fill the disk space of a directory defined in `partition` and fill only a percentage of available space, as defined in the `partition_pct` attribute. By default, `partition_pct` is set to 100, implying the complete disk space of that partition will be filled. \"\"\" name = \"disk_fill\" description = \"This agent fills up disk space.\" priority = AgentPriority . MODERATE_PRIORITY partition : Path = Field ( description = \"The Filepath of directory or partition to fill\" , default = Path ( \"/etc/\" ), examples = [ \"/etc/tmp\" , \"/home/tmpuser\" ], ) partition_pct : float = Field ( default = 80 , description = ( \"Percentage of the disk partition to fill\" \"This will fill a percentage of the disk space on the partition\" ), gt = 0 , le = 100 , ) max_file_size : int = Field ( default = ( 1024 * 1024 * 1024 * 20 ), # Max file size is 20GB, description = ( \"Maximum size of each disk fill file. If the size to be filled exceeds this max file size, multiple\" \"disk fill files will be used\" ), gt = 1024 , ) disk_fill_dir : str = Field ( default = \"ychaos_diskfill\" , description = ( \"Name of the temporary directory in which to store the disk fill files.\" \"This will be the path relative to the partition to fill\" ), ) def effective_disk_to_fill ( self ) -> int : \"\"\" Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: disk space to fill in given partition. \"\"\" stat = shutil . disk_usage ( self . partition ) partition_size_available = stat . free return math . floor ( self . partition_pct / 100 * partition_size_available )","title":"DiskFillConfig"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig.disk_fill_dir","text":"Name of the temporary directory in which to store the disk fill files.This will be the path relative to the partition to fill","title":"disk_fill_dir"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig.max_file_size","text":"Maximum size of each disk fill file. If the size to be filled exceeds this max file size, multipledisk fill files will be used","title":"max_file_size"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig.partition","text":"The Filepath of directory or partition to fill","title":"partition"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig.partition_pct","text":"Percentage of the disk partition to fillThis will fill a percentage of the disk space on the partition","title":"partition_pct"},{"location":"package_docs/agents/system/disk/#ychaos.agents.system.disk.DiskFillConfig.effective_disk_to_fill","text":"Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: Type Description int disk space to fill in given partition. Source code in agents/system/disk.py def effective_disk_to_fill ( self ) -> int : \"\"\" Calculates the disk space that needs to be filled based on the available space in the partition and the percentage of partition to fill partition_pct. Returns: disk space to fill in given partition. \"\"\" stat = shutil . disk_usage ( self . partition ) partition_size_available = stat . free return math . floor ( self . partition_pct / 100 * partition_size_available )","title":"effective_disk_to_fill()"},{"location":"package_docs/agents/system/icmp/","text":"PingDisable ( Agent ) \u00b6 Source code in agents/system/icmp.py class PingDisable ( Agent ): sysctl_var = \"net.ipv4.icmp_echo_ignore_all\" def monitor ( self ) -> LifoQueue : super ( PingDisable , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), # TODO: Ping localhost and add monitoring data state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( PingDisable , self ) . setup () self . preserved_state . is_ping_disabled = int ( SysCtl . get ( self . sysctl_var )) == 1 @log_agent_lifecycle def run ( self ) -> None : super ( PingDisable , self ) . run () if self . preserved_state . is_ping_disabled : warnings . warn ( \"ICMP ignore is already turned on. \" \"Running this agent will be a no-operation\" ) else : SysCtl . set ( self . sysctl_var , b \"1\" ) @log_agent_lifecycle def teardown ( self ) -> None : super ( PingDisable , self ) . teardown () if not self . preserved_state . is_ping_disabled : SysCtl . set ( self . sysctl_var , b \"0\" ) monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/icmp.py def monitor ( self ) -> LifoQueue : super ( PingDisable , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), # TODO: Ping localhost and add monitoring data state = self . current_state , ) ) return self . _status","title":"icmp"},{"location":"package_docs/agents/system/icmp/#ychaos.agents.system.icmp.PingDisable","text":"Source code in agents/system/icmp.py class PingDisable ( Agent ): sysctl_var = \"net.ipv4.icmp_echo_ignore_all\" def monitor ( self ) -> LifoQueue : super ( PingDisable , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), # TODO: Ping localhost and add monitoring data state = self . current_state , ) ) return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( PingDisable , self ) . setup () self . preserved_state . is_ping_disabled = int ( SysCtl . get ( self . sysctl_var )) == 1 @log_agent_lifecycle def run ( self ) -> None : super ( PingDisable , self ) . run () if self . preserved_state . is_ping_disabled : warnings . warn ( \"ICMP ignore is already turned on. \" \"Running this agent will be a no-operation\" ) else : SysCtl . set ( self . sysctl_var , b \"1\" ) @log_agent_lifecycle def teardown ( self ) -> None : super ( PingDisable , self ) . teardown () if not self . preserved_state . is_ping_disabled : SysCtl . set ( self . sysctl_var , b \"0\" )","title":"PingDisable"},{"location":"package_docs/agents/system/icmp/#ychaos.agents.system.icmp.PingDisable.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/system/icmp.py def monitor ( self ) -> LifoQueue : super ( PingDisable , self ) . monitor () self . _status . put ( AgentMonitoringDataPoint ( data = dict (), # TODO: Ping localhost and add monitoring data state = self . current_state , ) ) return self . _status","title":"monitor()"},{"location":"package_docs/agents/validation/certificate/","text":"CertificateFileConfig ( BaseModel ) pydantic-model \u00b6 Source code in agents/validation/certificate.py class CertificateFileConfig ( BaseModel ): path : FilePath = Field ( ... , description = \"Path to the certificate file\" ) type : CertificateFileType = Field ( default = CertificateFileType . PEM , description = \"Type of the certificate file\" ) path : FilePath pydantic-field required \u00b6 Path to the certificate file type : CertificateFileType pydantic-field \u00b6 Type of the certificate file CertificateFileType ( AEnum ) \u00b6 Attributes: Name Type Description ASN1 (asn1) ASN1 Certificate format PEM (pem) PEM Certificate format Source code in agents/validation/certificate.py class CertificateFileType ( AEnum ): \"\"\" Attributes: ASN1: (asn1) ASN1 Certificate format PEM: (pem) PEM Certificate format \"\"\" ASN1 = \"asn1\" , SimpleNamespace () PEM = \"pem\" , SimpleNamespace () def binder ( self ): pyopenssl = DependencyUtils . import_module ( \"requests.packages.urllib3.contrib.pyopenssl\" , raise_error = False ) if self == self . PEM : return pyopenssl . OpenSSL . crypto . FILETYPE_PEM elif self == self . ASN1 : return pyopenssl . OpenSSL . crypto . FILETYPE_ASN1 else : # pragma: no cover raise Exception ( \"Unknown Certificate FileType\" ) CertificateFileValidation ( Agent ) \u00b6 Source code in agents/validation/certificate.py class CertificateFileValidation ( Agent ): def monitor ( self ) -> LifoQueue : super ( CertificateFileValidation , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( CertificateFileValidation , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( CertificateFileValidation , self ) . run () for cert_path_config in self . config . paths : data = dict ( path = str ( cert_path_config . path ), type = cert_path_config . type . value , error = None , ) try : assert pyopenssl is not None cert = pyopenssl . OpenSSL . crypto . load_certificate ( cert_path_config . type . binder (), cert_path_config . path . read_bytes (), ) cert_expiry_date = datetime . strptime ( cert . get_notAfter () . decode ( \"ascii\" ), \"%Y%m %d %H%M%SZ\" ) cert_expiry_date . replace ( tzinfo = timezone . utc ) data . update ( dict ( not_valid_after = cert_expiry_date , is_expired = datetime . utcnow () >= cert_expiry_date , is_critical = datetime . utcnow () + self . config . expiry_threshold >= cert_expiry_date , ) ) except pyopenssl . OpenSSL . crypto . Error : # type: ignore data . update ( error = \"decoding_error\" ) self . _status . put ( AgentMonitoringDataPoint ( data = data , state = self . current_state , ) ) @log_agent_lifecycle def teardown ( self ) -> None : super ( CertificateFileValidation , self ) . teardown () monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/validation/certificate.py def monitor ( self ) -> LifoQueue : super ( CertificateFileValidation , self ) . monitor () return self . _status CertificateFileValidationConfig ( AgentConfig ) pydantic-model \u00b6 Source code in agents/validation/certificate.py class CertificateFileValidationConfig ( AgentConfig ): name = \"cert_file_validation\" desc = \"This agent decodes the local certificates and validates for expiry/critical\" priority = AgentPriority . LOW_PRIORITY expiry_threshold : timedelta = Field ( default = timedelta ( days = 7 ), description = \"Expiry threshold\" ) paths : List [ Union [ FilePath , CertificateFileConfig ]] = Field ( default = list (), description = \"List of Certificate files to be validated\" , min_items = 1 , ) @validator ( \"paths\" , each_item = True ) def parse_paths ( cls , v , values ): if isinstance ( v , Path ): return CertificateFileConfig ( path = v ) return v expiry_threshold : timedelta pydantic-field \u00b6 Expiry threshold paths : ConstrainedListValue pydantic-field \u00b6 List of Certificate files to be validated ServerCertValidation ( Agent ) \u00b6 Source code in agents/validation/certificate.py class ServerCertValidation ( Agent ): @validate_arguments def __init__ ( self , config : ServerCertValidationConfig ): super ( ServerCertValidation , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( ServerCertValidation , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( ServerCertValidation , self ) . setup () @staticmethod def get_server_cert ( host : str , port : int , timeout_ = 5 ): from socket import setdefaulttimeout setdefaulttimeout ( timeout_ ) assert pyopenssl is not None return pyopenssl . OpenSSL . crypto . load_certificate ( pyopenssl . OpenSSL . crypto . FILETYPE_PEM , pyopenssl . ssl . get_server_certificate (( host , port )), ) @log_agent_lifecycle def run ( self ) -> None : for url in self . config . urls : if url . port is None : url . port = \"443\" data = dict ( host = url . host , port = int ( url . port ), error = None ) try : cert = self . get_server_cert ( url . host , int ( url . port ), timeout_ = self . config . timeout ) cert_expiry_date = datetime . strptime ( cert . get_notAfter () . decode ( \"ascii\" ), \"%Y%m %d %H%M%SZ\" ) cert_expiry_date . replace ( tzinfo = timezone . utc ) data . update ( dict ( not_valid_after = cert_expiry_date , is_expired = datetime . utcnow () >= cert_expiry_date , is_critical = datetime . utcnow () + self . config . expiry_threshold >= cert_expiry_date , ) ) except ( timeout , gaierror ) as error : data . update ( error = str ( error . __class__ . __name__ )) self . _status . put ( AgentMonitoringDataPoint ( data = data , state = self . current_state , ) ) @log_agent_lifecycle def teardown ( self ) -> None : super ( ServerCertValidation , self ) . teardown () monitor ( self ) \u00b6 Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/validation/certificate.py def monitor ( self ) -> LifoQueue : super ( ServerCertValidation , self ) . monitor () return self . _status ServerCertValidationConfig ( AgentConfig ) pydantic-model \u00b6 Source code in agents/validation/certificate.py class ServerCertValidationConfig ( AgentConfig ): name = \"server_cert_validation\" desc = \"This agent retrieves SSL certificates from server and validates it\" priority = AgentPriority . LOW_PRIORITY urls : List [ AnyHttpUrl ] = Field ( default = list (), description = \"List of URLs which will be validated for their SSL certificate expiry\" , min_items = 1 , ) expiry_threshold : timedelta = Field ( default = timedelta ( days = 7 ), description = \"Expiry threshold\" ) timeout : int = Field ( default = 5 , description = \"Default timeout to fetch the certificates in seconds\" ) expiry_threshold : timedelta pydantic-field \u00b6 Expiry threshold timeout : int pydantic-field \u00b6 Default timeout to fetch the certificates in seconds urls : ConstrainedListValue pydantic-field \u00b6 List of URLs which will be validated for their SSL certificate expiry","title":"certificate"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileConfig","text":"Source code in agents/validation/certificate.py class CertificateFileConfig ( BaseModel ): path : FilePath = Field ( ... , description = \"Path to the certificate file\" ) type : CertificateFileType = Field ( default = CertificateFileType . PEM , description = \"Type of the certificate file\" )","title":"CertificateFileConfig"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileConfig.path","text":"Path to the certificate file","title":"path"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileConfig.type","text":"Type of the certificate file","title":"type"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileType","text":"Attributes: Name Type Description ASN1 (asn1) ASN1 Certificate format PEM (pem) PEM Certificate format Source code in agents/validation/certificate.py class CertificateFileType ( AEnum ): \"\"\" Attributes: ASN1: (asn1) ASN1 Certificate format PEM: (pem) PEM Certificate format \"\"\" ASN1 = \"asn1\" , SimpleNamespace () PEM = \"pem\" , SimpleNamespace () def binder ( self ): pyopenssl = DependencyUtils . import_module ( \"requests.packages.urllib3.contrib.pyopenssl\" , raise_error = False ) if self == self . PEM : return pyopenssl . OpenSSL . crypto . FILETYPE_PEM elif self == self . ASN1 : return pyopenssl . OpenSSL . crypto . FILETYPE_ASN1 else : # pragma: no cover raise Exception ( \"Unknown Certificate FileType\" )","title":"CertificateFileType"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileValidation","text":"Source code in agents/validation/certificate.py class CertificateFileValidation ( Agent ): def monitor ( self ) -> LifoQueue : super ( CertificateFileValidation , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( CertificateFileValidation , self ) . setup () @log_agent_lifecycle def run ( self ) -> None : super ( CertificateFileValidation , self ) . run () for cert_path_config in self . config . paths : data = dict ( path = str ( cert_path_config . path ), type = cert_path_config . type . value , error = None , ) try : assert pyopenssl is not None cert = pyopenssl . OpenSSL . crypto . load_certificate ( cert_path_config . type . binder (), cert_path_config . path . read_bytes (), ) cert_expiry_date = datetime . strptime ( cert . get_notAfter () . decode ( \"ascii\" ), \"%Y%m %d %H%M%SZ\" ) cert_expiry_date . replace ( tzinfo = timezone . utc ) data . update ( dict ( not_valid_after = cert_expiry_date , is_expired = datetime . utcnow () >= cert_expiry_date , is_critical = datetime . utcnow () + self . config . expiry_threshold >= cert_expiry_date , ) ) except pyopenssl . OpenSSL . crypto . Error : # type: ignore data . update ( error = \"decoding_error\" ) self . _status . put ( AgentMonitoringDataPoint ( data = data , state = self . current_state , ) ) @log_agent_lifecycle def teardown ( self ) -> None : super ( CertificateFileValidation , self ) . teardown ()","title":"CertificateFileValidation"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileValidation.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/validation/certificate.py def monitor ( self ) -> LifoQueue : super ( CertificateFileValidation , self ) . monitor () return self . _status","title":"monitor()"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileValidationConfig","text":"Source code in agents/validation/certificate.py class CertificateFileValidationConfig ( AgentConfig ): name = \"cert_file_validation\" desc = \"This agent decodes the local certificates and validates for expiry/critical\" priority = AgentPriority . LOW_PRIORITY expiry_threshold : timedelta = Field ( default = timedelta ( days = 7 ), description = \"Expiry threshold\" ) paths : List [ Union [ FilePath , CertificateFileConfig ]] = Field ( default = list (), description = \"List of Certificate files to be validated\" , min_items = 1 , ) @validator ( \"paths\" , each_item = True ) def parse_paths ( cls , v , values ): if isinstance ( v , Path ): return CertificateFileConfig ( path = v ) return v","title":"CertificateFileValidationConfig"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileValidationConfig.expiry_threshold","text":"Expiry threshold","title":"expiry_threshold"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.CertificateFileValidationConfig.paths","text":"List of Certificate files to be validated","title":"paths"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidation","text":"Source code in agents/validation/certificate.py class ServerCertValidation ( Agent ): @validate_arguments def __init__ ( self , config : ServerCertValidationConfig ): super ( ServerCertValidation , self ) . __init__ ( config ) def monitor ( self ) -> LifoQueue : super ( ServerCertValidation , self ) . monitor () return self . _status @log_agent_lifecycle def setup ( self ) -> None : super ( ServerCertValidation , self ) . setup () @staticmethod def get_server_cert ( host : str , port : int , timeout_ = 5 ): from socket import setdefaulttimeout setdefaulttimeout ( timeout_ ) assert pyopenssl is not None return pyopenssl . OpenSSL . crypto . load_certificate ( pyopenssl . OpenSSL . crypto . FILETYPE_PEM , pyopenssl . ssl . get_server_certificate (( host , port )), ) @log_agent_lifecycle def run ( self ) -> None : for url in self . config . urls : if url . port is None : url . port = \"443\" data = dict ( host = url . host , port = int ( url . port ), error = None ) try : cert = self . get_server_cert ( url . host , int ( url . port ), timeout_ = self . config . timeout ) cert_expiry_date = datetime . strptime ( cert . get_notAfter () . decode ( \"ascii\" ), \"%Y%m %d %H%M%SZ\" ) cert_expiry_date . replace ( tzinfo = timezone . utc ) data . update ( dict ( not_valid_after = cert_expiry_date , is_expired = datetime . utcnow () >= cert_expiry_date , is_critical = datetime . utcnow () + self . config . expiry_threshold >= cert_expiry_date , ) ) except ( timeout , gaierror ) as error : data . update ( error = str ( error . __class__ . __name__ )) self . _status . put ( AgentMonitoringDataPoint ( data = data , state = self . current_state , ) ) @log_agent_lifecycle def teardown ( self ) -> None : super ( ServerCertValidation , self ) . teardown ()","title":"ServerCertValidation"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidation.monitor","text":"Defines the implementation to monitor some stats for this agent and return a queue of the status Returns: Type Description LifoQueue A Queue of the status for this agent. Source code in agents/validation/certificate.py def monitor ( self ) -> LifoQueue : super ( ServerCertValidation , self ) . monitor () return self . _status","title":"monitor()"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidationConfig","text":"Source code in agents/validation/certificate.py class ServerCertValidationConfig ( AgentConfig ): name = \"server_cert_validation\" desc = \"This agent retrieves SSL certificates from server and validates it\" priority = AgentPriority . LOW_PRIORITY urls : List [ AnyHttpUrl ] = Field ( default = list (), description = \"List of URLs which will be validated for their SSL certificate expiry\" , min_items = 1 , ) expiry_threshold : timedelta = Field ( default = timedelta ( days = 7 ), description = \"Expiry threshold\" ) timeout : int = Field ( default = 5 , description = \"Default timeout to fetch the certificates in seconds\" )","title":"ServerCertValidationConfig"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidationConfig.expiry_threshold","text":"Expiry threshold","title":"expiry_threshold"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidationConfig.timeout","text":"Default timeout to fetch the certificates in seconds","title":"timeout"},{"location":"package_docs/agents/validation/certificate/#ychaos.agents.validation.certificate.ServerCertValidationConfig.urls","text":"List of URLs which will be validated for their SSL certificate expiry","title":"urls"},{"location":"package_docs/cli/main/","text":"App \u00b6 Source code in cli/main.py class App : def __init__ ( self , args : Namespace , cli : Optional [ ArgumentParser ] = None ): Settings ( args . config ) args . verbose = min ( 2 , args . verbose ) self . args = args self . console = Console ( record = True , no_color = args . no_color ) self . settings : Union [ DevSettings , ProdSettings ] = Settings . get_instance () self . cli = cli if args . log_file : self . settings . LOG_FILE_PATH = args . log_file AppLogger () def start ( self ) -> None : AppLogger . start () self . console . clear () self . console . rule ( title = self . settings . APP_DESC , style = \"magenta\" , ) if self . args . cls != YChaosRoot : self . print_cli_configuration () self . console . line () self . console . log ( \"Starting app\" ) def get_command_tree ( self ) -> List [ str ]: \"\"\" Determines the command tree of the invoked command. Returns: List of commands starting with `ychaos` and ending at the sub-command invoked \"\"\" _args = vars ( self . args ) parent = self . settings . PROG branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree = [] while branch is not None : tree . append ( parent ) parent = branch branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree . append ( parent ) return tree def _walk_parser ( self , parser : ArgumentParser , tree ): \"\"\" Walk the Argument parser and collect all the subcommands and its help message. Args: parser: Argument Parser Returns: Tree dictionary \"\"\" if parser . _subparsers is not None : for action in parser . _subparsers . _actions : if isinstance ( action , SubCommandParsersAction ): for command , subparser in action . choices . items (): tree [ subparser . prog ] = subparser . format_help () tree = self . _walk_parser ( subparser , tree ) return tree def manual_entry ( self ) -> Dict [ str , str ]: \"\"\" Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Dictionary of command to help message mapping \"\"\" _tree = OrderedDict () assert self . cli is not None _tree [ self . settings . PROG ] = self . cli . format_help () self . _walk_parser ( self . cli , _tree ) return _tree def is_debug_mode ( self ) -> bool : \"\"\" Returns if the app was initialized with debug mode Returns: True if debug mode \"\"\" return self . args . debug def print_cli_configuration ( self ): self . console . line () table = Table ( title = \"YChaos CLI configuration\" , header_style = \"bold green\" ) table . add_column ( \"Configuration\" , style = \"bold sea_green2\" ) table . add_column ( \"Value\" ) _renderable_config = vars ( self . args ) . copy () _renderable_config . pop ( \"app\" ) _renderable_config . pop ( \"cls\" ) _renderable_config [ \"_command_\" ] = \" :arrow_right: \" . join ( self . get_command_tree () ) for k , v in sorted ( _renderable_config . items ()): if not k . startswith ( \"_cmd\" ): if isinstance ( v , Iterable ) and not isinstance ( v , str ): v = \" \\n \" . join ([ str ( _v ) for _v in v ]) if v is not None : table . add_row ( str ( k ), str ( v )) self . console . print ( table ) def unknown_error ( self ): self . console . line () self . console . print_exception ( extra_lines = 2 ) def teardown ( self , exitcode : int ) -> None : if self . args . cls != YChaosRoot : self . console . line () self . console . log ( f \"Exiting with exitcode= { exitcode } \" ) self . console . rule ( title = \":sunny:\" , style = \"magenta\" , ) # Save Reports if self . args . text_report : self . console . save_text ( self . args . text_report ) if self . args . html_report : self . console . save_html ( self . args . html_report ) AppLogger . stop () get_command_tree ( self ) \u00b6 Determines the command tree of the invoked command. Returns: Type Description List[str] List of commands starting with ychaos and ending at the sub-command invoked Source code in cli/main.py def get_command_tree ( self ) -> List [ str ]: \"\"\" Determines the command tree of the invoked command. Returns: List of commands starting with `ychaos` and ending at the sub-command invoked \"\"\" _args = vars ( self . args ) parent = self . settings . PROG branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree = [] while branch is not None : tree . append ( parent ) parent = branch branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree . append ( parent ) return tree is_debug_mode ( self ) \u00b6 Returns if the app was initialized with debug mode Returns: Type Description bool True if debug mode Source code in cli/main.py def is_debug_mode ( self ) -> bool : \"\"\" Returns if the app was initialized with debug mode Returns: True if debug mode \"\"\" return self . args . debug manual_entry ( self ) \u00b6 Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Type Description Dict[str, str] Dictionary of command to help message mapping Source code in cli/main.py def manual_entry ( self ) -> Dict [ str , str ]: \"\"\" Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Dictionary of command to help message mapping \"\"\" _tree = OrderedDict () assert self . cli is not None _tree [ self . settings . PROG ] = self . cli . format_help () self . _walk_parser ( self . cli , _tree ) return _tree YChaos \u00b6 The YChaos CLI class. The main method of this class is the starting point of the CLI which takes in the program arguments. See YChaos CLI documentation for more details. To see the usage of the YChaos CLI, run ychaos -h on the terminal Source code in cli/main.py class YChaos : \"\"\" The YChaos CLI class. The `main` method of this class is the starting point of the CLI which takes in the program arguments. See YChaos CLI documentation for more details. To see the usage of the YChaos CLI, run `ychaos -h` on the terminal \"\"\" settings = ApplicationSettings . get_instance () @classmethod def main ( cls , program_arguments : list ) -> None : \"\"\" All good things begin some place, and that's here. Args: program_arguments: List of Program Arguments Returns: None \"\"\" ychaos_cli = YChaosArgumentParser ( prog = cls . settings . PROG , formatter_class = ArgumentDefaultsHelpFormatter , __root__ = YChaosRoot , ) # YChaos CLI version ychaos_cli . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = f \"v { cls . settings . get_version () } [yahoo/ychaos]\" , ) # Verbosity Argument Group verbosity_argument_group = ychaos_cli . add_argument_group ( \"verbosity\" ) verbosity_argument_group . add_argument ( \"-V\" , \"--verbose\" , action = \"count\" , help = \"Increase verbosity of logs (INFO)\" , default = 0 , required = False , ) verbosity_argument_group . add_argument ( \"--debug\" , action = \"store_true\" , help = \"Enable debug mode\" , default = False , required = False , ) # Configuration for the ychaos Command Line Interface ychaos_cli . add_argument ( \"-c\" , \"--config\" , choices = [ \"dev\" , \"prod\" ], default = \"prod\" , help = \"Set YChaos CLI configuration (prod)\" , metavar = \"config\" , ) ychaos_cli . add_argument ( \"--no-color\" , action = \"store_true\" , default = bool ( os . getenv ( \"NO_COLOR\" , False )), help = \"Disable color on console output ($NO_COLOR)\" , ) # Arguments for creating HTML & Text Reports report_argument_group = ychaos_cli . add_argument_group ( \"reports\" ) report_argument_group . add_argument ( \"--text-report\" , type = Path , default = None , required = False , help = \"Generate a text report from the YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--html-report\" , type = Path , default = None , required = False , help = \"Generate a HTML report from YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--log-file\" , type = Path , default = os . getenv ( \"YCHAOS_LOG_FILE\" ), required = False , help = ( \"The file to store application logs. ($YCHAOS_LOG_FILE)\" ), metavar = \"path\" , ) ychaos_cli_subparsers = ychaos_cli . add_subparsers ( action = SubCommandParsersAction , dest = cls . settings . COMMAND_IDENTIFIER . format ( cls . settings . PROG ), ) assert isinstance ( ychaos_cli_subparsers , SubCommandParsersAction ) # Subcommands ychaos_cli_subparsers . add_parser ( cls = TestPlan ) ychaos_cli_subparsers . add_parser ( cls = Manual ) ychaos_cli_subparsers . add_parser ( cls = Agent ) ychaos_cli_subparsers . add_parser ( cls = Verify ) ychaos_cli_subparsers . add_parser ( cls = Execute ) args = ychaos_cli . parse_args ( program_arguments ) args . app = App ( args , ychaos_cli ) # Start the Application args . app . start () # Call the right method for the subcommand try : exitcode = ychaos_cli . run_command ( args ) except Exception as unknown_error : # pragma: no cover exitcode = 255 args . app . unknown_error () # Teardown args . app . teardown ( exitcode ) sys . exit ( exitcode ) main ( program_arguments ) classmethod \u00b6 All good things begin some place, and that's here. Parameters: Name Type Description Default program_arguments list List of Program Arguments required Returns: Type Description None None Source code in cli/main.py @classmethod def main ( cls , program_arguments : list ) -> None : \"\"\" All good things begin some place, and that's here. Args: program_arguments: List of Program Arguments Returns: None \"\"\" ychaos_cli = YChaosArgumentParser ( prog = cls . settings . PROG , formatter_class = ArgumentDefaultsHelpFormatter , __root__ = YChaosRoot , ) # YChaos CLI version ychaos_cli . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = f \"v { cls . settings . get_version () } [yahoo/ychaos]\" , ) # Verbosity Argument Group verbosity_argument_group = ychaos_cli . add_argument_group ( \"verbosity\" ) verbosity_argument_group . add_argument ( \"-V\" , \"--verbose\" , action = \"count\" , help = \"Increase verbosity of logs (INFO)\" , default = 0 , required = False , ) verbosity_argument_group . add_argument ( \"--debug\" , action = \"store_true\" , help = \"Enable debug mode\" , default = False , required = False , ) # Configuration for the ychaos Command Line Interface ychaos_cli . add_argument ( \"-c\" , \"--config\" , choices = [ \"dev\" , \"prod\" ], default = \"prod\" , help = \"Set YChaos CLI configuration (prod)\" , metavar = \"config\" , ) ychaos_cli . add_argument ( \"--no-color\" , action = \"store_true\" , default = bool ( os . getenv ( \"NO_COLOR\" , False )), help = \"Disable color on console output ($NO_COLOR)\" , ) # Arguments for creating HTML & Text Reports report_argument_group = ychaos_cli . add_argument_group ( \"reports\" ) report_argument_group . add_argument ( \"--text-report\" , type = Path , default = None , required = False , help = \"Generate a text report from the YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--html-report\" , type = Path , default = None , required = False , help = \"Generate a HTML report from YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--log-file\" , type = Path , default = os . getenv ( \"YCHAOS_LOG_FILE\" ), required = False , help = ( \"The file to store application logs. ($YCHAOS_LOG_FILE)\" ), metavar = \"path\" , ) ychaos_cli_subparsers = ychaos_cli . add_subparsers ( action = SubCommandParsersAction , dest = cls . settings . COMMAND_IDENTIFIER . format ( cls . settings . PROG ), ) assert isinstance ( ychaos_cli_subparsers , SubCommandParsersAction ) # Subcommands ychaos_cli_subparsers . add_parser ( cls = TestPlan ) ychaos_cli_subparsers . add_parser ( cls = Manual ) ychaos_cli_subparsers . add_parser ( cls = Agent ) ychaos_cli_subparsers . add_parser ( cls = Verify ) ychaos_cli_subparsers . add_parser ( cls = Execute ) args = ychaos_cli . parse_args ( program_arguments ) args . app = App ( args , ychaos_cli ) # Start the Application args . app . start () # Call the right method for the subcommand try : exitcode = ychaos_cli . run_command ( args ) except Exception as unknown_error : # pragma: no cover exitcode = 255 args . app . unknown_error () # Teardown args . app . teardown ( exitcode ) sys . exit ( exitcode ) YChaosRoot ( YChaosSubCommand ) \u00b6 The YChaos root command. This class is invoked when the ychaos cli is invoked without any subcommands Source code in cli/main.py class YChaosRoot ( YChaosSubCommand ): \"\"\" The YChaos root command. This class is invoked when the ychaos cli is invoked without any subcommands \"\"\" @classmethod def main ( cls , args : Namespace ) -> Any : \"\"\" Does Nothing. Args: args: Arguments Returns: 0 (Zero) exitcode \"\"\" return 0 main ( args ) classmethod \u00b6 Does Nothing. Parameters: Name Type Description Default args Namespace Arguments required Returns: Type Description Any 0 (Zero) exitcode Source code in cli/main.py @classmethod def main ( cls , args : Namespace ) -> Any : \"\"\" Does Nothing. Args: args: Arguments Returns: 0 (Zero) exitcode \"\"\" return 0","title":"main"},{"location":"package_docs/cli/main/#ychaos.cli.main.App","text":"Source code in cli/main.py class App : def __init__ ( self , args : Namespace , cli : Optional [ ArgumentParser ] = None ): Settings ( args . config ) args . verbose = min ( 2 , args . verbose ) self . args = args self . console = Console ( record = True , no_color = args . no_color ) self . settings : Union [ DevSettings , ProdSettings ] = Settings . get_instance () self . cli = cli if args . log_file : self . settings . LOG_FILE_PATH = args . log_file AppLogger () def start ( self ) -> None : AppLogger . start () self . console . clear () self . console . rule ( title = self . settings . APP_DESC , style = \"magenta\" , ) if self . args . cls != YChaosRoot : self . print_cli_configuration () self . console . line () self . console . log ( \"Starting app\" ) def get_command_tree ( self ) -> List [ str ]: \"\"\" Determines the command tree of the invoked command. Returns: List of commands starting with `ychaos` and ending at the sub-command invoked \"\"\" _args = vars ( self . args ) parent = self . settings . PROG branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree = [] while branch is not None : tree . append ( parent ) parent = branch branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree . append ( parent ) return tree def _walk_parser ( self , parser : ArgumentParser , tree ): \"\"\" Walk the Argument parser and collect all the subcommands and its help message. Args: parser: Argument Parser Returns: Tree dictionary \"\"\" if parser . _subparsers is not None : for action in parser . _subparsers . _actions : if isinstance ( action , SubCommandParsersAction ): for command , subparser in action . choices . items (): tree [ subparser . prog ] = subparser . format_help () tree = self . _walk_parser ( subparser , tree ) return tree def manual_entry ( self ) -> Dict [ str , str ]: \"\"\" Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Dictionary of command to help message mapping \"\"\" _tree = OrderedDict () assert self . cli is not None _tree [ self . settings . PROG ] = self . cli . format_help () self . _walk_parser ( self . cli , _tree ) return _tree def is_debug_mode ( self ) -> bool : \"\"\" Returns if the app was initialized with debug mode Returns: True if debug mode \"\"\" return self . args . debug def print_cli_configuration ( self ): self . console . line () table = Table ( title = \"YChaos CLI configuration\" , header_style = \"bold green\" ) table . add_column ( \"Configuration\" , style = \"bold sea_green2\" ) table . add_column ( \"Value\" ) _renderable_config = vars ( self . args ) . copy () _renderable_config . pop ( \"app\" ) _renderable_config . pop ( \"cls\" ) _renderable_config [ \"_command_\" ] = \" :arrow_right: \" . join ( self . get_command_tree () ) for k , v in sorted ( _renderable_config . items ()): if not k . startswith ( \"_cmd\" ): if isinstance ( v , Iterable ) and not isinstance ( v , str ): v = \" \\n \" . join ([ str ( _v ) for _v in v ]) if v is not None : table . add_row ( str ( k ), str ( v )) self . console . print ( table ) def unknown_error ( self ): self . console . line () self . console . print_exception ( extra_lines = 2 ) def teardown ( self , exitcode : int ) -> None : if self . args . cls != YChaosRoot : self . console . line () self . console . log ( f \"Exiting with exitcode= { exitcode } \" ) self . console . rule ( title = \":sunny:\" , style = \"magenta\" , ) # Save Reports if self . args . text_report : self . console . save_text ( self . args . text_report ) if self . args . html_report : self . console . save_html ( self . args . html_report ) AppLogger . stop ()","title":"App"},{"location":"package_docs/cli/main/#ychaos.cli.main.App.get_command_tree","text":"Determines the command tree of the invoked command. Returns: Type Description List[str] List of commands starting with ychaos and ending at the sub-command invoked Source code in cli/main.py def get_command_tree ( self ) -> List [ str ]: \"\"\" Determines the command tree of the invoked command. Returns: List of commands starting with `ychaos` and ending at the sub-command invoked \"\"\" _args = vars ( self . args ) parent = self . settings . PROG branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree = [] while branch is not None : tree . append ( parent ) parent = branch branch = _args . get ( self . settings . COMMAND_IDENTIFIER . format ( parent ), None ) tree . append ( parent ) return tree","title":"get_command_tree()"},{"location":"package_docs/cli/main/#ychaos.cli.main.App.is_debug_mode","text":"Returns if the app was initialized with debug mode Returns: Type Description bool True if debug mode Source code in cli/main.py def is_debug_mode ( self ) -> bool : \"\"\" Returns if the app was initialized with debug mode Returns: True if debug mode \"\"\" return self . args . debug","title":"is_debug_mode()"},{"location":"package_docs/cli/main/#ychaos.cli.main.App.manual_entry","text":"Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Type Description Dict[str, str] Dictionary of command to help message mapping Source code in cli/main.py def manual_entry ( self ) -> Dict [ str , str ]: \"\"\" Determines the manual entry of the YChaos CLI and returns a program aware dictionary of cli -> usage mapping Returns: Dictionary of command to help message mapping \"\"\" _tree = OrderedDict () assert self . cli is not None _tree [ self . settings . PROG ] = self . cli . format_help () self . _walk_parser ( self . cli , _tree ) return _tree","title":"manual_entry()"},{"location":"package_docs/cli/main/#ychaos.cli.main.YChaos","text":"The YChaos CLI class. The main method of this class is the starting point of the CLI which takes in the program arguments. See YChaos CLI documentation for more details. To see the usage of the YChaos CLI, run ychaos -h on the terminal Source code in cli/main.py class YChaos : \"\"\" The YChaos CLI class. The `main` method of this class is the starting point of the CLI which takes in the program arguments. See YChaos CLI documentation for more details. To see the usage of the YChaos CLI, run `ychaos -h` on the terminal \"\"\" settings = ApplicationSettings . get_instance () @classmethod def main ( cls , program_arguments : list ) -> None : \"\"\" All good things begin some place, and that's here. Args: program_arguments: List of Program Arguments Returns: None \"\"\" ychaos_cli = YChaosArgumentParser ( prog = cls . settings . PROG , formatter_class = ArgumentDefaultsHelpFormatter , __root__ = YChaosRoot , ) # YChaos CLI version ychaos_cli . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = f \"v { cls . settings . get_version () } [yahoo/ychaos]\" , ) # Verbosity Argument Group verbosity_argument_group = ychaos_cli . add_argument_group ( \"verbosity\" ) verbosity_argument_group . add_argument ( \"-V\" , \"--verbose\" , action = \"count\" , help = \"Increase verbosity of logs (INFO)\" , default = 0 , required = False , ) verbosity_argument_group . add_argument ( \"--debug\" , action = \"store_true\" , help = \"Enable debug mode\" , default = False , required = False , ) # Configuration for the ychaos Command Line Interface ychaos_cli . add_argument ( \"-c\" , \"--config\" , choices = [ \"dev\" , \"prod\" ], default = \"prod\" , help = \"Set YChaos CLI configuration (prod)\" , metavar = \"config\" , ) ychaos_cli . add_argument ( \"--no-color\" , action = \"store_true\" , default = bool ( os . getenv ( \"NO_COLOR\" , False )), help = \"Disable color on console output ($NO_COLOR)\" , ) # Arguments for creating HTML & Text Reports report_argument_group = ychaos_cli . add_argument_group ( \"reports\" ) report_argument_group . add_argument ( \"--text-report\" , type = Path , default = None , required = False , help = \"Generate a text report from the YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--html-report\" , type = Path , default = None , required = False , help = \"Generate a HTML report from YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--log-file\" , type = Path , default = os . getenv ( \"YCHAOS_LOG_FILE\" ), required = False , help = ( \"The file to store application logs. ($YCHAOS_LOG_FILE)\" ), metavar = \"path\" , ) ychaos_cli_subparsers = ychaos_cli . add_subparsers ( action = SubCommandParsersAction , dest = cls . settings . COMMAND_IDENTIFIER . format ( cls . settings . PROG ), ) assert isinstance ( ychaos_cli_subparsers , SubCommandParsersAction ) # Subcommands ychaos_cli_subparsers . add_parser ( cls = TestPlan ) ychaos_cli_subparsers . add_parser ( cls = Manual ) ychaos_cli_subparsers . add_parser ( cls = Agent ) ychaos_cli_subparsers . add_parser ( cls = Verify ) ychaos_cli_subparsers . add_parser ( cls = Execute ) args = ychaos_cli . parse_args ( program_arguments ) args . app = App ( args , ychaos_cli ) # Start the Application args . app . start () # Call the right method for the subcommand try : exitcode = ychaos_cli . run_command ( args ) except Exception as unknown_error : # pragma: no cover exitcode = 255 args . app . unknown_error () # Teardown args . app . teardown ( exitcode ) sys . exit ( exitcode )","title":"YChaos"},{"location":"package_docs/cli/main/#ychaos.cli.main.YChaos.main","text":"All good things begin some place, and that's here. Parameters: Name Type Description Default program_arguments list List of Program Arguments required Returns: Type Description None None Source code in cli/main.py @classmethod def main ( cls , program_arguments : list ) -> None : \"\"\" All good things begin some place, and that's here. Args: program_arguments: List of Program Arguments Returns: None \"\"\" ychaos_cli = YChaosArgumentParser ( prog = cls . settings . PROG , formatter_class = ArgumentDefaultsHelpFormatter , __root__ = YChaosRoot , ) # YChaos CLI version ychaos_cli . add_argument ( \"-v\" , \"--version\" , action = \"version\" , version = f \"v { cls . settings . get_version () } [yahoo/ychaos]\" , ) # Verbosity Argument Group verbosity_argument_group = ychaos_cli . add_argument_group ( \"verbosity\" ) verbosity_argument_group . add_argument ( \"-V\" , \"--verbose\" , action = \"count\" , help = \"Increase verbosity of logs (INFO)\" , default = 0 , required = False , ) verbosity_argument_group . add_argument ( \"--debug\" , action = \"store_true\" , help = \"Enable debug mode\" , default = False , required = False , ) # Configuration for the ychaos Command Line Interface ychaos_cli . add_argument ( \"-c\" , \"--config\" , choices = [ \"dev\" , \"prod\" ], default = \"prod\" , help = \"Set YChaos CLI configuration (prod)\" , metavar = \"config\" , ) ychaos_cli . add_argument ( \"--no-color\" , action = \"store_true\" , default = bool ( os . getenv ( \"NO_COLOR\" , False )), help = \"Disable color on console output ($NO_COLOR)\" , ) # Arguments for creating HTML & Text Reports report_argument_group = ychaos_cli . add_argument_group ( \"reports\" ) report_argument_group . add_argument ( \"--text-report\" , type = Path , default = None , required = False , help = \"Generate a text report from the YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--html-report\" , type = Path , default = None , required = False , help = \"Generate a HTML report from YChaos execution\" , metavar = \"path\" , ) report_argument_group . add_argument ( \"--log-file\" , type = Path , default = os . getenv ( \"YCHAOS_LOG_FILE\" ), required = False , help = ( \"The file to store application logs. ($YCHAOS_LOG_FILE)\" ), metavar = \"path\" , ) ychaos_cli_subparsers = ychaos_cli . add_subparsers ( action = SubCommandParsersAction , dest = cls . settings . COMMAND_IDENTIFIER . format ( cls . settings . PROG ), ) assert isinstance ( ychaos_cli_subparsers , SubCommandParsersAction ) # Subcommands ychaos_cli_subparsers . add_parser ( cls = TestPlan ) ychaos_cli_subparsers . add_parser ( cls = Manual ) ychaos_cli_subparsers . add_parser ( cls = Agent ) ychaos_cli_subparsers . add_parser ( cls = Verify ) ychaos_cli_subparsers . add_parser ( cls = Execute ) args = ychaos_cli . parse_args ( program_arguments ) args . app = App ( args , ychaos_cli ) # Start the Application args . app . start () # Call the right method for the subcommand try : exitcode = ychaos_cli . run_command ( args ) except Exception as unknown_error : # pragma: no cover exitcode = 255 args . app . unknown_error () # Teardown args . app . teardown ( exitcode ) sys . exit ( exitcode )","title":"main()"},{"location":"package_docs/cli/main/#ychaos.cli.main.YChaosRoot","text":"The YChaos root command. This class is invoked when the ychaos cli is invoked without any subcommands Source code in cli/main.py class YChaosRoot ( YChaosSubCommand ): \"\"\" The YChaos root command. This class is invoked when the ychaos cli is invoked without any subcommands \"\"\" @classmethod def main ( cls , args : Namespace ) -> Any : \"\"\" Does Nothing. Args: args: Arguments Returns: 0 (Zero) exitcode \"\"\" return 0","title":"YChaosRoot"},{"location":"package_docs/cli/main/#ychaos.cli.main.YChaosRoot.main","text":"Does Nothing. Parameters: Name Type Description Default args Namespace Arguments required Returns: Type Description Any 0 (Zero) exitcode Source code in cli/main.py @classmethod def main ( cls , args : Namespace ) -> Any : \"\"\" Does Nothing. Args: args: Arguments Returns: 0 (Zero) exitcode \"\"\" return 0","title":"main()"},{"location":"package_docs/cli/manual/","text":"Manual ( YChaosSubCommand ) \u00b6 Used to print the manual for the entire CLI command. Can be used to auto-generate Markdown docs for the YChaos CLI by passing the -f/--file argument. In case, a file is not passed, the markdown is printed on the console. Source code in cli/manual.py class Manual ( YChaosSubCommand ): \"\"\" Used to print the manual for the entire CLI command. Can be used to auto-generate Markdown docs for the YChaos CLI by passing the `-f/--file` argument. In case, a file is not passed, the markdown is printed on the console. \"\"\" name = \"manual\" help = \"Print the manual for YChaos CLI\" def __init__ ( self , ** kwargs ): super ( Manual , self ) . __init__ ( ** kwargs ) self . file : Optional [ Path ] = kwargs . pop ( \"file\" , None ) @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser . add_argument ( \"-f\" , \"--file\" , type = Path , help = \"Print YChaos CLI Manual to a file\" , required = False , metavar = \"path\" , ) return parser def do_print_manual_entry ( self ): tempfile = StringIO () for cmd , msg in self . app . manual_entry () . items (): tempfile . write ( f \" { '#' * len ( cmd . split ()) } { cmd } \" ) tempfile . write ( \" \\n \" ) tempfile . write ( \"``` \\n \" ) tempfile . write ( msg ) tempfile . write ( \" \\n ``` \\n \" ) if self . file is not None : try : self . file . write_text ( tempfile . getvalue ()) self . console . log ( f \" { self . app . settings . PROG } manual entry written to { self . file } \" ) except FileNotFoundError as file_not_found_error : self . set_exitcode ( 1 ) self . console . print ( f \":mag: { self . file } [italic]not found[/italic]\" , style = \"indian_red\" , ) except IsADirectoryError as is_a_directory_error : self . set_exitcode ( 1 ) self . console . print ( f \":file_folder: The input path ( { self . file } ) is a directory\" ) else : self . console . print ( Markdown ( tempfile . getvalue ())) @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover manual = cls ( ** vars ( args )) manual . do_print_manual_entry () return manual . _exitcode build_parser ( parser ) classmethod \u00b6 Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/manual.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser . add_argument ( \"-f\" , \"--file\" , type = Path , help = \"Print YChaos CLI Manual to a file\" , required = False , metavar = \"path\" , ) return parser main ( args ) classmethod \u00b6 Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/manual.py @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover manual = cls ( ** vars ( args )) manual . do_print_manual_entry () return manual . _exitcode","title":"manual"},{"location":"package_docs/cli/manual/#ychaos.cli.manual.Manual","text":"Used to print the manual for the entire CLI command. Can be used to auto-generate Markdown docs for the YChaos CLI by passing the -f/--file argument. In case, a file is not passed, the markdown is printed on the console. Source code in cli/manual.py class Manual ( YChaosSubCommand ): \"\"\" Used to print the manual for the entire CLI command. Can be used to auto-generate Markdown docs for the YChaos CLI by passing the `-f/--file` argument. In case, a file is not passed, the markdown is printed on the console. \"\"\" name = \"manual\" help = \"Print the manual for YChaos CLI\" def __init__ ( self , ** kwargs ): super ( Manual , self ) . __init__ ( ** kwargs ) self . file : Optional [ Path ] = kwargs . pop ( \"file\" , None ) @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser . add_argument ( \"-f\" , \"--file\" , type = Path , help = \"Print YChaos CLI Manual to a file\" , required = False , metavar = \"path\" , ) return parser def do_print_manual_entry ( self ): tempfile = StringIO () for cmd , msg in self . app . manual_entry () . items (): tempfile . write ( f \" { '#' * len ( cmd . split ()) } { cmd } \" ) tempfile . write ( \" \\n \" ) tempfile . write ( \"``` \\n \" ) tempfile . write ( msg ) tempfile . write ( \" \\n ``` \\n \" ) if self . file is not None : try : self . file . write_text ( tempfile . getvalue ()) self . console . log ( f \" { self . app . settings . PROG } manual entry written to { self . file } \" ) except FileNotFoundError as file_not_found_error : self . set_exitcode ( 1 ) self . console . print ( f \":mag: { self . file } [italic]not found[/italic]\" , style = \"indian_red\" , ) except IsADirectoryError as is_a_directory_error : self . set_exitcode ( 1 ) self . console . print ( f \":file_folder: The input path ( { self . file } ) is a directory\" ) else : self . console . print ( Markdown ( tempfile . getvalue ())) @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover manual = cls ( ** vars ( args )) manual . do_print_manual_entry () return manual . _exitcode","title":"Manual"},{"location":"package_docs/cli/manual/#ychaos.cli.manual.Manual.build_parser","text":"Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/manual.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser . add_argument ( \"-f\" , \"--file\" , type = Path , help = \"Print YChaos CLI Manual to a file\" , required = False , metavar = \"path\" , ) return parser","title":"build_parser()"},{"location":"package_docs/cli/manual/#ychaos.cli.manual.Manual.main","text":"Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/manual.py @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover manual = cls ( ** vars ( args )) manual . do_print_manual_entry () return manual . _exitcode","title":"main()"},{"location":"package_docs/cli/mock/","text":"MockApp ( App ) \u00b6 This will create a mocked application similar to App whose console output will be tracked by a StringIO object for verification. This is not to be used for production and only for testing purposes. Source code in cli/mock.py class MockApp ( App ): \"\"\" This will create a mocked application similar to [App][ychaos.cli.main.App] whose console output will be tracked by a StringIO object for verification. This is not to be used for production and only for testing purposes. \"\"\" def __init__ ( self , args : Namespace ): if \"config\" not in args : args . config = \"dev\" if \"verbose\" not in args : args . verbose = 0 if \"log_file\" not in args : args . log_file = None if \"no_color\" not in args : args . no_color = None super ( MockApp , self ) . __init__ ( args ) self . console = Console ( file = StringIO (), width = 150 ) def get_console_output ( self ) -> str : \"\"\" Returns the entire console output printed by the CLI application during its run Returns: String \"\"\" assert isinstance ( self . console . file , StringIO ) return self . console . file . getvalue () get_console_output ( self ) \u00b6 Returns the entire console output printed by the CLI application during its run Returns: Type Description str String Source code in cli/mock.py def get_console_output ( self ) -> str : \"\"\" Returns the entire console output printed by the CLI application during its run Returns: String \"\"\" assert isinstance ( self . console . file , StringIO ) return self . console . file . getvalue ()","title":"mock"},{"location":"package_docs/cli/mock/#ychaos.cli.mock.MockApp","text":"This will create a mocked application similar to App whose console output will be tracked by a StringIO object for verification. This is not to be used for production and only for testing purposes. Source code in cli/mock.py class MockApp ( App ): \"\"\" This will create a mocked application similar to [App][ychaos.cli.main.App] whose console output will be tracked by a StringIO object for verification. This is not to be used for production and only for testing purposes. \"\"\" def __init__ ( self , args : Namespace ): if \"config\" not in args : args . config = \"dev\" if \"verbose\" not in args : args . verbose = 0 if \"log_file\" not in args : args . log_file = None if \"no_color\" not in args : args . no_color = None super ( MockApp , self ) . __init__ ( args ) self . console = Console ( file = StringIO (), width = 150 ) def get_console_output ( self ) -> str : \"\"\" Returns the entire console output printed by the CLI application during its run Returns: String \"\"\" assert isinstance ( self . console . file , StringIO ) return self . console . file . getvalue ()","title":"MockApp"},{"location":"package_docs/cli/mock/#ychaos.cli.mock.MockApp.get_console_output","text":"Returns the entire console output printed by the CLI application during its run Returns: Type Description str String Source code in cli/mock.py def get_console_output ( self ) -> str : \"\"\" Returns the entire console output printed by the CLI application during its run Returns: String \"\"\" assert isinstance ( self . console . file , StringIO ) return self . console . file . getvalue ()","title":"get_console_output()"},{"location":"package_docs/cli/verify/","text":"Verify ( YChaosTestplanInputSubCommand ) \u00b6 The verify subcommand of YChaos is used to verify the state of the system. This subcommand requires a valid testplan which can be provided with the -t/--testplan argument. The subcommand also requires a valid state at which the system is verified. Source code in cli/verify.py class Verify ( YChaosTestplanInputSubCommand ): \"\"\" The `verify` subcommand of YChaos is used to verify the state of the system. This subcommand requires a valid testplan which can be provided with the -t/--testplan argument. The subcommand also requires a valid state at which the system is verified. \"\"\" name = \"verify\" help = \"The verification subcommand of YChaos\" def __init__ ( self , ** kwargs ): super ( Verify , self ) . __init__ ( ** kwargs ) self . test_plan_path : Path = kwargs . pop ( \"testplan\" ) self . state : SystemState = SystemState ( kwargs . pop ( \"state\" , None ) . upper ()) self . dump_yaml : Optional [ Path ] = kwargs . pop ( \"dump_yaml\" , None ) self . dump_json : Optional [ Path ] = kwargs . pop ( \"dump_json\" , None ) self . state_data_path : Optional [ Path ] = kwargs . pop ( \"state_data\" , None ) @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser = super ( Verify , cls ) . build_parser ( parser ) parser . add_argument ( \"-s\" , \"--state\" , choices = [ x . value . lower () for x in list ( SystemState )], help = \"System state to verify\" , default = \"steady\" , metavar = \"state\" , ) report_argument_group = parser . add_argument_group ( \"verification reports\" ) report_argument_group . add_argument ( \"--dump-yaml\" , type = Path , help = \"Store the verification data in YAML format\" , required = False , metavar = \"path\" , ) report_argument_group . add_argument ( \"--dump-json\" , type = Path , help = \"Store the verification data in JSON format\" , required = False , metavar = \"path\" , ) parser . add_argument ( \"--state-data\" , type = Path , help = \"The path of the verification data state file (JSON/YAML)\" , required = False , metavar = \"path\" , ) return parser def get_state_data ( self ): self . console . log ( \"Getting state data\" ) self . console . line () try : import yaml path = Path ( self . state_data_path ) with open ( path , \"r\" ) as file : state_data = yaml . safe_load ( file ) return state_data except IsADirectoryError as is_directory : self . set_exitcode ( 1 ) self . console . print ( f \":file_folder: The input path ( { self . state_data_path } ) is not a valid state data file\" , style = \"indian_red\" , ) except FileNotFoundError as file_not_found_error : self . set_exitcode ( 1 ) self . console . print ( \":mag: {file} [italic]not found[/italic]\" . format ( file = str ( self . state_data_path ) ), style = \"indian_red\" , ) return None @validate_arguments ( config = dict ( arbitrary_types_allowed = True )) def _generate_verification_report ( self , verification_controller : VerificationController , output_format : str , report_file_path : Union [ Path , str ], ): self . console . log ( f \"Writing { self . state . value . lower () } state verification data to { report_file_path } , format= { output_format } \" ) report_output_base_path = Path ( report_file_path ) . parent try : if not report_output_base_path . is_dir (): report_output_base_path . mkdir ( parents = True , exist_ok = True ) except PermissionError as permission_error : self . console . log ( \":file_folder: [italic]Permission denied to create report directory[/italic]\" , style = \"indian_red\" , ) return try : with open ( report_file_path , \"w\" ) as fp : verification_controller . dump_verification ( fp , output_format = output_format ) except PermissionError as permission_error : self . console . log ( \":file_folder: [italic]Permission denied to create report file[/italic]\" , style = \"indian_red\" , ) def verify_system_state ( self ): testplan = self . get_validated_test_plan ( self . test_plan_path ) if self . _exitcode != 0 : return state_data = list () if self . state_data_path : state_data = self . get_state_data () if self . _exitcode != 0 : return # section Hooks class VerificationHook ( YChaosCLIHook , ABC ): def __init__ ( self , app , state : SystemState ): super ( VerificationHook , self ) . __init__ ( app ) self . state = state class OnEachPluginStartHook ( VerificationHook ): def __call__ ( self , index : int , config : VerificationConfig ): self . console . log ( f \"Running [i] { self . state . value . lower () } [/i] state verification of type= { config . type . value } [ { index } ]\" ) class OnPluginNotFoundHook ( VerificationHook ): def __call__ ( self , index : int , plugin_type : VerificationType ): self . console . log ( f \"The verification plugin type=[i] { plugin_type . value } [/i][ { index } ] is not available for use.\" ) class OnEachPluginEndHook ( VerificationHook ): def __call__ ( self , index : int , config : VerificationConfig , verified_state_data : VerificationStateData , ): self . console . log ( ( f \"Completed [i] { self . state . value . lower () } [/i] state verification of type= { config . type . value } ;\" f \" verified= { verified_state_data . rc == 0 } \" ) ) # end section verification_controller = VerificationController ( testplan , self . state , state_data ) verification_controller . register_hook ( \"on_each_plugin_start\" , OnEachPluginStartHook ( self . app , self . state ) ) verification_controller . register_hook ( \"on_each_plugin_end\" , OnEachPluginEndHook ( self . app , self . state ) ) verification_controller . register_hook ( \"on_plugin_not_found\" , OnPluginNotFoundHook ( self . app , self . state ) ) self . console . log ( f \"Starting [i] { self . state . value . lower () } [/i] state verification.\" ) is_verified = verification_controller . execute () self . set_exitcode ( int ( not is_verified )) self . console . line () if is_verified : self . console . print ( f \"The system is verified to be in { self . state . value . lower () } state\" , style = \"green\" , ) else : self . console . print ( f \"The system is not verified to be in { self . state . value . lower () } state\" , style = \"red\" , ) self . console . line () if self . dump_json : self . _generate_verification_report ( verification_controller , report_file_path = self . dump_json , output_format = \"json\" , ) if self . dump_yaml : self . _generate_verification_report ( verification_controller , report_file_path = self . dump_yaml , output_format = \"yaml\" , ) @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover verification_command = Verify ( ** vars ( args )) verification_command . verify_system_state () return verification_command . _exitcode build_parser ( parser ) classmethod \u00b6 Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/verify.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser = super ( Verify , cls ) . build_parser ( parser ) parser . add_argument ( \"-s\" , \"--state\" , choices = [ x . value . lower () for x in list ( SystemState )], help = \"System state to verify\" , default = \"steady\" , metavar = \"state\" , ) report_argument_group = parser . add_argument_group ( \"verification reports\" ) report_argument_group . add_argument ( \"--dump-yaml\" , type = Path , help = \"Store the verification data in YAML format\" , required = False , metavar = \"path\" , ) report_argument_group . add_argument ( \"--dump-json\" , type = Path , help = \"Store the verification data in JSON format\" , required = False , metavar = \"path\" , ) parser . add_argument ( \"--state-data\" , type = Path , help = \"The path of the verification data state file (JSON/YAML)\" , required = False , metavar = \"path\" , ) return parser main ( args ) classmethod \u00b6 Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/verify.py @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover verification_command = Verify ( ** vars ( args )) verification_command . verify_system_state () return verification_command . _exitcode","title":"veriify"},{"location":"package_docs/cli/verify/#ychaos.cli.verify.Verify","text":"The verify subcommand of YChaos is used to verify the state of the system. This subcommand requires a valid testplan which can be provided with the -t/--testplan argument. The subcommand also requires a valid state at which the system is verified. Source code in cli/verify.py class Verify ( YChaosTestplanInputSubCommand ): \"\"\" The `verify` subcommand of YChaos is used to verify the state of the system. This subcommand requires a valid testplan which can be provided with the -t/--testplan argument. The subcommand also requires a valid state at which the system is verified. \"\"\" name = \"verify\" help = \"The verification subcommand of YChaos\" def __init__ ( self , ** kwargs ): super ( Verify , self ) . __init__ ( ** kwargs ) self . test_plan_path : Path = kwargs . pop ( \"testplan\" ) self . state : SystemState = SystemState ( kwargs . pop ( \"state\" , None ) . upper ()) self . dump_yaml : Optional [ Path ] = kwargs . pop ( \"dump_yaml\" , None ) self . dump_json : Optional [ Path ] = kwargs . pop ( \"dump_json\" , None ) self . state_data_path : Optional [ Path ] = kwargs . pop ( \"state_data\" , None ) @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser = super ( Verify , cls ) . build_parser ( parser ) parser . add_argument ( \"-s\" , \"--state\" , choices = [ x . value . lower () for x in list ( SystemState )], help = \"System state to verify\" , default = \"steady\" , metavar = \"state\" , ) report_argument_group = parser . add_argument_group ( \"verification reports\" ) report_argument_group . add_argument ( \"--dump-yaml\" , type = Path , help = \"Store the verification data in YAML format\" , required = False , metavar = \"path\" , ) report_argument_group . add_argument ( \"--dump-json\" , type = Path , help = \"Store the verification data in JSON format\" , required = False , metavar = \"path\" , ) parser . add_argument ( \"--state-data\" , type = Path , help = \"The path of the verification data state file (JSON/YAML)\" , required = False , metavar = \"path\" , ) return parser def get_state_data ( self ): self . console . log ( \"Getting state data\" ) self . console . line () try : import yaml path = Path ( self . state_data_path ) with open ( path , \"r\" ) as file : state_data = yaml . safe_load ( file ) return state_data except IsADirectoryError as is_directory : self . set_exitcode ( 1 ) self . console . print ( f \":file_folder: The input path ( { self . state_data_path } ) is not a valid state data file\" , style = \"indian_red\" , ) except FileNotFoundError as file_not_found_error : self . set_exitcode ( 1 ) self . console . print ( \":mag: {file} [italic]not found[/italic]\" . format ( file = str ( self . state_data_path ) ), style = \"indian_red\" , ) return None @validate_arguments ( config = dict ( arbitrary_types_allowed = True )) def _generate_verification_report ( self , verification_controller : VerificationController , output_format : str , report_file_path : Union [ Path , str ], ): self . console . log ( f \"Writing { self . state . value . lower () } state verification data to { report_file_path } , format= { output_format } \" ) report_output_base_path = Path ( report_file_path ) . parent try : if not report_output_base_path . is_dir (): report_output_base_path . mkdir ( parents = True , exist_ok = True ) except PermissionError as permission_error : self . console . log ( \":file_folder: [italic]Permission denied to create report directory[/italic]\" , style = \"indian_red\" , ) return try : with open ( report_file_path , \"w\" ) as fp : verification_controller . dump_verification ( fp , output_format = output_format ) except PermissionError as permission_error : self . console . log ( \":file_folder: [italic]Permission denied to create report file[/italic]\" , style = \"indian_red\" , ) def verify_system_state ( self ): testplan = self . get_validated_test_plan ( self . test_plan_path ) if self . _exitcode != 0 : return state_data = list () if self . state_data_path : state_data = self . get_state_data () if self . _exitcode != 0 : return # section Hooks class VerificationHook ( YChaosCLIHook , ABC ): def __init__ ( self , app , state : SystemState ): super ( VerificationHook , self ) . __init__ ( app ) self . state = state class OnEachPluginStartHook ( VerificationHook ): def __call__ ( self , index : int , config : VerificationConfig ): self . console . log ( f \"Running [i] { self . state . value . lower () } [/i] state verification of type= { config . type . value } [ { index } ]\" ) class OnPluginNotFoundHook ( VerificationHook ): def __call__ ( self , index : int , plugin_type : VerificationType ): self . console . log ( f \"The verification plugin type=[i] { plugin_type . value } [/i][ { index } ] is not available for use.\" ) class OnEachPluginEndHook ( VerificationHook ): def __call__ ( self , index : int , config : VerificationConfig , verified_state_data : VerificationStateData , ): self . console . log ( ( f \"Completed [i] { self . state . value . lower () } [/i] state verification of type= { config . type . value } ;\" f \" verified= { verified_state_data . rc == 0 } \" ) ) # end section verification_controller = VerificationController ( testplan , self . state , state_data ) verification_controller . register_hook ( \"on_each_plugin_start\" , OnEachPluginStartHook ( self . app , self . state ) ) verification_controller . register_hook ( \"on_each_plugin_end\" , OnEachPluginEndHook ( self . app , self . state ) ) verification_controller . register_hook ( \"on_plugin_not_found\" , OnPluginNotFoundHook ( self . app , self . state ) ) self . console . log ( f \"Starting [i] { self . state . value . lower () } [/i] state verification.\" ) is_verified = verification_controller . execute () self . set_exitcode ( int ( not is_verified )) self . console . line () if is_verified : self . console . print ( f \"The system is verified to be in { self . state . value . lower () } state\" , style = \"green\" , ) else : self . console . print ( f \"The system is not verified to be in { self . state . value . lower () } state\" , style = \"red\" , ) self . console . line () if self . dump_json : self . _generate_verification_report ( verification_controller , report_file_path = self . dump_json , output_format = \"json\" , ) if self . dump_yaml : self . _generate_verification_report ( verification_controller , report_file_path = self . dump_yaml , output_format = \"yaml\" , ) @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover verification_command = Verify ( ** vars ( args )) verification_command . verify_system_state () return verification_command . _exitcode","title":"Verify"},{"location":"package_docs/cli/verify/#ychaos.cli.verify.Verify.build_parser","text":"Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/verify.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : parser = super ( Verify , cls ) . build_parser ( parser ) parser . add_argument ( \"-s\" , \"--state\" , choices = [ x . value . lower () for x in list ( SystemState )], help = \"System state to verify\" , default = \"steady\" , metavar = \"state\" , ) report_argument_group = parser . add_argument_group ( \"verification reports\" ) report_argument_group . add_argument ( \"--dump-yaml\" , type = Path , help = \"Store the verification data in YAML format\" , required = False , metavar = \"path\" , ) report_argument_group . add_argument ( \"--dump-json\" , type = Path , help = \"Store the verification data in JSON format\" , required = False , metavar = \"path\" , ) parser . add_argument ( \"--state-data\" , type = Path , help = \"The path of the verification data state file (JSON/YAML)\" , required = False , metavar = \"path\" , ) return parser","title":"build_parser()"},{"location":"package_docs/cli/verify/#ychaos.cli.verify.Verify.main","text":"Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/verify.py @classmethod def main ( cls , args : Namespace ) -> Any : # pragma: no cover verification_command = Verify ( ** vars ( args )) verification_command . verify_system_state () return verification_command . _exitcode","title":"main()"},{"location":"package_docs/cli/agent/attack/","text":"Attack ( YChaosTestplanInputSubCommand ) \u00b6 Agent Attack subcommand is used to perform the attack on the target. This subcommand requires a valid testplan to perforrm the required attack on the target system. Source code in cli/agent/attack.py class Attack ( YChaosTestplanInputSubCommand ): \"\"\" Agent Attack subcommand is used to perform the attack on the target. This subcommand requires a valid testplan to perforrm the required attack on the target system. \"\"\" name = \"attack\" help = \"YChaos Agent Attack Subcommand\" @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : super ( Attack , cls ) . build_parser ( parser ) parser . add_argument ( \"--attack-report-yaml\" , type = Path , help = \"File Path to store attack report in YAML format\" , default = None , metavar = \"path\" , ) return parser def __init__ ( self , ** kwargs ): super ( Attack , self ) . __init__ ( ** kwargs ) self . test_plan_path : Path = kwargs . pop ( \"testplan\" ) self . attack_report_yaml_path : Optional [ Path ] = kwargs . pop ( \"attack_report_yaml\" ) if self . attack_report_yaml_path and self . attack_report_yaml_path . is_dir (): self . console . log ( f \" { self . attack_report_yaml_path } is not a valid file path\" ) self . attack_report_yaml_path = None self . test_plan : Optional [ TestPlan ] = None self . coordinator : Optional [ Coordinator ] = None def validate_and_load_test_plan ( self ) -> int : self . test_plan = super ( Attack , self ) . get_validated_test_plan ( self . test_plan_path ) return self . _exitcode def configure_attack ( self ): self . coordinator = Coordinator ( self . test_plan ) class YChaosAgentAttackCLIHook ( YChaosCLIHook ): def __init__ ( self , app ): super ( YChaosAgentAttackCLIHook , self ) . __init__ ( app ) class OnAttackStart ( YChaosAgentAttackCLIHook ): def __call__ ( self ): self . console . log ( \"Attack Started\" ) class OnAttackCompleted ( YChaosCLIHook ): def __call__ ( self ): self . console . log ( \"Attack Ended\" ) class OnAgentStart ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Started\" ) class OnAgentTeardown ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Teardown started\" ) class OnAgentStop ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Stopped\" ) self . coordinator . register_hook ( \"on_attack_start\" , OnAttackStart ( self . app )) self . coordinator . register_hook ( \"on_attack_completed\" , OnAttackCompleted ( self . app ), ) self . coordinator . register_hook ( \"on_each_agent_start\" , OnAgentStart ( self . app )) self . coordinator . register_hook ( \"on_each_agent_teardown\" , OnAgentTeardown ( self . app ), ) self . coordinator . register_hook ( \"on_each_agent_stop\" , OnAgentStop ( self . app )) self . coordinator . configure_agent_in_test_plan () table = Table ( Column ( \"Agent\" , style = \"green\" ), Column ( \"Start Delay\" , justify = \"center\" , style = \"green\" ), Column ( \"Start Time\" , style = \"green\" ), Column ( \"End Time\" , style = \"green\" ), title = \"Configured Agents\" , show_header = True , header_style = \"bold magenta\" , ) for configured_agent in self . coordinator . configured_agents : table . add_row ( configured_agent . agent . config . name , str ( configured_agent . agent . config . start_delay ), str ( configured_agent . start_time ), str ( configured_agent . end_time ) if hasattr ( configured_agent . agent . config , \"duration\" ) else \"Unknown\" , ) self . console . print ( table ) def print_all_errors ( self ): all_exceptions = self . coordinator . get_all_exceptions () for e in all_exceptions : try : raise e except Exception : self . console . print_exception () def dump_attack_report ( self ): if self . attack_report_yaml_path : import yaml with open ( self . attack_report_yaml_path , \"w\" , ) as fp : yaml . dump ( self . coordinator . generate_attack_report (), fp , default_flow_style = False , sort_keys = False , Dumper = Dumper , indent = 4 , ) self . console . log ( f \"Attack report stored at { self . attack_report_yaml_path } \" ) @classmethod def main ( cls , args : Namespace ) -> Any : agent = cls ( ** vars ( args )) if agent . _exitcode : return agent . _exitcode if not agent . validate_and_load_test_plan (): agent . configure_attack () assert agent . coordinator is not None agent . coordinator . start_attack () agent . print_all_errors () agent . dump_attack_report () if agent . _exitcode or agent . coordinator . get_exit_status (): agent . console . log ( \"Attack failed\" ) agent . set_exitcode ( 1 ) return agent . _exitcode build_parser ( parser ) classmethod \u00b6 Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/agent/attack.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : super ( Attack , cls ) . build_parser ( parser ) parser . add_argument ( \"--attack-report-yaml\" , type = Path , help = \"File Path to store attack report in YAML format\" , default = None , metavar = \"path\" , ) return parser main ( args ) classmethod \u00b6 Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/agent/attack.py @classmethod def main ( cls , args : Namespace ) -> Any : agent = cls ( ** vars ( args )) if agent . _exitcode : return agent . _exitcode if not agent . validate_and_load_test_plan (): agent . configure_attack () assert agent . coordinator is not None agent . coordinator . start_attack () agent . print_all_errors () agent . dump_attack_report () if agent . _exitcode or agent . coordinator . get_exit_status (): agent . console . log ( \"Attack failed\" ) agent . set_exitcode ( 1 ) return agent . _exitcode","title":"attack"},{"location":"package_docs/cli/agent/attack/#ychaos.cli.agent.attack.Attack","text":"Agent Attack subcommand is used to perform the attack on the target. This subcommand requires a valid testplan to perforrm the required attack on the target system. Source code in cli/agent/attack.py class Attack ( YChaosTestplanInputSubCommand ): \"\"\" Agent Attack subcommand is used to perform the attack on the target. This subcommand requires a valid testplan to perforrm the required attack on the target system. \"\"\" name = \"attack\" help = \"YChaos Agent Attack Subcommand\" @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : super ( Attack , cls ) . build_parser ( parser ) parser . add_argument ( \"--attack-report-yaml\" , type = Path , help = \"File Path to store attack report in YAML format\" , default = None , metavar = \"path\" , ) return parser def __init__ ( self , ** kwargs ): super ( Attack , self ) . __init__ ( ** kwargs ) self . test_plan_path : Path = kwargs . pop ( \"testplan\" ) self . attack_report_yaml_path : Optional [ Path ] = kwargs . pop ( \"attack_report_yaml\" ) if self . attack_report_yaml_path and self . attack_report_yaml_path . is_dir (): self . console . log ( f \" { self . attack_report_yaml_path } is not a valid file path\" ) self . attack_report_yaml_path = None self . test_plan : Optional [ TestPlan ] = None self . coordinator : Optional [ Coordinator ] = None def validate_and_load_test_plan ( self ) -> int : self . test_plan = super ( Attack , self ) . get_validated_test_plan ( self . test_plan_path ) return self . _exitcode def configure_attack ( self ): self . coordinator = Coordinator ( self . test_plan ) class YChaosAgentAttackCLIHook ( YChaosCLIHook ): def __init__ ( self , app ): super ( YChaosAgentAttackCLIHook , self ) . __init__ ( app ) class OnAttackStart ( YChaosAgentAttackCLIHook ): def __call__ ( self ): self . console . log ( \"Attack Started\" ) class OnAttackCompleted ( YChaosCLIHook ): def __call__ ( self ): self . console . log ( \"Attack Ended\" ) class OnAgentStart ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Started\" ) class OnAgentTeardown ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Teardown started\" ) class OnAgentStop ( YChaosAgentAttackCLIHook ): def __call__ ( self , agent_name : str ): self . console . log ( f \"Agent: { agent_name } - Stopped\" ) self . coordinator . register_hook ( \"on_attack_start\" , OnAttackStart ( self . app )) self . coordinator . register_hook ( \"on_attack_completed\" , OnAttackCompleted ( self . app ), ) self . coordinator . register_hook ( \"on_each_agent_start\" , OnAgentStart ( self . app )) self . coordinator . register_hook ( \"on_each_agent_teardown\" , OnAgentTeardown ( self . app ), ) self . coordinator . register_hook ( \"on_each_agent_stop\" , OnAgentStop ( self . app )) self . coordinator . configure_agent_in_test_plan () table = Table ( Column ( \"Agent\" , style = \"green\" ), Column ( \"Start Delay\" , justify = \"center\" , style = \"green\" ), Column ( \"Start Time\" , style = \"green\" ), Column ( \"End Time\" , style = \"green\" ), title = \"Configured Agents\" , show_header = True , header_style = \"bold magenta\" , ) for configured_agent in self . coordinator . configured_agents : table . add_row ( configured_agent . agent . config . name , str ( configured_agent . agent . config . start_delay ), str ( configured_agent . start_time ), str ( configured_agent . end_time ) if hasattr ( configured_agent . agent . config , \"duration\" ) else \"Unknown\" , ) self . console . print ( table ) def print_all_errors ( self ): all_exceptions = self . coordinator . get_all_exceptions () for e in all_exceptions : try : raise e except Exception : self . console . print_exception () def dump_attack_report ( self ): if self . attack_report_yaml_path : import yaml with open ( self . attack_report_yaml_path , \"w\" , ) as fp : yaml . dump ( self . coordinator . generate_attack_report (), fp , default_flow_style = False , sort_keys = False , Dumper = Dumper , indent = 4 , ) self . console . log ( f \"Attack report stored at { self . attack_report_yaml_path } \" ) @classmethod def main ( cls , args : Namespace ) -> Any : agent = cls ( ** vars ( args )) if agent . _exitcode : return agent . _exitcode if not agent . validate_and_load_test_plan (): agent . configure_attack () assert agent . coordinator is not None agent . coordinator . start_attack () agent . print_all_errors () agent . dump_attack_report () if agent . _exitcode or agent . coordinator . get_exit_status (): agent . console . log ( \"Attack failed\" ) agent . set_exitcode ( 1 ) return agent . _exitcode","title":"Attack"},{"location":"package_docs/cli/agent/attack/#ychaos.cli.agent.attack.Attack.build_parser","text":"Called from the SubCommandParser to add arguments, parsers to the subparser created from Argparse. The subclasses inheriting this class, can add arguments to this subparser Parameters: Name Type Description Default parser ArgumentParser Subparser object required Returns: Type Description ArgumentParser Parser object with arguments, optionals, subparsers attached. Source code in cli/agent/attack.py @classmethod def build_parser ( cls , parser : ArgumentParser ) -> ArgumentParser : super ( Attack , cls ) . build_parser ( parser ) parser . add_argument ( \"--attack-report-yaml\" , type = Path , help = \"File Path to store attack report in YAML format\" , default = None , metavar = \"path\" , ) return parser","title":"build_parser()"},{"location":"package_docs/cli/agent/attack/#ychaos.cli.agent.attack.Attack.main","text":"Defines the Program Logic to be executed when this subcommand is invoked. This method is called with one argument args of type Namespace which contains the parsed values. Parameters: Name Type Description Default args Namespace Namespace arguments parsed from the input required Returns: Type Description Any Any Source code in cli/agent/attack.py @classmethod def main ( cls , args : Namespace ) -> Any : agent = cls ( ** vars ( args )) if agent . _exitcode : return agent . _exitcode if not agent . validate_and_load_test_plan (): agent . configure_attack () assert agent . coordinator is not None agent . coordinator . start_attack () agent . print_all_errors () agent . dump_attack_report () if agent . _exitcode or agent . coordinator . get_exit_status (): agent . console . log ( \"Attack failed\" ) agent . set_exitcode ( 1 ) return agent . _exitcode","title":"main()"},{"location":"package_docs/core/executor/BaseExecutor/","text":"BaseExecutor ( EventHook , ABC ) \u00b6 TargetExecutor defines the target where the agents are executed to test the resiliency of the system. A simple example of Target Executor is the MachineTargetExecutor which holds the program logic to execute the agents (with Coordinator) in Virtual Machines/BareMetals Each new Target Executor overrides the execute() method which defines \"what\" is to be done to execute the agents in a particular target environment. This class extends the EventHook class, which implies each of the target executor can define its own events and the hooks that will be called during the trigger of an event. Source code in core/executor/BaseExecutor.py class BaseExecutor ( EventHook , ABC ): \"\"\" TargetExecutor defines the target where the agents are executed to test the resiliency of the system. A simple example of Target Executor is the [MachineTargetExecutor][ychaos.core.executor.MachineTargetExecutor.MachineTargetExecutor] which holds the program logic to execute the agents (with Coordinator) in Virtual Machines/BareMetals Each new Target Executor overrides the `execute()` method which defines \"what\" is to be done to execute the agents in a particular target environment. This class extends the [EventHook][ychaos.utils.hooks.EventHook] class, which implies each of the target executor can define its own events and the hooks that will be called during the trigger of an event. \"\"\" __target_type__ : str def __init__ ( self , testplan : TestPlan , * args , ** kwargs ): super ( BaseExecutor , self ) . __init__ () self . testplan = testplan self . _validate_target_config () def _get_target_type ( self ): # To avoid circular import from ...testplan.attack import TargetType return TargetType ( self . __target_type__ ) def _validate_target_config ( self ): target_config = self . testplan . attack . get_target_config () if self . testplan . attack . target_type != self . _get_target_type (): raise YChaosTargetConfigConditionFailedError ( \"Target type mismatch\" ) # Even though ideally this branch is never entered by the code (unless there is some issue with pydantic) if not isinstance ( target_config , self . _get_target_type () . metadata . schema ): # pragma: no cover raise YChaosTargetConfigConditionFailedError ( \"Target configuration is not processable for this executor\" ) @abstractmethod def execute ( self ) -> None : \"\"\" Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: None \"\"\" pass # Implement in Executors execute ( self ) \u00b6 Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/BaseExecutor.py @abstractmethod def execute ( self ) -> None : \"\"\" Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: None \"\"\" pass # Implement in Executors","title":"BaseExecutor"},{"location":"package_docs/core/executor/BaseExecutor/#ychaos.core.executor.BaseExecutor.BaseExecutor","text":"TargetExecutor defines the target where the agents are executed to test the resiliency of the system. A simple example of Target Executor is the MachineTargetExecutor which holds the program logic to execute the agents (with Coordinator) in Virtual Machines/BareMetals Each new Target Executor overrides the execute() method which defines \"what\" is to be done to execute the agents in a particular target environment. This class extends the EventHook class, which implies each of the target executor can define its own events and the hooks that will be called during the trigger of an event. Source code in core/executor/BaseExecutor.py class BaseExecutor ( EventHook , ABC ): \"\"\" TargetExecutor defines the target where the agents are executed to test the resiliency of the system. A simple example of Target Executor is the [MachineTargetExecutor][ychaos.core.executor.MachineTargetExecutor.MachineTargetExecutor] which holds the program logic to execute the agents (with Coordinator) in Virtual Machines/BareMetals Each new Target Executor overrides the `execute()` method which defines \"what\" is to be done to execute the agents in a particular target environment. This class extends the [EventHook][ychaos.utils.hooks.EventHook] class, which implies each of the target executor can define its own events and the hooks that will be called during the trigger of an event. \"\"\" __target_type__ : str def __init__ ( self , testplan : TestPlan , * args , ** kwargs ): super ( BaseExecutor , self ) . __init__ () self . testplan = testplan self . _validate_target_config () def _get_target_type ( self ): # To avoid circular import from ...testplan.attack import TargetType return TargetType ( self . __target_type__ ) def _validate_target_config ( self ): target_config = self . testplan . attack . get_target_config () if self . testplan . attack . target_type != self . _get_target_type (): raise YChaosTargetConfigConditionFailedError ( \"Target type mismatch\" ) # Even though ideally this branch is never entered by the code (unless there is some issue with pydantic) if not isinstance ( target_config , self . _get_target_type () . metadata . schema ): # pragma: no cover raise YChaosTargetConfigConditionFailedError ( \"Target configuration is not processable for this executor\" ) @abstractmethod def execute ( self ) -> None : \"\"\" Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: None \"\"\" pass # Implement in Executors","title":"BaseExecutor"},{"location":"package_docs/core/executor/BaseExecutor/#ychaos.core.executor.BaseExecutor.BaseExecutor.execute","text":"Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/BaseExecutor.py @abstractmethod def execute ( self ) -> None : \"\"\" Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: None \"\"\" pass # Implement in Executors","title":"execute()"},{"location":"package_docs/core/executor/MachineTargetExecutor/","text":"MachineTargetExecutor ( BaseExecutor ) \u00b6 The executor that executes the agent on a set of Virtual machines/Bare metals by connecting to the hosts via SSH. The input for the executor is the testplan, within which, the target_type is defined as machine . The target_config will provide the list of hosts out of which random blast_radius % of the hosts is selected for attack. The following are the valid hooks to this executor Valid Hooks \u00b6 on_start Called when starting to run the Ansible playbook. def callable_hook (): ... on_no_targets_found Called when no targets are found to attack. Either blast radius is too low or there are no hosts in the attack list. def callable_hook (): ... on_target_unreachable Called when a target becomes unreachable during the Ansible play def callable_hook ( result : AnsibleResult ): ... on_target_passed Called when an ansible task is passed def callable_hook ( result : AnsibleResult ): ... on_target_failed Called when an ansible task is failed def callable_hook ( result : AnsibleResult ): ... on_end Called after the end of Ansible playbook run def callable_hook ( result ): ... on_error Called when an exception is raised def callable_hook ( e : Exception ): ... Source code in core/executor/MachineTargetExecutor.py class MachineTargetExecutor ( BaseExecutor ): \"\"\" The executor that executes the agent on a set of Virtual machines/Bare metals by connecting to the hosts via SSH. The input for the executor is the testplan, within which, the target_type is defined as `machine`. The target_config will provide the list of hosts out of which random `blast_radius`% of the hosts is selected for attack. The following are the valid hooks to this executor ## Valid Hooks === \"on_start\" Called when starting to run the Ansible playbook. ```python def callable_hook(): ... ``` === \"on_no_targets_found\" Called when no targets are found to attack. Either blast radius is too low or there are no hosts in the attack list. ```python def callable_hook(): ... ``` === \"on_target_unreachable\" Called when a target becomes unreachable during the Ansible play ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_target_passed\" Called when an ansible task is passed ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_target_failed\" Called when an ansible task is failed ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_end\" Called after the end of Ansible playbook run ```python def callable_hook(result): ... ``` === \"on_error\" Called when an exception is raised ```python def callable_hook(e: Exception): ... ``` \"\"\" __target_type__ = \"machine\" # __taskresult_callable__ = EventHook.Callable(TaskResult) __hook_events__ = { \"on_no_targets_found\" : EventHook . CallableType (), \"on_start\" : EventHook . CallableType (), \"on_target_unreachable\" : EventHook . CallableType ( TaskResult ), \"on_target_failed\" : EventHook . CallableType ( TaskResult ), \"on_target_passed\" : EventHook . CallableType ( TaskResult ), \"on_error\" : EventHook . CallableType ( Exception ), \"on_end\" : EventHook . CallableType ( TaskResult ), } def __init__ ( self , testplan : TestPlan , * args , ** kwargs ): super ( MachineTargetExecutor , self ) . __init__ ( testplan ) # Selects a `blast_radius`% of hosts at random from the # effective hosts and uses it as the target hosts for the attack self . _compute_target_hosts () self . ansible_context = SimpleNamespace () self . logger = AppLogger . get_logger ( self . __class__ . __name__ ) def _compute_target_hosts ( self ): target_defn : MachineTargetDefinition = self . testplan . attack . get_target_config () effective_hosts = target_defn . get_effective_hosts () self . target_hosts = random . sample ( effective_hosts , target_defn . blast_radius * len ( effective_hosts ) // 100 ) def prepare ( self ): self . ansible_context . loader = DataLoader () self . ansible_context . results_callback = YChaosAnsibleResultCallback ( hooks = { k : v for k , v in self . hooks . items () if k in YChaosAnsibleResultCallback . __hook_events__ } ) # Hosts to be in comma separated string hosts = \",\" . join ( self . testplan . attack . get_target_config () . get_effective_hosts ()) if len ( self . testplan . attack . get_target_config () . get_effective_hosts ()) == 1 : hosts += \",\" self . ansible_context . inventory = InventoryManager ( loader = self . ansible_context . loader , sources = hosts ) self . ansible_context . variable_manager = VariableManager ( loader = self . ansible_context . loader , inventory = self . ansible_context . inventory ) self . ansible_context . tqm = TaskQueueManager ( inventory = self . ansible_context . inventory , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , passwords = dict ( vault_pass = None ), stdout_callback = self . ansible_context . results_callback , ) self . ansible_context . play_source = dict ( name = \"YChaos Ansible Play\" , hosts = \",\" . join ( self . target_hosts ), remote_user = self . testplan . attack . get_target_config () . ssh_config . user , connection = \"ssh\" , strategy = \"free\" , gather_facts = \"no\" , ignore_unreachable = \"no\" , tasks = [ dict ( name = \"Check current working directory\" , action = dict ( module = \"command\" , args = dict ( cmd = \"pwd\" )), register = \"result_pwd\" , changed_when = \"false\" , ), dict ( name = \"Check if python3 installed\" , action = dict ( module = \"command\" , args = dict ( cmd = \"which python3\" )), register = \"result_which_python3\" , changed_when = \"false\" , failed_when = [ # Fail if python3 not installed on the target \"result_which_python3.rc != 0\" ], ), dict ( name = \"Create a virtual environment\" , register = \"result_pip\" , action = dict ( module = \"pip\" , chdir = \"{{result_pwd.stdout}}\" , name = \"pip\" , state = \"latest\" , virtualenv = \"ychaos_env\" , virtualenv_command = \"{{result_which_python3.stdout}} -m venv\" , ), failed_when = [ # Failed in these following reasons # 1. pip not installed # 2. Failed to installed latest pip version \"result_pip.state == 'absent'\" ], vars = dict ( ansible_python_interpreter = \"{{result_which_python3.stdout}}\" ), ), dict ( name = \"Install ychaos[agents]\" , register = \"result_pip_install_ychaos_agents\" , action = dict ( module = \"pip\" , chdir = \"{{result_pwd.stdout}}\" , name = \"ychaos[agents]\" , virtualenv = \"ychaos_env\" , ), failed_when = [ # Failed if unable to install ychaos[agents] \"result_pip_install_ychaos_agents.state == 'absent'\" ], vars = dict ( ansible_python_interpreter = \"{{result_which_python3.stdout}}\" ), ), dict ( name = \"Create a workspace directory for storing local report files\" , register = \"result_create_workspace\" , action = dict ( module = \"file\" , path = \"{{result_pwd.stdout}}/ychaos_ws\" , state = \"directory\" , mode = \"0755\" , ), ), * self . get_file_transfer_tasks (), dict ( name = \"Run YChaos Agent\" , ignore_errors = \"yes\" , action = dict ( module = \"shell\" , cmd = \" \" . join ( [ \"source {{result_pip.virtualenv}}/bin/activate\" , \"&&\" , \"ychaos --log-file {{result_create_workspace.path}}/ychaos.log\" , \"agent attack --testplan {{result_testplan_file.dest}} --attack-report-yaml {{result_create_workspace.path}}/attack_report.yaml\" , ] ), ), ), dict ( name = \"Zip workspace directory\" , action = dict ( module = \"community.general.archive\" , path = \"{{result_create_workspace.path}}\" , dest = \"{{result_create_workspace.path}}/ychaos.zip\" , format = \"zip\" , ), ), dict ( name = \"Copy Workspace directory to local\" , action = dict ( module = \"fetch\" , src = \"{{result_create_workspace.path}}/ychaos.zip\" , dest = str ( self . testplan . attack . get_target_config () . report_dir . resolve () ) + \"/ychaos_{{inventory_hostname}}.zip\" , ), ), dict ( name = \"Delete YChaos Workspace on host\" , action = dict ( module = \"file\" , path = \"{{result_create_workspace.path}}\" , state = \"absent\" , ), ), dict ( name = \"Delete Virtual environment\" , action = dict ( module = \"file\" , path = \"{{result_pip.virtualenv}}\" , state = \"absent\" , ), ), ], ) def get_file_transfer_tasks ( self ): task_list = list () testplan = self . testplan . copy () for i , agent in enumerate ( self . testplan . attack . agents ): if agent . type == AgentType . CONTRIB : filename = Path ( testplan . attack . agents [ i ] . config [ \"path\" ]) task = dict ( name = f \"Copy { filename . name } to remote\" , register = \"copy_contrib_agent_\" + filename . stem , action = dict ( module = \"copy\" , src = str ( filename . absolute ()), dest = \"{{result_create_workspace.path}}/\" + filename . name , ), ) task_list . append ( task ) testplan . attack . agents [ i ] . config [ \"path\" ] = \"./ychaos_ws/ {} \" . format ( filename . name ) # testplan will not have any changes from original if there are no contrib agents present testplan_task = [ dict ( name = \"Copy testplan from local to remote\" , register = \"result_testplan_file\" , action = dict ( module = \"copy\" , content = json . dumps ( testplan . to_serialized_dict (), indent = 4 ), dest = \"{{result_create_workspace.path}}/testplan.json\" , ), ) ] return testplan_task + task_list def execute ( self ) -> None : self . prepare () if len ( self . target_hosts ) == 0 : self . execute_hooks ( \"on_no_targets_found\" ) return play = Play () . load ( self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) # Create Report Directory import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files () __hook_events__ : Dict [ str , Callable [ ... , NoneType ]] special \u00b6 Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered. execute ( self ) \u00b6 Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/MachineTargetExecutor.py def execute ( self ) -> None : self . prepare () if len ( self . target_hosts ) == 0 : self . execute_hooks ( \"on_no_targets_found\" ) return play = Play () . load ( self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) # Create Report Directory import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files ()","title":"MachineTargetExecutor"},{"location":"package_docs/core/executor/MachineTargetExecutor/#ychaos.core.executor.MachineTargetExecutor.MachineTargetExecutor","text":"The executor that executes the agent on a set of Virtual machines/Bare metals by connecting to the hosts via SSH. The input for the executor is the testplan, within which, the target_type is defined as machine . The target_config will provide the list of hosts out of which random blast_radius % of the hosts is selected for attack. The following are the valid hooks to this executor","title":"MachineTargetExecutor"},{"location":"package_docs/core/executor/MachineTargetExecutor/#ychaos.core.executor.MachineTargetExecutor.MachineTargetExecutor.__hook_events__","text":"Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered.","title":"__hook_events__"},{"location":"package_docs/core/executor/MachineTargetExecutor/#ychaos.core.executor.MachineTargetExecutor.MachineTargetExecutor.execute","text":"Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/MachineTargetExecutor.py def execute ( self ) -> None : self . prepare () if len ( self . target_hosts ) == 0 : self . execute_hooks ( \"on_no_targets_found\" ) return play = Play () . load ( self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) # Create Report Directory import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files ()","title":"execute()"},{"location":"package_docs/core/executor/SelfTargetExecutor/","text":"SelfTargetExecutor ( BaseExecutor ) \u00b6 The executor that executes the agent on localhost. The input for the executor is the testplan, within which, the target_type is defined as self . The following are the valid hooks to this executor Valid Hooks \u00b6 on_start Called when starting to run the Ansible playbook. def callable_hook (): ... on_target_unreachable Called when a target becomes unreachable during the Ansible play def callable_hook ( result : AnsibleResult ): ... on_target_passed Called when an ansible task is passed def callable_hook ( result : AnsibleResult ): ... on_target_failed Called when an ansible task is failed def callable_hook ( result : AnsibleResult ): ... on_end Called after the end of Ansible playbook run def callable_hook ( result ): ... on_error Called when an exception is raised def callable_hook ( e : Exception ): ... Source code in core/executor/SelfTargetExecutor.py class SelfTargetExecutor ( BaseExecutor ): \"\"\" The executor that executes the agent on localhost. The input for the executor is the testplan, within which, the target_type is defined as `self`. The following are the valid hooks to this executor ## Valid Hooks === \"on_start\" Called when starting to run the Ansible playbook. ```python def callable_hook(): ... ``` === \"on_target_unreachable\" Called when a target becomes unreachable during the Ansible play ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_target_passed\" Called when an ansible task is passed ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_target_failed\" Called when an ansible task is failed ```python def callable_hook(result: AnsibleResult): ... ``` === \"on_end\" Called after the end of Ansible playbook run ```python def callable_hook(result): ... ``` === \"on_error\" Called when an exception is raised ```python def callable_hook(e: Exception): ... ``` \"\"\" __target_type__ = \"self\" __hook_events__ = { \"on_start\" : EventHook . CallableType (), \"on_target_unreachable\" : EventHook . CallableType ( TaskResult ), \"on_target_failed\" : EventHook . CallableType ( TaskResult ), \"on_target_passed\" : EventHook . CallableType ( TaskResult ), \"on_error\" : EventHook . CallableType ( Exception ), \"on_end\" : EventHook . CallableType ( TaskResult ), } LOCALHOST : str = \"localhost\" def __init__ ( self , testplan : TestPlan , * args , ** kwargs ): super ( SelfTargetExecutor , self ) . __init__ ( testplan ) self . ansible_context = SimpleNamespace () self . logger = AppLogger . get_logger ( self . __class__ . __name__ ) def prepare ( self ): self . ansible_context . loader = DataLoader () self . ansible_context . results_callback = YChaosAnsibleResultCallback ( hooks = { k : v for k , v in self . hooks . items () if k in YChaosAnsibleResultCallback . __hook_events__ } ) self . ansible_context . inventory = InventoryManager ( loader = self . ansible_context . loader , sources = f \" { self . LOCALHOST } ,\" ) self . ansible_context . variable_manager = VariableManager ( loader = self . ansible_context . loader , inventory = self . ansible_context . inventory ) self . ansible_context . tqm = TaskQueueManager ( inventory = self . ansible_context . inventory , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , passwords = dict ( vault_pass = None ), stdout_callback = self . ansible_context . results_callback , ) self . ansible_context . play_source = dict ( name = \"Ychaos Ansible Play\" , hosts = self . LOCALHOST , connection = \"local\" , gather_facts = \"no\" , ignore_unreachable = \"no\" , tasks = [ dict ( name = \"Check current working directory\" , action = dict ( module = \"command\" , args = dict ( cmd = \"pwd\" )), register = \"result_pwd\" , changed_when = \"false\" , ), dict ( name = \"Create a virtual environment\" , register = \"result_pip\" , action = dict ( module = \"pip\" , chdir = \"{{result_pwd.stdout}}\" , name = \"pip\" , state = \"latest\" , virtualenv = \"ychaos_env\" , virtualenv_command = \"python3 -m venv\" , ), failed_when = [ # Failed in these following reasons # 1. pip not installed # 2. Failed to installed latest pip version \"result_pip.state == 'absent'\" ], ), dict ( name = \"Install ychaos[agents]\" , register = \"result_pip_install_ychaos_agents\" , action = dict ( module = \"pip\" , chdir = \"{{result_pwd.stdout}}\" , name = \"ychaos[agents]\" , virtualenv = \"ychaos_env\" , ), failed_when = [ # Failed if unable to install ychaos[agents] \"result_pip_install_ychaos_agents.state == 'absent'\" ], ), dict ( name = \"Create a workspace directory for storing local report files\" , register = \"result_create_workspace\" , action = dict ( module = \"file\" , path = \"{{result_pwd.stdout}}/ychaos_ws\" , state = \"directory\" , mode = \"0755\" , ), ), dict ( name = \"Put testplan in ychaos_ws\" , register = \"result_testplan_file\" , action = dict ( module = \"copy\" , content = json . dumps ( self . testplan . to_serialized_dict (), indent = 4 ), dest = \"{{result_create_workspace.path}}/testplan.json\" , ), ), dict ( name = \"Run YChaos Agent\" , ignore_errors = \"yes\" , action = dict ( module = \"shell\" , args = dict ( cmd = \" \" . join ( [ \"ychaos --log-file '{{result_create_workspace.path}}/ychaos.log'\" , \"agent attack --testplan '{{result_testplan_file.dest}}' --attack-report-yaml '{{result_create_workspace.path}}/attack_report.yaml'\" , ] ), ), ), ), dict ( name = \"Delete Virtual environment\" , action = dict ( module = \"file\" , path = \"{{result_pip.virtualenv}}\" , state = \"absent\" , ), ), ], ) def execute ( self ) -> None : self . prepare () play = Play () . load ( data = self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files () __hook_events__ : Dict [ str , Callable [ ... , NoneType ]] special \u00b6 Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered. execute ( self ) \u00b6 Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/SelfTargetExecutor.py def execute ( self ) -> None : self . prepare () play = Play () . load ( data = self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files ()","title":"SelfTargetExecutor"},{"location":"package_docs/core/executor/SelfTargetExecutor/#ychaos.core.executor.SelfTargetExecutor.SelfTargetExecutor","text":"The executor that executes the agent on localhost. The input for the executor is the testplan, within which, the target_type is defined as self . The following are the valid hooks to this executor","title":"SelfTargetExecutor"},{"location":"package_docs/core/executor/SelfTargetExecutor/#ychaos.core.executor.SelfTargetExecutor.SelfTargetExecutor.__hook_events__","text":"Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered.","title":"__hook_events__"},{"location":"package_docs/core/executor/SelfTargetExecutor/#ychaos.core.executor.SelfTargetExecutor.SelfTargetExecutor.execute","text":"Define \"what\" is to be done when the testplan consists the instruction to execute the agents in a particular target environment. Returns: Type Description None None Source code in core/executor/SelfTargetExecutor.py def execute ( self ) -> None : self . prepare () play = Play () . load ( data = self . ansible_context . play_source , variable_manager = self . ansible_context . variable_manager , loader = self . ansible_context . loader , ) import os os . makedirs ( self . testplan . attack . get_target_config () . report_dir . resolve (), exist_ok = True ) try : self . execute_hooks ( \"on_start\" ) result = self . ansible_context . tqm . run ( play ) self . execute_hooks ( \"on_end\" , result ) except Exception as e : self . execute_hooks ( \"on_error\" , e ) finally : self . ansible_context . tqm . cleanup () if self . ansible_context . loader : # pragma: no cover self . ansible_context . loader . cleanup_all_tmp_files ()","title":"execute()"},{"location":"package_docs/core/verification/controller/","text":"VerificationController ( EventHook ) \u00b6 Verification controller is used to run all the verification plugins configured in the testplan and assert that the system is expected to be in a state expected by the user. Extends the EventHook class, that defines the following event hooks. Valid Hooks \u00b6 on_start Hook that gets called when the verification execution is about to start. No arguments are passed to the callable. def callable_hook (): ... on_each_plugin_start Hook that gets called when a particular plugin execution is about to start. index in the signature refers to the position in the list def callable_hook ( index : int , config : VerificationConfig ): ... References VerificationConfig on_each_plugin_end Hook that gets called when a particular plugin execution has ended. index in the signature refers to the position in the list def callable_hook ( index : int , config : VerificationConfig , state_data : VerificationStateData ): ... References VerificationConfig VerificationStateData on_end Hook that gets called when the verification execution has ended. Each element in the list of boolean corresponds to the result of the plugin, where True indicates successful verification and False is a failure to verify the state def callable_hook ( verify_list : List [ bool ]): ... on_plugin_not_found Hook that gets called when a plugin available in schema is not ready for usage/not implemented. This case is possible for the plugins that are in Beta/development phase def callable_hook ( index : int , plugin_type : VerificationType ): ... Each of the hooks get called on a certain event. The caller can register as many hooks for a particular event, by calling the register_hook(event_name, hook_method) method. All the hooks are executed sequentially. The best example of this is to register a hook to print information on CLI. Source code in core/verification/controller.py class VerificationController ( EventHook ): \"\"\" Verification controller is used to run all the verification plugins configured in the testplan and assert that the system is expected to be in a state expected by the user. Extends the EventHook class, that defines the following event hooks. ## Valid Hooks === \"on_start\" Hook that gets called when the verification execution is about to start. No arguments are passed to the callable. ```python def callable_hook(): ... ``` === \"on_each_plugin_start\" Hook that gets called when a particular plugin execution is about to start. `index` in the signature refers to the position in the list ```python def callable_hook(index: int, config: VerificationConfig): ... ``` References: 1. [VerificationConfig][ychaos.testplan.verification.VerificationConfig] === \"on_each_plugin_end\" Hook that gets called when a particular plugin execution has ended. `index` in the signature refers to the position in the list ```python def callable_hook(index: int, config: VerificationConfig, state_data: VerificationStateData): ... ``` References: 1. [VerificationConfig][ychaos.testplan.verification.VerificationConfig] 2. [VerificationStateData][ychaos.core.verification.data.VerificationStateData] === \"on_end\" Hook that gets called when the verification execution has ended. Each element in the list of boolean corresponds to the result of the plugin, where `True` indicates successful verification and `False` is a failure to verify the state ```python def callable_hook(verify_list: List[bool]): ... ``` === \"on_plugin_not_found\" Hook that gets called when a plugin available in schema is not ready for usage/not implemented. This case is possible for the plugins that are in Beta/development phase ```python def callable_hook(index:int, plugin_type: VerificationType): ... ``` --- Each of the hooks get called on a certain event. The caller can register as many hooks for a particular event, by calling the `register_hook(event_name, hook_method)` method. All the hooks are executed sequentially. The best example of this is to register a hook to print information on CLI. \"\"\" __hook_events__ = { \"on_start\" : EventHook . CallableType (), \"on_each_plugin_start\" : EventHook . CallableType ( int , VerificationConfig ), \"on_each_plugin_end\" : EventHook . CallableType ( int , VerificationConfig , VerificationStateData ), \"on_plugin_not_found\" : EventHook . CallableType ( int , VerificationType ), \"on_end\" : EventHook . CallableType ( List [ bool ]), } @validate_arguments def __init__ ( self , testplan : TestPlan , current_state : SystemState , verification_data : List [ Dict [ SystemState , Optional [ VerificationStateData ]]], ): \"\"\" Initialize a verification controller object. Args: testplan: A valid testplan object current_state: The state in which the system is expected to be in verification_data (List[VerificationData]): The verification data probably from previous run. \"\"\" super ( VerificationController , self ) . __init__ () self . logger = AppLogger . get_logger ( self . __class__ . __name__ ) self . logger . bind ( event = \"controller\" ) self . testplan = testplan self . current_state = current_state if not verification_data : verification_data = [ dict (), ] * len ( self . testplan . verification ) elif len ( verification_data ) != len ( self . testplan . verification ): raise ValueError ( \"Data and verification config size mismatch\" ) self . verification_data = list () for data in verification_data : self . verification_data . append ( VerificationData . parse_obj ( data )) def execute ( self ) -> bool : \"\"\" Execute the Verification controller. Returns: True if all the verification plugin pass, False otherwise \"\"\" # Call all the hooks that were registered for `verification_start` # If there were no hooks registered, this will be no-op self . execute_hooks ( \"on_start\" ) _verify_list = list () for index , ( verification_plugin , data ) in enumerate ( zip ( self . testplan . verification , self . verification_data ) ): assert isinstance ( verification_plugin . states , List ) # For mypy if self . current_state in verification_plugin . states : self . logger . info ( msg = f \"Starting { verification_plugin . type . value } verification\" ) plugin_class = VERIFICATION_PLUGIN_MAP . get ( verification_plugin . type . value , None ) if plugin_class is None : # This can happen when a new plugin is not implemented yet, but is # available in the schema self . execute_hooks ( \"on_plugin_not_found\" , index , verification_plugin . type ) continue plugin = plugin_class ( verification_plugin . config , data ) # Delay before verifying time . sleep ( verification_plugin . delay_before / 1000 ) # Call all the hooks that were registered for `verification_plugin_start`. self . execute_hooks ( \"on_each_plugin_start\" , index , verification_plugin ) state_data = plugin . run_verification () self . logger . info ( msg = f \"Completed { verification_plugin . type . value } verification\" ) # Call all the hooks that were registered for `verification_plugin_end`. self . execute_hooks ( \"on_each_plugin_end\" , index , verification_plugin , state_data ) data . replace_data ( self . current_state , state_data ) if verification_plugin . strict : _verify_list . append ( state_data . rc == 0 ) else : data . add_data ( self . current_state , None ) # Delay after verifying time . sleep ( verification_plugin . delay_after / 1000 ) # Call all the hooks that were registered for `verification_end`. self . execute_hooks ( \"on_end\" , _verify_list ) return all ( _verify_list ) def get_encoded_verification_data ( self ): return [ data . encoded_dict () for data in self . verification_data ] def dump_verification ( self , fp , output_format ): if output_format == \"json\" : self . dump_verification_json ( fp ) else : self . dump_verification_yaml ( fp ) def dump_verification_json ( self , fp ): import json json . dump ( self . get_encoded_verification_data (), fp = fp , indent = 4 ) def dump_verification_yaml ( self , fp ): import yaml yaml . dump ( self . get_encoded_verification_data (), fp , default_flow_style = False , sort_keys = False , Dumper = Dumper , indent = 4 , ) __hook_events__ : Dict [ str , Callable [ ... , NoneType ]] special \u00b6 Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered. __init__ ( self , testplan , current_state , verification_data ) special \u00b6 Initialize a verification controller object. Parameters: Name Type Description Default testplan TestPlan A valid testplan object required current_state SystemState The state in which the system is expected to be in required verification_data List[VerificationData] The verification data probably from previous run. required Source code in core/verification/controller.py @validate_arguments def __init__ ( self , testplan : TestPlan , current_state : SystemState , verification_data : List [ Dict [ SystemState , Optional [ VerificationStateData ]]], ): \"\"\" Initialize a verification controller object. Args: testplan: A valid testplan object current_state: The state in which the system is expected to be in verification_data (List[VerificationData]): The verification data probably from previous run. \"\"\" super ( VerificationController , self ) . __init__ () self . logger = AppLogger . get_logger ( self . __class__ . __name__ ) self . logger . bind ( event = \"controller\" ) self . testplan = testplan self . current_state = current_state if not verification_data : verification_data = [ dict (), ] * len ( self . testplan . verification ) elif len ( verification_data ) != len ( self . testplan . verification ): raise ValueError ( \"Data and verification config size mismatch\" ) self . verification_data = list () for data in verification_data : self . verification_data . append ( VerificationData . parse_obj ( data )) execute ( self ) \u00b6 Execute the Verification controller. Returns: Type Description bool True if all the verification plugin pass, False otherwise Source code in core/verification/controller.py def execute ( self ) -> bool : \"\"\" Execute the Verification controller. Returns: True if all the verification plugin pass, False otherwise \"\"\" # Call all the hooks that were registered for `verification_start` # If there were no hooks registered, this will be no-op self . execute_hooks ( \"on_start\" ) _verify_list = list () for index , ( verification_plugin , data ) in enumerate ( zip ( self . testplan . verification , self . verification_data ) ): assert isinstance ( verification_plugin . states , List ) # For mypy if self . current_state in verification_plugin . states : self . logger . info ( msg = f \"Starting { verification_plugin . type . value } verification\" ) plugin_class = VERIFICATION_PLUGIN_MAP . get ( verification_plugin . type . value , None ) if plugin_class is None : # This can happen when a new plugin is not implemented yet, but is # available in the schema self . execute_hooks ( \"on_plugin_not_found\" , index , verification_plugin . type ) continue plugin = plugin_class ( verification_plugin . config , data ) # Delay before verifying time . sleep ( verification_plugin . delay_before / 1000 ) # Call all the hooks that were registered for `verification_plugin_start`. self . execute_hooks ( \"on_each_plugin_start\" , index , verification_plugin ) state_data = plugin . run_verification () self . logger . info ( msg = f \"Completed { verification_plugin . type . value } verification\" ) # Call all the hooks that were registered for `verification_plugin_end`. self . execute_hooks ( \"on_each_plugin_end\" , index , verification_plugin , state_data ) data . replace_data ( self . current_state , state_data ) if verification_plugin . strict : _verify_list . append ( state_data . rc == 0 ) else : data . add_data ( self . current_state , None ) # Delay after verifying time . sleep ( verification_plugin . delay_after / 1000 ) # Call all the hooks that were registered for `verification_end`. self . execute_hooks ( \"on_end\" , _verify_list ) return all ( _verify_list )","title":"controller"},{"location":"package_docs/core/verification/controller/#ychaos.core.verification.controller.VerificationController","text":"Verification controller is used to run all the verification plugins configured in the testplan and assert that the system is expected to be in a state expected by the user. Extends the EventHook class, that defines the following event hooks.","title":"VerificationController"},{"location":"package_docs/core/verification/controller/#ychaos.core.verification.controller.VerificationController.__hook_events__","text":"Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered.","title":"__hook_events__"},{"location":"package_docs/core/verification/controller/#ychaos.core.verification.controller.VerificationController.__init__","text":"Initialize a verification controller object. Parameters: Name Type Description Default testplan TestPlan A valid testplan object required current_state SystemState The state in which the system is expected to be in required verification_data List[VerificationData] The verification data probably from previous run. required Source code in core/verification/controller.py @validate_arguments def __init__ ( self , testplan : TestPlan , current_state : SystemState , verification_data : List [ Dict [ SystemState , Optional [ VerificationStateData ]]], ): \"\"\" Initialize a verification controller object. Args: testplan: A valid testplan object current_state: The state in which the system is expected to be in verification_data (List[VerificationData]): The verification data probably from previous run. \"\"\" super ( VerificationController , self ) . __init__ () self . logger = AppLogger . get_logger ( self . __class__ . __name__ ) self . logger . bind ( event = \"controller\" ) self . testplan = testplan self . current_state = current_state if not verification_data : verification_data = [ dict (), ] * len ( self . testplan . verification ) elif len ( verification_data ) != len ( self . testplan . verification ): raise ValueError ( \"Data and verification config size mismatch\" ) self . verification_data = list () for data in verification_data : self . verification_data . append ( VerificationData . parse_obj ( data ))","title":"__init__()"},{"location":"package_docs/core/verification/controller/#ychaos.core.verification.controller.VerificationController.execute","text":"Execute the Verification controller. Returns: Type Description bool True if all the verification plugin pass, False otherwise Source code in core/verification/controller.py def execute ( self ) -> bool : \"\"\" Execute the Verification controller. Returns: True if all the verification plugin pass, False otherwise \"\"\" # Call all the hooks that were registered for `verification_start` # If there were no hooks registered, this will be no-op self . execute_hooks ( \"on_start\" ) _verify_list = list () for index , ( verification_plugin , data ) in enumerate ( zip ( self . testplan . verification , self . verification_data ) ): assert isinstance ( verification_plugin . states , List ) # For mypy if self . current_state in verification_plugin . states : self . logger . info ( msg = f \"Starting { verification_plugin . type . value } verification\" ) plugin_class = VERIFICATION_PLUGIN_MAP . get ( verification_plugin . type . value , None ) if plugin_class is None : # This can happen when a new plugin is not implemented yet, but is # available in the schema self . execute_hooks ( \"on_plugin_not_found\" , index , verification_plugin . type ) continue plugin = plugin_class ( verification_plugin . config , data ) # Delay before verifying time . sleep ( verification_plugin . delay_before / 1000 ) # Call all the hooks that were registered for `verification_plugin_start`. self . execute_hooks ( \"on_each_plugin_start\" , index , verification_plugin ) state_data = plugin . run_verification () self . logger . info ( msg = f \"Completed { verification_plugin . type . value } verification\" ) # Call all the hooks that were registered for `verification_plugin_end`. self . execute_hooks ( \"on_each_plugin_end\" , index , verification_plugin , state_data ) data . replace_data ( self . current_state , state_data ) if verification_plugin . strict : _verify_list . append ( state_data . rc == 0 ) else : data . add_data ( self . current_state , None ) # Delay after verifying time . sleep ( verification_plugin . delay_after / 1000 ) # Call all the hooks that were registered for `verification_end`. self . execute_hooks ( \"on_end\" , _verify_list ) return all ( _verify_list )","title":"execute()"},{"location":"package_docs/core/verification/data/","text":"VerificationStateData ( BaseModel ) pydantic-model \u00b6 Source code in core/verification/data.py class VerificationStateData ( BaseModel ): rc : int = Field ( ... , description = \"The return code of the verification plugin. 0, +x and -x respectively indicate success, failure and error.\" , ) timestamp : datetime = Field ( default_factory = datetime . utcnow , description = \"The timestamp at which this state data was recorded.\" , ) type : VerificationType = Field ( ... , description = \"The type of verification plugin that ran to record this state data\" , ) data : Union [ Dict [ Any , Any ], List [ Any ]] = Field ( default = dict (), description = \"Plugin level data that can be consumed by the respective plugin\" , ) class Config : json_encoders = { datetime : lambda v : int ( v . timestamp ())} data : Union [ Dict [ Any , Any ], List [ Any ]] pydantic-field \u00b6 Plugin level data that can be consumed by the respective plugin rc : int pydantic-field required \u00b6 The return code of the verification plugin. 0, +x and -x respectively indicate success, failure and error. timestamp : datetime pydantic-field \u00b6 The timestamp at which this state data was recorded. type : VerificationType pydantic-field required \u00b6 The type of verification plugin that ran to record this state data __json_encoder__ ( obj ) special staticmethod \u00b6 partial(func, *args, **keywords) - new function with partial application of the given arguments and keywords.","title":"data"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData","text":"Source code in core/verification/data.py class VerificationStateData ( BaseModel ): rc : int = Field ( ... , description = \"The return code of the verification plugin. 0, +x and -x respectively indicate success, failure and error.\" , ) timestamp : datetime = Field ( default_factory = datetime . utcnow , description = \"The timestamp at which this state data was recorded.\" , ) type : VerificationType = Field ( ... , description = \"The type of verification plugin that ran to record this state data\" , ) data : Union [ Dict [ Any , Any ], List [ Any ]] = Field ( default = dict (), description = \"Plugin level data that can be consumed by the respective plugin\" , ) class Config : json_encoders = { datetime : lambda v : int ( v . timestamp ())}","title":"VerificationStateData"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData.data","text":"Plugin level data that can be consumed by the respective plugin","title":"data"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData.rc","text":"The return code of the verification plugin. 0, +x and -x respectively indicate success, failure and error.","title":"rc"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData.timestamp","text":"The timestamp at which this state data was recorded.","title":"timestamp"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData.type","text":"The type of verification plugin that ran to record this state data","title":"type"},{"location":"package_docs/core/verification/data/#ychaos.core.verification.data.VerificationStateData.__json_encoder__","text":"partial(func, *args, **keywords) - new function with partial application of the given arguments and keywords.","title":"__json_encoder__()"},{"location":"package_docs/testplan/attack/","text":"AgentExecutionConfig ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/attack.py class AgentExecutionConfig ( SchemaModel ): type : AgentType = Field ( ... , description = ( \"Defines the agent type to be executed on the target. \" \"The configuration of agent is determined by this attribute\" ), examples = [ \"cpu_burn\" , \"no_op\" , \"ping_disable\" ], ) config : Dict [ Any , Any ] = Field ( default = dict (), description = \"The Agent configuration for a particular agent type\" , ) def get_agent_config ( self ): return self . type . metadata . schema ( ** self . config ) @validator ( \"config\" , pre = True ) def _parse_agent_configuration ( cls , v , values ): if \"type\" in values : return AgentType ( values [ \"type\" ]) . metadata . schema ( ** v ) else : # pragma: no cover return v config : Dict [ Any , Any ] pydantic-field \u00b6 The Agent configuration for a particular agent type type : AgentType pydantic-field required \u00b6 Defines the agent type to be executed on the target. The configuration of agent is determined by this attribute AttackConfig ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/attack.py class AttackConfig ( SchemaModel ): target_type : TargetType = Field ( ... , description = ( \"Defines the target type which will be used as a target for the execution of agents. \" \"The target_type configuration is determined the type mentioned in this attribute\" ), examples = [ \"self\" , \"machine\" ], ) target_config : Dict [ Any , Any ] = Field ( default = dict (), description = ( \"Defines the targets for running the agents.\" \"This can be set to null to imply that the framework should run all the agents within the same system where the executor has been invoked\" ), ) mode : AttackMode = Field ( default = AttackMode . SEQUENTIAL , description = \"Define the execution mode for the attack\" , ) agents : List [ AgentExecutionConfig ] = Field ( default = list (), description = ( \"List of agents to be executed on the Target. \" \"Each of the item of execution configuration will infer a type of agent and a configuration of the agent\" ), min_items = 1 , ) def get_target_config ( self ): return self . target_type . metadata . schema ( ** self . target_config ) @validator ( \"target_config\" , pre = True ) def _parse_target_configuration ( cls , v , values ): if \"target_type\" in values : return TargetType ( values [ \"target_type\" ]) . metadata . schema ( ** v ) else : # pragma: no cover return v agents : ConstrainedListValue pydantic-field \u00b6 List of agents to be executed on the Target. Each of the item of execution configuration will infer a type of agent and a configuration of the agent mode : AttackMode pydantic-field \u00b6 Define the execution mode for the attack target_config : Dict [ Any , Any ] pydantic-field \u00b6 Defines the targets for running the agents.This can be set to null to imply that the framework should run all the agents within the same system where the executor has been invoked target_type : TargetType pydantic-field required \u00b6 Defines the target type which will be used as a target for the execution of agents. The target_type configuration is determined the type mentioned in this attribute AttackMode ( Enum ) \u00b6 Defines the type of execution mode for executing the configured Agents Source code in testplan/attack.py class AttackMode ( Enum ): \"\"\" Defines the type of execution mode for executing the configured Agents \"\"\" CONCURRENT = \"concurrent\" SEQUENTIAL = \"sequential\" MachineTargetDefinition ( TargetDefinition ) pydantic-model \u00b6 Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, target_type should be equal to machine Attributes: Name Type Description blast_radius int The percentage of targets to be attacked. This is a required field ssh_config SSHConfig The SSH Configuration to be used while logging into the hosts. See SSHConfig hostnames List[ychaos.utils.builtins.FQDN] List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns List[str] List of Host patterns with a single number range within the pattern hostfiles List[pydantic.types.FilePath] List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude List[ychaos.utils.builtins.FQDN] List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning Testplan validator will not be able to validate each of the host entries if the targets are provided using hostfiles . The tool will dynamically validate each of the entry while reading the files. Source code in testplan/attack.py class MachineTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, `target_type` should be equal to `machine` Attributes: blast_radius: The percentage of targets to be attacked. **This is a required field** ssh_config: The SSH Configuration to be used while logging into the hosts. See [SSHConfig][ychaos.testplan.attack.SSHConfig] hostnames: List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns: List of Host patterns with a single number range within the pattern hostfiles: List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude: List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning: Testplan validator will not be able to validate each of the host entries if the targets are provided using `hostfiles`. The tool will dynamically validate each of the entry while reading the files. \"\"\" blast_radius : int = Field ( ... , description = \"The percentage of targets to be attacked\" , ge = 0 , le = 100 ) ssh_config : SSHConfig = Field ( default = SSHConfig (), description = \"The configuration used to SSH to the target machines.\" , ) hostnames : List [ FQDN ] = Field ( default = list (), description = \"List of hosts as targets to run the agents on. These should be valid FQDNs.\" , examples = [ [ \"myhost01.yahoo.com\" , \"myhost02.yahoo.com\" , \"mockhost.web.fe.yahoo.com\" ], ], ) hostpatterns : List [ str ] = Field ( default = list (), description = \"List of Host patterns with a single number range within the pattern\" , examples = [ [ \"myhost[12-34].yahoo.com\" , \"hostpattern[00-10].mock.yahoo.com\" ], ], ) hostfiles : List [ FilePath ] = Field ( default = list (), description = ( \"List of files containing hostnames separated by a newline\" \"The path provided can be an absolute path or a relative path from which the tool is invoked.\" \"Note that the testplan will not validate each file during static validation.\" ), examples = [ [ \"/home/awesomeuser/hostlist.txt\" , \"/home/awesomeuser/tmp/inventory.txt\" ] ], ) exclude : List [ FQDN ] = Field ( default = list (), description = ( \"List of hosts to be always excluded out of the attack.\" \"The filtering criteria will always exclude the hosts in this list\" ), ) def iterate_hostfiles ( self ): for file in self . hostfiles : for host in file . read_text () . strip () . splitlines (): yield FQDN ( host ) def iterate_hostpattern ( self ): for v in self . hostpatterns : match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : yield FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): yield FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) def expand_hostpatterns ( self ) -> List [ FQDN ]: expanded_list = list () for hostname in self . iterate_hostpattern (): expanded_list . append ( hostname ) return expanded_list def expand_hostfiles ( self ): expanded_list = list () for host in self . iterate_hostfiles (): expanded_list . append ( host ) return expanded_list def get_effective_hosts ( self ): return list ( set ( self . expand_hostpatterns () + self . expand_hostfiles () + self . hostnames ) . difference ( set ( self . exclude )) ) @validator ( \"hostpatterns\" , pre = True , each_item = True ) def validate_hostpatterns ( cls , v ): match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) return v blast_radius : ConstrainedIntValue pydantic-field required \u00b6 The percentage of targets to be attacked exclude : List [ ychaos . utils . builtins . FQDN ] pydantic-field \u00b6 List of hosts to be always excluded out of the attack.The filtering criteria will always exclude the hosts in this list hostfiles : List [ pydantic . types . FilePath ] pydantic-field \u00b6 List of files containing hostnames separated by a newlineThe path provided can be an absolute path or a relative path from which the tool is invoked.Note that the testplan will not validate each file during static validation. hostnames : List [ ychaos . utils . builtins . FQDN ] pydantic-field \u00b6 List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns : List [ str ] pydantic-field \u00b6 List of Host patterns with a single number range within the pattern ssh_config : SSHConfig pydantic-field \u00b6 The configuration used to SSH to the target machines. SSHConfig ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/attack.py class SSHConfig ( SchemaModel ): user : str = Field ( default = getpass . getuser (), description = \"The login user for SSH connection. Defaults to current user.\" , ) private_key : Optional [ Path ] = Field ( default = None , description = \"The private key file that will be used to login to the hosts.\" , ) password : Union [ SecretStr , Secret ] = Field ( default = None , description = \"The password that will be used to login to the hosts.\" , ) ssh_common_args : str = Field ( default = os . getenv ( \"ANSIBLE_SSH_COMMON_ARGS\" , \"\" ), description = \"The common Arguments to be used while SSHing to a host with Ansible (`$ANSIBLE_SSH_COMMON_ARGS`)\" , ) @validator ( \"ssh_common_args\" , always = True ) def set_ssh_common_args_env ( cls , v ): os . environ [ \"ANSIBLE_SSH_COMMON_ARGS\" ] = v return v password : Union [ pydantic . types . SecretStr , ychaos . testplan . common . Secret ] pydantic-field \u00b6 The password that will be used to login to the hosts. private_key : Path pydantic-field \u00b6 The private key file that will be used to login to the hosts. ssh_common_args : str pydantic-field \u00b6 The common Arguments to be used while SSHing to a host with Ansible ( $ANSIBLE_SSH_COMMON_ARGS ) user : str pydantic-field \u00b6 The login user for SSH connection. Defaults to current user. SelfTargetDefinition ( TargetDefinition ) pydantic-model \u00b6 Represents the configuration when the target is your local machine . To use this as a target, target_type should be equal to self . You can avoid specifying target_config for this target type. Source code in testplan/attack.py class SelfTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is your local machine . To use this as a target, `target_type` should be equal to `self`. You can avoid specifying `target_config` for this target type. \"\"\" pass TargetDefinition ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/attack.py class TargetDefinition ( SchemaModel ): report_dir : Path = Field ( default = Path ( \"./\" ), description = \"The report directory to store execution files. Defaults to current directory\" , ) report_dir : Path pydantic-field \u00b6 The report directory to store execution files. Defaults to current directory TargetType ( AEnum ) \u00b6 An enumeration. Source code in testplan/attack.py class TargetType ( AEnum ): SELF = \"self\" , SimpleNamespace ( schema = SelfTargetDefinition ) # The machine running the toolkit registers itself as the target to run all the agents MACHINE = \"machine\" , SimpleNamespace ( schema = MachineTargetDefinition )","title":"attack"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AgentExecutionConfig","text":"Source code in testplan/attack.py class AgentExecutionConfig ( SchemaModel ): type : AgentType = Field ( ... , description = ( \"Defines the agent type to be executed on the target. \" \"The configuration of agent is determined by this attribute\" ), examples = [ \"cpu_burn\" , \"no_op\" , \"ping_disable\" ], ) config : Dict [ Any , Any ] = Field ( default = dict (), description = \"The Agent configuration for a particular agent type\" , ) def get_agent_config ( self ): return self . type . metadata . schema ( ** self . config ) @validator ( \"config\" , pre = True ) def _parse_agent_configuration ( cls , v , values ): if \"type\" in values : return AgentType ( values [ \"type\" ]) . metadata . schema ( ** v ) else : # pragma: no cover return v","title":"AgentExecutionConfig"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AgentExecutionConfig.config","text":"The Agent configuration for a particular agent type","title":"config"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AgentExecutionConfig.type","text":"Defines the agent type to be executed on the target. The configuration of agent is determined by this attribute","title":"type"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackConfig","text":"Source code in testplan/attack.py class AttackConfig ( SchemaModel ): target_type : TargetType = Field ( ... , description = ( \"Defines the target type which will be used as a target for the execution of agents. \" \"The target_type configuration is determined the type mentioned in this attribute\" ), examples = [ \"self\" , \"machine\" ], ) target_config : Dict [ Any , Any ] = Field ( default = dict (), description = ( \"Defines the targets for running the agents.\" \"This can be set to null to imply that the framework should run all the agents within the same system where the executor has been invoked\" ), ) mode : AttackMode = Field ( default = AttackMode . SEQUENTIAL , description = \"Define the execution mode for the attack\" , ) agents : List [ AgentExecutionConfig ] = Field ( default = list (), description = ( \"List of agents to be executed on the Target. \" \"Each of the item of execution configuration will infer a type of agent and a configuration of the agent\" ), min_items = 1 , ) def get_target_config ( self ): return self . target_type . metadata . schema ( ** self . target_config ) @validator ( \"target_config\" , pre = True ) def _parse_target_configuration ( cls , v , values ): if \"target_type\" in values : return TargetType ( values [ \"target_type\" ]) . metadata . schema ( ** v ) else : # pragma: no cover return v","title":"AttackConfig"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackConfig.agents","text":"List of agents to be executed on the Target. Each of the item of execution configuration will infer a type of agent and a configuration of the agent","title":"agents"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackConfig.mode","text":"Define the execution mode for the attack","title":"mode"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackConfig.target_config","text":"Defines the targets for running the agents.This can be set to null to imply that the framework should run all the agents within the same system where the executor has been invoked","title":"target_config"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackConfig.target_type","text":"Defines the target type which will be used as a target for the execution of agents. The target_type configuration is determined the type mentioned in this attribute","title":"target_type"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.AttackMode","text":"Defines the type of execution mode for executing the configured Agents Source code in testplan/attack.py class AttackMode ( Enum ): \"\"\" Defines the type of execution mode for executing the configured Agents \"\"\" CONCURRENT = \"concurrent\" SEQUENTIAL = \"sequential\"","title":"AttackMode"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition","text":"Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, target_type should be equal to machine Attributes: Name Type Description blast_radius int The percentage of targets to be attacked. This is a required field ssh_config SSHConfig The SSH Configuration to be used while logging into the hosts. See SSHConfig hostnames List[ychaos.utils.builtins.FQDN] List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns List[str] List of Host patterns with a single number range within the pattern hostfiles List[pydantic.types.FilePath] List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude List[ychaos.utils.builtins.FQDN] List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning Testplan validator will not be able to validate each of the host entries if the targets are provided using hostfiles . The tool will dynamically validate each of the entry while reading the files. Source code in testplan/attack.py class MachineTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, `target_type` should be equal to `machine` Attributes: blast_radius: The percentage of targets to be attacked. **This is a required field** ssh_config: The SSH Configuration to be used while logging into the hosts. See [SSHConfig][ychaos.testplan.attack.SSHConfig] hostnames: List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns: List of Host patterns with a single number range within the pattern hostfiles: List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude: List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning: Testplan validator will not be able to validate each of the host entries if the targets are provided using `hostfiles`. The tool will dynamically validate each of the entry while reading the files. \"\"\" blast_radius : int = Field ( ... , description = \"The percentage of targets to be attacked\" , ge = 0 , le = 100 ) ssh_config : SSHConfig = Field ( default = SSHConfig (), description = \"The configuration used to SSH to the target machines.\" , ) hostnames : List [ FQDN ] = Field ( default = list (), description = \"List of hosts as targets to run the agents on. These should be valid FQDNs.\" , examples = [ [ \"myhost01.yahoo.com\" , \"myhost02.yahoo.com\" , \"mockhost.web.fe.yahoo.com\" ], ], ) hostpatterns : List [ str ] = Field ( default = list (), description = \"List of Host patterns with a single number range within the pattern\" , examples = [ [ \"myhost[12-34].yahoo.com\" , \"hostpattern[00-10].mock.yahoo.com\" ], ], ) hostfiles : List [ FilePath ] = Field ( default = list (), description = ( \"List of files containing hostnames separated by a newline\" \"The path provided can be an absolute path or a relative path from which the tool is invoked.\" \"Note that the testplan will not validate each file during static validation.\" ), examples = [ [ \"/home/awesomeuser/hostlist.txt\" , \"/home/awesomeuser/tmp/inventory.txt\" ] ], ) exclude : List [ FQDN ] = Field ( default = list (), description = ( \"List of hosts to be always excluded out of the attack.\" \"The filtering criteria will always exclude the hosts in this list\" ), ) def iterate_hostfiles ( self ): for file in self . hostfiles : for host in file . read_text () . strip () . splitlines (): yield FQDN ( host ) def iterate_hostpattern ( self ): for v in self . hostpatterns : match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : yield FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): yield FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) def expand_hostpatterns ( self ) -> List [ FQDN ]: expanded_list = list () for hostname in self . iterate_hostpattern (): expanded_list . append ( hostname ) return expanded_list def expand_hostfiles ( self ): expanded_list = list () for host in self . iterate_hostfiles (): expanded_list . append ( host ) return expanded_list def get_effective_hosts ( self ): return list ( set ( self . expand_hostpatterns () + self . expand_hostfiles () + self . hostnames ) . difference ( set ( self . exclude )) ) @validator ( \"hostpatterns\" , pre = True , each_item = True ) def validate_hostpatterns ( cls , v ): match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) return v","title":"MachineTargetDefinition"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.blast_radius","text":"The percentage of targets to be attacked","title":"blast_radius"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.exclude","text":"List of hosts to be always excluded out of the attack.The filtering criteria will always exclude the hosts in this list","title":"exclude"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.hostfiles","text":"List of files containing hostnames separated by a newlineThe path provided can be an absolute path or a relative path from which the tool is invoked.Note that the testplan will not validate each file during static validation.","title":"hostfiles"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.hostnames","text":"List of hosts as targets to run the agents on. These should be valid FQDNs.","title":"hostnames"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.hostpatterns","text":"List of Host patterns with a single number range within the pattern","title":"hostpatterns"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.MachineTargetDefinition.ssh_config","text":"The configuration used to SSH to the target machines.","title":"ssh_config"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SSHConfig","text":"Source code in testplan/attack.py class SSHConfig ( SchemaModel ): user : str = Field ( default = getpass . getuser (), description = \"The login user for SSH connection. Defaults to current user.\" , ) private_key : Optional [ Path ] = Field ( default = None , description = \"The private key file that will be used to login to the hosts.\" , ) password : Union [ SecretStr , Secret ] = Field ( default = None , description = \"The password that will be used to login to the hosts.\" , ) ssh_common_args : str = Field ( default = os . getenv ( \"ANSIBLE_SSH_COMMON_ARGS\" , \"\" ), description = \"The common Arguments to be used while SSHing to a host with Ansible (`$ANSIBLE_SSH_COMMON_ARGS`)\" , ) @validator ( \"ssh_common_args\" , always = True ) def set_ssh_common_args_env ( cls , v ): os . environ [ \"ANSIBLE_SSH_COMMON_ARGS\" ] = v return v","title":"SSHConfig"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SSHConfig.password","text":"The password that will be used to login to the hosts.","title":"password"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SSHConfig.private_key","text":"The private key file that will be used to login to the hosts.","title":"private_key"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SSHConfig.ssh_common_args","text":"The common Arguments to be used while SSHing to a host with Ansible ( $ANSIBLE_SSH_COMMON_ARGS )","title":"ssh_common_args"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SSHConfig.user","text":"The login user for SSH connection. Defaults to current user.","title":"user"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.SelfTargetDefinition","text":"Represents the configuration when the target is your local machine . To use this as a target, target_type should be equal to self . You can avoid specifying target_config for this target type. Source code in testplan/attack.py class SelfTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is your local machine . To use this as a target, `target_type` should be equal to `self`. You can avoid specifying `target_config` for this target type. \"\"\" pass","title":"SelfTargetDefinition"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.TargetDefinition","text":"Source code in testplan/attack.py class TargetDefinition ( SchemaModel ): report_dir : Path = Field ( default = Path ( \"./\" ), description = \"The report directory to store execution files. Defaults to current directory\" , )","title":"TargetDefinition"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.TargetDefinition.report_dir","text":"The report directory to store execution files. Defaults to current directory","title":"report_dir"},{"location":"package_docs/testplan/attack/#ychaos.testplan.attack.TargetType","text":"An enumeration. Source code in testplan/attack.py class TargetType ( AEnum ): SELF = \"self\" , SimpleNamespace ( schema = SelfTargetDefinition ) # The machine running the toolkit registers itself as the target to run all the agents MACHINE = \"machine\" , SimpleNamespace ( schema = MachineTargetDefinition )","title":"TargetType"},{"location":"package_docs/testplan/common/","text":"Secret ( SchemaModel ) pydantic-model \u00b6 Secret object defines the ways of fetching a secret to populate a value. For example, the login password to a host. The type of secret defines what kind of secret, the tool is trying to fetch and id is the unique identifier for that secret. A simple example is a Environment Variable. If the type= env and id= HOST_PASSWORD , then the tool will read the environment variable to determine the secret to use. This will allow the users to not reveal the secrets in testplan. Source code in testplan/common.py class Secret ( SchemaModel ): \"\"\" Secret object defines the ways of fetching a secret to populate a value. For example, the login password to a host. The type of secret defines what kind of secret, the tool is trying to fetch and id is the unique identifier for that secret. A simple example is a Environment Variable. If the type=`env` and id=`HOST_PASSWORD`, then the tool will read the environment variable to determine the secret to use. This will allow the users to not reveal the secrets in testplan. \"\"\" type : SecretType = Field ( default = SecretType . ENV , description = \"defines the type of secret to be fetched. \" ) id : Any = Field ( ... , description = \"The public identifier data which can be used to fetch the secret\" , ) def get_secret_value ( self ): \"\"\" Return the secret value. Returns: the secret value fetched from the parser. \"\"\" return self . type . metadata . parser ( self . id ) id : Any pydantic-field required \u00b6 The public identifier data which can be used to fetch the secret type : SecretType pydantic-field \u00b6 defines the type of secret to be fetched. get_secret_value ( self ) \u00b6 Return the secret value. Returns: Type Description the secret value fetched from the parser. Source code in testplan/common.py def get_secret_value ( self ): \"\"\" Return the secret value. Returns: the secret value fetched from the parser. \"\"\" return self . type . metadata . parser ( self . id ) SecretType ( AEnum ) \u00b6 Defines the type of secret the caller wants to fetch Attributes: Name Type Description env The secret is to be fetched from Environment variable. Source code in testplan/common.py class SecretType ( AEnum ): \"\"\" Defines the type of secret the caller wants to fetch Attributes: env: The secret is to be fetched from Environment variable. \"\"\" ENV = \"env\" , SimpleNamespace ( parser = lambda v : os . getenv ( v ))","title":"common"},{"location":"package_docs/testplan/common/#ychaos.testplan.common.Secret","text":"Secret object defines the ways of fetching a secret to populate a value. For example, the login password to a host. The type of secret defines what kind of secret, the tool is trying to fetch and id is the unique identifier for that secret. A simple example is a Environment Variable. If the type= env and id= HOST_PASSWORD , then the tool will read the environment variable to determine the secret to use. This will allow the users to not reveal the secrets in testplan. Source code in testplan/common.py class Secret ( SchemaModel ): \"\"\" Secret object defines the ways of fetching a secret to populate a value. For example, the login password to a host. The type of secret defines what kind of secret, the tool is trying to fetch and id is the unique identifier for that secret. A simple example is a Environment Variable. If the type=`env` and id=`HOST_PASSWORD`, then the tool will read the environment variable to determine the secret to use. This will allow the users to not reveal the secrets in testplan. \"\"\" type : SecretType = Field ( default = SecretType . ENV , description = \"defines the type of secret to be fetched. \" ) id : Any = Field ( ... , description = \"The public identifier data which can be used to fetch the secret\" , ) def get_secret_value ( self ): \"\"\" Return the secret value. Returns: the secret value fetched from the parser. \"\"\" return self . type . metadata . parser ( self . id )","title":"Secret"},{"location":"package_docs/testplan/common/#ychaos.testplan.common.Secret.id","text":"The public identifier data which can be used to fetch the secret","title":"id"},{"location":"package_docs/testplan/common/#ychaos.testplan.common.Secret.type","text":"defines the type of secret to be fetched.","title":"type"},{"location":"package_docs/testplan/common/#ychaos.testplan.common.Secret.get_secret_value","text":"Return the secret value. Returns: Type Description the secret value fetched from the parser. Source code in testplan/common.py def get_secret_value ( self ): \"\"\" Return the secret value. Returns: the secret value fetched from the parser. \"\"\" return self . type . metadata . parser ( self . id )","title":"get_secret_value()"},{"location":"package_docs/testplan/common/#ychaos.testplan.common.SecretType","text":"Defines the type of secret the caller wants to fetch Attributes: Name Type Description env The secret is to be fetched from Environment variable. Source code in testplan/common.py class SecretType ( AEnum ): \"\"\" Defines the type of secret the caller wants to fetch Attributes: env: The secret is to be fetched from Environment variable. \"\"\" ENV = \"env\" , SimpleNamespace ( parser = lambda v : os . getenv ( v ))","title":"SecretType"},{"location":"package_docs/testplan/schema/","text":"TestPlan ( TestPlanSchema ) pydantic-model \u00b6 The Test Plan Dataclass. Source code in testplan/schema.py class TestPlan ( TestPlanSchema ): \"\"\" The Test Plan Dataclass. \"\"\" __test__ = False id : UUID = Field ( default_factory = uuid4 , description = \"Schema for the test plan identifier\" , examples = [ \"061fc077-b95b-478b-87b6-73c29cb33c04\" , \"6402e065-9c90-4719-b98c-ad03152e1238\" , ], ) @classmethod def load_file ( cls , path : Union [ str , Path ]) -> \"TestPlan\" : path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) return cls ( ** data ) def to_serialized_dict ( self , * , include = None , exclude = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Optional [ Callable [[ Any ], Any ]] = None , ** dumps_kwargs : Any , ) -> dict : return json . loads ( self . json ( include = include , exclude = exclude , by_alias = by_alias , skip_defaults = skip_defaults , exclude_unset = exclude_unset , exclude_defaults = exclude_defaults , exclude_none = exclude_none , encoder = encoder , ** dumps_kwargs , ) ) def export_to_file ( self , path : Union [ str , Path ], * , yaml_format : bool = False , ** kwargs ): path = Path ( path ) json_data = self . to_serialized_dict ( ** kwargs ) with open ( path , \"w\" ) as file : if yaml_format : yaml . dump ( json_data , file , default_flow_style = False , sort_keys = False , Dumper = Dumper , ** kwargs , ) else : json . dump ( json_data , file , indent = 4 ) id : UUID pydantic-field \u00b6 Schema for the test plan identifier TestPlanSchema ( SchemaModel ) pydantic-model \u00b6 Defines the schema for the Test Plan. Source code in testplan/schema.py class TestPlanSchema ( SchemaModel ): \"\"\" Defines the schema for the Test Plan. \"\"\" __test__ = False description : str = Field ( default = \"\" , description = \"Description of the Test performed in this test plan\" ) verification : List [ VerificationConfig ] = Field ( default = list (), description = \"List of verification configurations that will be executed to verify the system is in favorable condition\" , ) attack : AttackConfig = Field ( ... , description = \"The configuration that will be used to create chaos\" ) def filter_verification_by_state ( self , system_state : SystemState ) -> List [ VerificationConfig ]: \"\"\" Get all the verification configurations for a particular state Args: system_state: SystemState to filter the list Returns: Filtered list of verification configuration that are to be executed in a particular state \"\"\" _filtered_config = list () for verification_config in self . verification : assert isinstance ( verification_config . states , list ) if system_state in verification_config . states : _filtered_config . append ( verification_config ) return _filtered_config class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model ) -> None : for prop in schema . get ( \"properties\" , {}) . values (): prop . pop ( \"title\" , None ) schema_extra = { \"$schema\" : \"https://json-schema.org/draft-07/schema\" , \"$id\" : \"https://resilience.yahoo.com/schema.json\" , } schema . update ( schema_extra ) attack : AttackConfig pydantic-field required \u00b6 The configuration that will be used to create chaos description : str pydantic-field \u00b6 Description of the Test performed in this test plan verification : List [ ychaos . testplan . verification . VerificationConfig ] pydantic-field \u00b6 List of verification configurations that will be executed to verify the system is in favorable condition filter_verification_by_state ( self , system_state ) \u00b6 Get all the verification configurations for a particular state Parameters: Name Type Description Default system_state SystemState SystemState to filter the list required Returns: Type Description List[ychaos.testplan.verification.VerificationConfig] Filtered list of verification configuration that are to be executed in a particular state Source code in testplan/schema.py def filter_verification_by_state ( self , system_state : SystemState ) -> List [ VerificationConfig ]: \"\"\" Get all the verification configurations for a particular state Args: system_state: SystemState to filter the list Returns: Filtered list of verification configuration that are to be executed in a particular state \"\"\" _filtered_config = list () for verification_config in self . verification : assert isinstance ( verification_config . states , list ) if system_state in verification_config . states : _filtered_config . append ( verification_config ) return _filtered_config","title":"schema"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlan","text":"The Test Plan Dataclass. Source code in testplan/schema.py class TestPlan ( TestPlanSchema ): \"\"\" The Test Plan Dataclass. \"\"\" __test__ = False id : UUID = Field ( default_factory = uuid4 , description = \"Schema for the test plan identifier\" , examples = [ \"061fc077-b95b-478b-87b6-73c29cb33c04\" , \"6402e065-9c90-4719-b98c-ad03152e1238\" , ], ) @classmethod def load_file ( cls , path : Union [ str , Path ]) -> \"TestPlan\" : path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) return cls ( ** data ) def to_serialized_dict ( self , * , include = None , exclude = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Optional [ Callable [[ Any ], Any ]] = None , ** dumps_kwargs : Any , ) -> dict : return json . loads ( self . json ( include = include , exclude = exclude , by_alias = by_alias , skip_defaults = skip_defaults , exclude_unset = exclude_unset , exclude_defaults = exclude_defaults , exclude_none = exclude_none , encoder = encoder , ** dumps_kwargs , ) ) def export_to_file ( self , path : Union [ str , Path ], * , yaml_format : bool = False , ** kwargs ): path = Path ( path ) json_data = self . to_serialized_dict ( ** kwargs ) with open ( path , \"w\" ) as file : if yaml_format : yaml . dump ( json_data , file , default_flow_style = False , sort_keys = False , Dumper = Dumper , ** kwargs , ) else : json . dump ( json_data , file , indent = 4 )","title":"TestPlan"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlan.id","text":"Schema for the test plan identifier","title":"id"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlanSchema","text":"Defines the schema for the Test Plan. Source code in testplan/schema.py class TestPlanSchema ( SchemaModel ): \"\"\" Defines the schema for the Test Plan. \"\"\" __test__ = False description : str = Field ( default = \"\" , description = \"Description of the Test performed in this test plan\" ) verification : List [ VerificationConfig ] = Field ( default = list (), description = \"List of verification configurations that will be executed to verify the system is in favorable condition\" , ) attack : AttackConfig = Field ( ... , description = \"The configuration that will be used to create chaos\" ) def filter_verification_by_state ( self , system_state : SystemState ) -> List [ VerificationConfig ]: \"\"\" Get all the verification configurations for a particular state Args: system_state: SystemState to filter the list Returns: Filtered list of verification configuration that are to be executed in a particular state \"\"\" _filtered_config = list () for verification_config in self . verification : assert isinstance ( verification_config . states , list ) if system_state in verification_config . states : _filtered_config . append ( verification_config ) return _filtered_config class Config : @staticmethod def schema_extra ( schema : Dict [ str , Any ], model ) -> None : for prop in schema . get ( \"properties\" , {}) . values (): prop . pop ( \"title\" , None ) schema_extra = { \"$schema\" : \"https://json-schema.org/draft-07/schema\" , \"$id\" : \"https://resilience.yahoo.com/schema.json\" , } schema . update ( schema_extra )","title":"TestPlanSchema"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlanSchema.attack","text":"The configuration that will be used to create chaos","title":"attack"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlanSchema.description","text":"Description of the Test performed in this test plan","title":"description"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlanSchema.verification","text":"List of verification configurations that will be executed to verify the system is in favorable condition","title":"verification"},{"location":"package_docs/testplan/schema/#ychaos.testplan.schema.TestPlanSchema.filter_verification_by_state","text":"Get all the verification configurations for a particular state Parameters: Name Type Description Default system_state SystemState SystemState to filter the list required Returns: Type Description List[ychaos.testplan.verification.VerificationConfig] Filtered list of verification configuration that are to be executed in a particular state Source code in testplan/schema.py def filter_verification_by_state ( self , system_state : SystemState ) -> List [ VerificationConfig ]: \"\"\" Get all the verification configurations for a particular state Args: system_state: SystemState to filter the list Returns: Filtered list of verification configuration that are to be executed in a particular state \"\"\" _filtered_config = list () for verification_config in self . verification : assert isinstance ( verification_config . states , list ) if system_state in verification_config . states : _filtered_config . append ( verification_config ) return _filtered_config","title":"filter_verification_by_state()"},{"location":"package_docs/testplan/validator/","text":"TestPlanValidator \u00b6 The Test plan validator class. Provides utility methods to validate the test plan files or raw data. Source code in testplan/validator.py class TestPlanValidator : \"\"\" The Test plan validator class. Provides utility methods to validate the test plan files or raw data. \"\"\" @classmethod def validate_file ( cls , path : Union [ str , Path ]) -> None : \"\"\" Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the content of the file does not follow the test plan schema FileNotFoundError: If the path passed to the method does not exist Args: path: A pathlike object Returns: None. \"\"\" path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) cls . validate_data ( data ) @classmethod def validate_data ( cls , data : Any ) -> None : \"\"\" Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the data does not follow the test plan schema Args: data: A data object (dictionary) Returns: None \"\"\" TestPlan . validate ( data ) validate_data ( data ) classmethod \u00b6 Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Exceptions: Type Description pydantic.ValidationError If the data does not follow the test plan schema Parameters: Name Type Description Default data Any A data object (dictionary) required Returns: Type Description None None Source code in testplan/validator.py @classmethod def validate_data ( cls , data : Any ) -> None : \"\"\" Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the data does not follow the test plan schema Args: data: A data object (dictionary) Returns: None \"\"\" TestPlan . validate ( data ) validate_file ( path ) classmethod \u00b6 Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Exceptions: Type Description pydantic.ValidationError If the content of the file does not follow the test plan schema FileNotFoundError If the path passed to the method does not exist Parameters: Name Type Description Default path Union[str, pathlib.Path] A pathlike object required Returns: Type Description None None. Source code in testplan/validator.py @classmethod def validate_file ( cls , path : Union [ str , Path ]) -> None : \"\"\" Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the content of the file does not follow the test plan schema FileNotFoundError: If the path passed to the method does not exist Args: path: A pathlike object Returns: None. \"\"\" path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) cls . validate_data ( data )","title":"validator"},{"location":"package_docs/testplan/validator/#ychaos.testplan.validator.TestPlanValidator","text":"The Test plan validator class. Provides utility methods to validate the test plan files or raw data. Source code in testplan/validator.py class TestPlanValidator : \"\"\" The Test plan validator class. Provides utility methods to validate the test plan files or raw data. \"\"\" @classmethod def validate_file ( cls , path : Union [ str , Path ]) -> None : \"\"\" Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the content of the file does not follow the test plan schema FileNotFoundError: If the path passed to the method does not exist Args: path: A pathlike object Returns: None. \"\"\" path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) cls . validate_data ( data ) @classmethod def validate_data ( cls , data : Any ) -> None : \"\"\" Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the data does not follow the test plan schema Args: data: A data object (dictionary) Returns: None \"\"\" TestPlan . validate ( data )","title":"TestPlanValidator"},{"location":"package_docs/testplan/validator/#ychaos.testplan.validator.TestPlanValidator.validate_data","text":"Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Exceptions: Type Description pydantic.ValidationError If the data does not follow the test plan schema Parameters: Name Type Description Default data Any A data object (dictionary) required Returns: Type Description None None Source code in testplan/validator.py @classmethod def validate_data ( cls , data : Any ) -> None : \"\"\" Validate raw data (e.g. dictionary) whether it follows the Test plan schema. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the data does not follow the test plan schema Args: data: A data object (dictionary) Returns: None \"\"\" TestPlan . validate ( data )","title":"validate_data()"},{"location":"package_docs/testplan/validator/#ychaos.testplan.validator.TestPlanValidator.validate_file","text":"Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Exceptions: Type Description pydantic.ValidationError If the content of the file does not follow the test plan schema FileNotFoundError If the path passed to the method does not exist Parameters: Name Type Description Default path Union[str, pathlib.Path] A pathlike object required Returns: Type Description None None. Source code in testplan/validator.py @classmethod def validate_file ( cls , path : Union [ str , Path ]) -> None : \"\"\" Validate a file (JSON/YAML) if the file content adheres to the testplan schema or not. This method on successful validation should not throw any errors. Raises: pydantic.ValidationError: If the content of the file does not follow the test plan schema FileNotFoundError: If the path passed to the method does not exist Args: path: A pathlike object Returns: None. \"\"\" path = Path ( path ) with open ( path , \"r\" ) as file : data = yaml . safe_load ( file ) cls . validate_data ( data )","title":"validate_file()"},{"location":"package_docs/testplan/verification/","text":"HTTPRequestSchema ( SchemaModel ) pydantic-model \u00b6 The Base class for Plugin that make a HTTP Network call. Source code in testplan/verification/__init__.py class HTTPRequestSchema ( SchemaModel ): \"\"\" The Base class for Plugin that make a HTTP Network call. \"\"\" method : str = Field ( default = \"GET\" , description = \"HTTP method to be used\" ) headers : Dict [ str , Union [ SecretStr , Secret ]] = Field ( default = dict (), description = \"Headers to be sent with the request\" ) params : Dict [ str , str ] = Field ( default = dict (), description = \"Query params to be sent with the request\" ) verify : bool = Field ( default = True , description = \"Verify the target URL SSL certificates\" ) # Authentication basic_auth : Optional [ Tuple [ str , Union [ SecretStr , Secret ]]] = Field ( default = None , description = \"Basic Auth authentication for the HTTP call\" ) bearer_token : Optional [ Union [ SecretStr , Secret ]] = Field ( default = None , description = \"Bearer token authentication for the HTTP call\" ) # Certificate cert : Optional [ Tuple [ Path , Path ]] = Field ( default = None , description = \"The certificate to be sent for HTTP call. The tuple should contain Certificate and Key File path\" , ) timeout : int = Field ( default = 10000 , description = \"Timeout in milliseconds at which the HTTP requests will timeout\" , gt = 0 , ) _validate_method = validator ( \"method\" , pre = True , allow_reuse = True )( BuiltinUtils . Request . validate_method ) def get_request_cert ( self ) -> Optional [ Tuple [ Path , Path ]]: \"\"\" Returns the resolved Certificate Paths by expanding the user path (~). \"\"\" if self . cert : return ( self . cert [ 0 ] . expanduser () . resolve (), self . cert [ 1 ] . expanduser () . resolve (), ) return None basic_auth : Tuple [ str , Union [ pydantic . types . SecretStr , ychaos . testplan . common . Secret ]] pydantic-field \u00b6 Basic Auth authentication for the HTTP call bearer_token : Union [ pydantic . types . SecretStr , ychaos . testplan . common . Secret ] pydantic-field \u00b6 Bearer token authentication for the HTTP call cert : Tuple [ pathlib . Path , pathlib . Path ] pydantic-field \u00b6 The certificate to be sent for HTTP call. The tuple should contain Certificate and Key File path headers : Dict [ str , Union [ pydantic . types . SecretStr , ychaos . testplan . common . Secret ]] pydantic-field \u00b6 Headers to be sent with the request method : str pydantic-field \u00b6 HTTP method to be used params : Dict [ str , str ] pydantic-field \u00b6 Query params to be sent with the request timeout : ConstrainedIntValue pydantic-field \u00b6 Timeout in milliseconds at which the HTTP requests will timeout verify : bool pydantic-field \u00b6 Verify the target URL SSL certificates get_request_cert ( self ) \u00b6 Returns the resolved Certificate Paths by expanding the user path (~). Source code in testplan/verification/__init__.py def get_request_cert ( self ) -> Optional [ Tuple [ Path , Path ]]: \"\"\" Returns the resolved Certificate Paths by expanding the user path (~). \"\"\" if self . cert : return ( self . cert [ 0 ] . expanduser () . resolve (), self . cert [ 1 ] . expanduser () . resolve (), ) return None HTTPRequestVerification ( HTTPRequestSchema ) pydantic-model \u00b6 Makes requests to the specified endpoints and verifies that the service is returning a valid response along with verifying the response time of the service being less than latency field. The user can also specify a count attribute requesting the tool to make count number of requests to the same endpoints. Source code in testplan/verification/__init__.py class HTTPRequestVerification ( HTTPRequestSchema ): \"\"\" Makes requests to the specified endpoints and verifies that the service is returning a valid response along with verifying the response time of the service being less than `latency` field. The user can also specify a `count` attribute requesting the tool to make `count` number of requests to the same endpoints. \"\"\" count : int = Field ( default = 1 , description = \"Number of HTTP calls to be sent to each of the URL\" , ge = 1 , ) latency : int = Field ( default = 50 , description = \"Expected Latency in ms. A latency below this value indicates successful verification\" , ge = 1 , ) status_codes : List [ int ] = Field ( default_factory = functools . partial ( list , range ( 200 , 300 )), description = \"The list of status code which will be the comparison factor for the HTTP responses\" , ) urls : List [ AnyHttpUrl ] = Field ( default = list (), description = \"List of HTTP/s URLs to be requested\" ) count : ConstrainedIntValue pydantic-field \u00b6 Number of HTTP calls to be sent to each of the URL latency : ConstrainedIntValue pydantic-field \u00b6 Expected Latency in ms. A latency below this value indicates successful verification status_codes : List [ int ] pydantic-field \u00b6 The list of status code which will be the comparison factor for the HTTP responses urls : List [ pydantic . networks . AnyHttpUrl ] pydantic-field \u00b6 List of HTTP/s URLs to be requested OpenTSDBVerification ( HTTPRequestSchema ) pydantic-model \u00b6 The OpenTSDB Verification Plugin gets the metrics from an OpenTSDB server and compares it with the provided comparison parameters in the testplan. If the condition passes Source code in testplan/verification/__init__.py class OpenTSDBVerification ( HTTPRequestSchema ): \"\"\" The OpenTSDB Verification Plugin gets the metrics from an OpenTSDB server and compares it with the provided comparison parameters in the testplan. If the condition passes \"\"\" url : AnyHttpUrl = Field ( ... , description = \"The OpenTSDB server URL to get the metrics from\" ) # Override method to change default value method : str = Field ( default = \"POST\" , description = \"HTTP method to be used\" ) query : Dict [ str , Any ] = Field ( default = dict (), description = \"The OpenTSDB query sent to the server.\" ) criteria : List [ MultipleConditionalsMetricsVerificationCriteria ] = Field ( default = list (), description = ( \"Metrics verification criteria without state information.\" \"All the criteria part of this list must pass for the verification to be successful\" ), ) state_bound_criteria : List [ StateBoundMetricsVerificationCriteria ] = Field ( default = list (), description = ( \"Metrics verification criteria with state.\" \"All the criteria part of this list must pass for the verification to be successful\" ), ) @validator ( \"state_bound_criteria\" , pre = True , always = True ) def _criteria_validation ( cls , v , values ): # The input must contain at least one of \"criteria\" or \"state_bound_criteria\" if not v and not values . get ( \"criteria\" , list ()): raise ValueError ( \"Either criteria or state_bound_criteria must be present for this configuration.\" ) return v _validate_method = validator ( \"method\" , pre = True , allow_reuse = True )( BuiltinUtils . Request . validate_method ) criteria : List [ ychaos . testplan . verification . plugins . metrics . MultipleConditionalsMetricsVerificationCriteria ] pydantic-field \u00b6 Metrics verification criteria without state information.All the criteria part of this list must pass for the verification to be successful query : Dict [ str , Any ] pydantic-field \u00b6 The OpenTSDB query sent to the server. state_bound_criteria : List [ ychaos . testplan . verification . plugins . metrics . StateBoundMetricsVerificationCriteria ] pydantic-field \u00b6 Metrics verification criteria with state.All the criteria part of this list must pass for the verification to be successful url : AnyHttpUrl pydantic-field required \u00b6 The OpenTSDB server URL to get the metrics from PythonModuleVerification ( SchemaModel ) pydantic-model \u00b6 The Python Module verification. Runs an custom python script given the path of the script. The executable of the script is set to sys.executable by default which can be overridden by a custom executable. The script can also be passed a list of arguments that are provided in the arguments argument which are passed to the script by separating each element of the argument by space. The user of this plugin takes the entire responsibility of the script executed. YChaos is only responsible of running the script and collecting the exitcode of the script with which the state of the system is verified/monitored. Source code in testplan/verification/__init__.py class PythonModuleVerification ( SchemaModel ): \"\"\" The Python Module verification. Runs an custom python script given the path of the script. The executable of the script is set to `sys.executable` by default which can be overridden by a custom executable. The script can also be passed a list of arguments that are provided in the arguments argument which are passed to the script by separating each element of the argument by space. The user of this plugin takes the entire responsibility of the script executed. YChaos is only responsible of running the script and collecting the exitcode of the script with which the state of the system is verified/monitored. \"\"\" path : Path = Field ( ... , description = \"The absolute path of the python script\" ) executable : str = Field ( default = sys . executable , description = \"The python shell to be used for executing the script\" , ) arguments : List [ str ] = Field ( default = list (), description = \"List of arguments to be sent to the script. The arguments in the list will be sent to the script space separated\" , ) def safe_arguments ( self ): return [ shlex . quote ( x ) for x in self . arguments ] arguments : List [ str ] pydantic-field \u00b6 List of arguments to be sent to the script. The arguments in the list will be sent to the script space separated executable : str pydantic-field \u00b6 The python shell to be used for executing the script path : Path pydantic-field required \u00b6 The absolute path of the python script SDv4Verification ( SchemaModel ) pydantic-model \u00b6 The SDV4VerificationPlugin offers the user of YChaos to configure a 3 rd party Screwdriver Job that is triggered remotely by YChaos and upon the successful completion of that SDv4 job, the verification is marked as successful. If the SDv4 job fails/is aborted, the verification is marked as failure. Know more about Screwdriver CI/CD Source code in testplan/verification/__init__.py class SDv4Verification ( SchemaModel ): \"\"\" The SDV4VerificationPlugin offers the user of YChaos to configure a 3rd party Screwdriver Job that is triggered remotely by YChaos and upon the successful completion of that SDv4 job, the verification is marked as successful. If the SDv4 job fails/is aborted, the verification is marked as failure. [Know more about Screwdriver CI/CD](https://screwdriver.cd/) \"\"\" pipeline_id : int = Field ( ... , description = \"SDv4 pipeline ID\" , examples = [ 123456 , 1041241 ] ) job_name : str = Field ( ... , description = \"Job name in the pipeline\" , examples = [ \"test_validation\" , \"state_verification\" ], ) sd_api_url : AnyHttpUrl = Field ( ... , description = \"SDv4 API URL\" ) sd_api_token : Union [ SecretStr , Secret ] = Field ( ... , description = \"The Screwdriver pipeline/user access token to be able to start the jon in the pipeline\" , ) job_timeout : PositiveInt = Field ( default = 3600 , description = \"Job Timeout in seconds\" ) job_name : str pydantic-field required \u00b6 Job name in the pipeline job_timeout : PositiveInt pydantic-field \u00b6 Job Timeout in seconds pipeline_id : int pydantic-field required \u00b6 SDv4 pipeline ID sd_api_token : Union [ pydantic . types . SecretStr , ychaos . testplan . common . Secret ] pydantic-field required \u00b6 The Screwdriver pipeline/user access token to be able to start the jon in the pipeline sd_api_url : AnyHttpUrl pydantic-field required \u00b6 SDv4 API URL VerificationConfig ( SchemaModel ) pydantic-model \u00b6 The verification configuration that is executed during some state of the system to verify the system is in a favorable conditions or not. Source code in testplan/verification/__init__.py class VerificationConfig ( SchemaModel ): \"\"\" The verification configuration that is executed during some state of the system to verify the system is in a favorable conditions or not. \"\"\" delay_before : float = Field ( default = 0 , description = \"delay (in ms) to be introduced before running this plugin\" , ) delay_after : float = Field ( default = 0 , description = \"delay (in ms) to be introduced after running this plugin\" , ) states : Union [ SystemState , List [ SystemState ]] = Field ( ... , description = \"A system state or a list of system states in which this verification plugin should be executed.\" , ) type : VerificationType = Field ( ... , description = \"The verification type to be used.\" ) strict : bool = Field ( default = True , description = ( \"Setting this value to false implies the overall verification\" \" does not fail because of the failure of this test.\" ), ) config : Dict [ str , Any ] = Field ( ... , description = \"The verification type configuration\" ) def get_verification_config ( self ): return self . type . metadata . schema ( ** self . config ) @validator ( \"states\" , pre = True ) def _parse_states_to_list ( cls , v ): \"\"\" Parses the state object to List of states to keep the access consistent Args: v: SystemState object/ List of SystemState Returns: List of SystemState \"\"\" return BuiltinUtils . wrap_if_non_iterable ( v ) @validator ( \"config\" , pre = True ) def _parse_plugin_configuration ( cls , v , values ): \"\"\" Validates the plugin configuration to match with the mapper class of the plugin. Args: v: Plugin configuration values: verification configuration Returns: Parsed mapper object \"\"\" if \"type\" in values : return VerificationType ( values [ \"type\" ]) . metadata . schema ( ** v ) else : return v config : Dict [ str , Any ] pydantic-field required \u00b6 The verification type configuration delay_after : float pydantic-field \u00b6 delay (in ms) to be introduced after running this plugin delay_before : float pydantic-field \u00b6 delay (in ms) to be introduced before running this plugin states : Union [ ychaos . testplan . SystemState , List [ ychaos . testplan . SystemState ]] pydantic-field required \u00b6 A system state or a list of system states in which this verification plugin should be executed. strict : bool pydantic-field \u00b6 Setting this value to false implies the overall verification does not fail because of the failure of this test. type : VerificationType pydantic-field required \u00b6 The verification type to be used. VerificationType ( AEnum ) \u00b6 Defines the Type of plugin to be used for verification. Source code in testplan/verification/__init__.py class VerificationType ( AEnum ): \"\"\" Defines the Type of plugin to be used for verification. \"\"\" # The metadata object will contain the following attributes # 1. schema : The Schema class of the VerificationType PYTHON_MODULE = \"python_module\" , SimpleNamespace ( schema = PythonModuleVerification ) HTTP_REQUEST = \"http_request\" , SimpleNamespace ( schema = HTTPRequestVerification ) SDV4_VERIFICATION = ( \"sdv4\" , SimpleNamespace ( schema = SDv4Verification ), ) OPENTSDB_VERIFICATION = \"tsdb\" , SimpleNamespace ( schema = OpenTSDBVerification ) # For Testing purpose, cannot be used by users. NOOP = \"noop\" , SimpleNamespace ( schema = NoOpConfig ) plugins special \u00b6 metrics \u00b6 ComparisonCondition ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/verification/plugins/metrics.py class ComparisonCondition ( SchemaModel ): comparator : MetricsComparator = Field ( ... , description = \"Comparison condition to compare between the metrics data and fetched value\" , ) value : Union [ float , Tuple ] = Field ( ... , description = \"Numerical value/range to be used for comparison\" ) # Resolve Aliases @validator ( \"comparator\" , pre = True ) def resolve_comparator ( cls , v , values ): values [ \"_comparator\" ] = v # Store the actual value in a private attribute return v comparator : MetricsComparator pydantic-field required \u00b6 Comparison condition to compare between the metrics data and fetched value value : Union [ float , Tuple ] pydantic-field required \u00b6 Numerical value/range to be used for comparison MetricsAggregator ( AEnum ) \u00b6 The Metrics aggregator options. Allows the user to transform a time series data into comparable data. Source code in testplan/verification/plugins/metrics.py class MetricsAggregator ( AEnum ): \"\"\" The Metrics aggregator options. Allows the user to transform a time series data into comparable data. \"\"\" AVG = \"avg\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . avg , __desc__ = \"Gets the Average of all valid datapoints\" , ) LATEST = \"latest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . latest , __desc__ = \"Gets the latest valid datapoint\" , ) OLDEST = \"oldest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . oldest , __desc__ = \"Gets the oldest valid datapoint\" , ) RANDOM = \"random\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . random , __desc__ = \"Gets a random valid datapoint\" , ) MAX = \"max\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . max , __desc__ = \"Gets the largest valid datapoint\" , ) MIN = \"min\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . min , __desc__ = \"Gets the smallest valid datapoint\" , ) SLOPE = \"slope\" , SimpleNamespace ( aggregate = lambda data : BuiltinUtils . raise_error ( NotImplementedError ( \"This aggregator is not implemented\" ) ), __desc__ = \"Gets the slope of the datapoints\" , ) MetricsComparator ( AEnum ) \u00b6 An enumeration. Source code in testplan/verification/plugins/metrics.py class MetricsComparator ( AEnum ): LT = \"lt\" , SimpleNamespace ( __aliases__ = ( \"<\" ,), compare = lambda data , expected : data < expected , relational = True , ) LE = \"le\" , SimpleNamespace ( __aliases__ = ( \"<=\" ,), compare = lambda data , expected : data <= expected , relational = True , ) GT = \"gt\" , SimpleNamespace ( __aliases__ = ( \">\" ,), compare = lambda data , expected : data > expected , relational = True , ) GE = \"ge\" , SimpleNamespace ( __aliases__ = ( \">=\" ,), compare = lambda data , expected : data >= expected , relational = True , ) EQ = \"eq\" , SimpleNamespace ( __aliases__ = ( \"==\" ,), compare = lambda data , expected : data == expected , relational = True , ) NEQ = \"neq\" , SimpleNamespace ( __aliases__ = ( \"!=\" ,), compare = lambda data , expected : data != expected , relational = True , ) RANGE = \"range\" , SimpleNamespace ( __aliases__ = ( \"()\" , \"(]\" , \"[)\" , \"[]\" ), compare = lambda range_type , data , expected_range : MetricsComparator . range_compare ( # type: ignore range_type , data , expected_range ), relational = False , ) # The below comparators can only be used for state bound criteria PCT = \"pct\" , SimpleNamespace ( __aliases__ = ( \" %% \" ,), compare = lambda new_data , old_data , expected : MetricsComparator . pct_compare ( # type: ignore new_data , old_data , expected ), relational = False , ) @classmethod @validate_arguments def pct_compare ( cls , new_data : float , old_data : float , expected : Union [ float , Tuple ] ) -> bool : \"\"\" Calculate the percentage variation from new_val and old_val Args: new_data: New Value from data old_data: Old value from saved data expected: Expected percentage change Returns: True if the condition meets \"\"\" pct_change = (( new_data - old_data ) / old_data ) * 100 if isinstance ( expected , tuple ): return ( BuiltinUtils . Float . parse ( expected [ 0 ], - math . inf ) <= pct_change <= BuiltinUtils . Float . parse ( expected [ 1 ], math . inf ) ) else : return pct_change == expected @classmethod @validate_arguments def range_compare ( cls , range_type : str , data : float , expected_range : Tuple , ) -> bool : \"\"\" Args: range_type: The range type that depicts inclusiveness data: Data to be compared expected_range: Expected range for the data to be within Returns: \"\"\" if range_type == MetricsComparator . RANGE . value : range_type = \"()\" if range_type == \"()\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"[)\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"(]\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) else : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) MultipleConditionalsMetricsVerificationCriteria ( SchemaModel ) pydantic-model \u00b6 Defines the Metrics Verification criteria Source code in testplan/verification/plugins/metrics.py class MultipleConditionalsMetricsVerificationCriteria ( SchemaModel ): \"\"\" Defines the Metrics Verification criteria \"\"\" aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) conditionals : List [ ComparisonCondition ] = Field ( default = list (), description = \"The conditionals out of which any one needs to pass for the criteria to be marked as passed\" , ) aggeragator : MetricsAggregator pydantic-field \u00b6 Data aggregator conditionals : List [ ychaos . testplan . verification . plugins . metrics . ComparisonCondition ] pydantic-field \u00b6 The conditionals out of which any one needs to pass for the criteria to be marked as passed StateBoundMetricsVerificationCriteria ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/verification/plugins/metrics.py class StateBoundMetricsVerificationCriteria ( SchemaModel ): aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) criteria : Dict [ SystemState , ComparisonCondition ] = Field ( ... , description = \"Metrics verification criteria with state.\" , ) def get_criteria ( self , state : SystemState ): return self . criteria [ state . value ] # type: ignore class Config : use_enum_values = True # To make the model JSON serializable aggeragator : MetricsAggregator pydantic-field \u00b6 Data aggregator criteria : Dict [ ychaos . testplan . SystemState , ychaos . testplan . verification . plugins . metrics . ComparisonCondition ] pydantic-field required \u00b6 Metrics verification criteria with state. TimeSeriesDataAggregator \u00b6 The class containing the implementations of different Time Series data Aggregator Source code in testplan/verification/plugins/metrics.py class TimeSeriesDataAggregator : \"\"\" The class containing the implementations of different Time Series data Aggregator \"\"\" @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )]) @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , ) @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , ) avg ( data ) classmethod \u00b6 Returns the Average value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Average value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , ) get_filtered_data ( data ) classmethod \u00b6 Filter the time series data by removing NAN data Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description Dict[datetime.datetime, float] Filtered data Source code in testplan/verification/plugins/metrics.py @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )]) latest ( data ) classmethod \u00b6 Returns the latest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) max ( data ) classmethod \u00b6 Returns the max value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Max value Source code in testplan/verification/plugins/metrics.py @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) min ( data ) classmethod \u00b6 Returns the min value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Min value Source code in testplan/verification/plugins/metrics.py @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) oldest ( data ) classmethod \u00b6 Returns the oldest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) random ( data ) classmethod \u00b6 Returns the random value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Random value Source code in testplan/verification/plugins/metrics.py @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , )","title":"__init__"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema","text":"The Base class for Plugin that make a HTTP Network call. Source code in testplan/verification/__init__.py class HTTPRequestSchema ( SchemaModel ): \"\"\" The Base class for Plugin that make a HTTP Network call. \"\"\" method : str = Field ( default = \"GET\" , description = \"HTTP method to be used\" ) headers : Dict [ str , Union [ SecretStr , Secret ]] = Field ( default = dict (), description = \"Headers to be sent with the request\" ) params : Dict [ str , str ] = Field ( default = dict (), description = \"Query params to be sent with the request\" ) verify : bool = Field ( default = True , description = \"Verify the target URL SSL certificates\" ) # Authentication basic_auth : Optional [ Tuple [ str , Union [ SecretStr , Secret ]]] = Field ( default = None , description = \"Basic Auth authentication for the HTTP call\" ) bearer_token : Optional [ Union [ SecretStr , Secret ]] = Field ( default = None , description = \"Bearer token authentication for the HTTP call\" ) # Certificate cert : Optional [ Tuple [ Path , Path ]] = Field ( default = None , description = \"The certificate to be sent for HTTP call. The tuple should contain Certificate and Key File path\" , ) timeout : int = Field ( default = 10000 , description = \"Timeout in milliseconds at which the HTTP requests will timeout\" , gt = 0 , ) _validate_method = validator ( \"method\" , pre = True , allow_reuse = True )( BuiltinUtils . Request . validate_method ) def get_request_cert ( self ) -> Optional [ Tuple [ Path , Path ]]: \"\"\" Returns the resolved Certificate Paths by expanding the user path (~). \"\"\" if self . cert : return ( self . cert [ 0 ] . expanduser () . resolve (), self . cert [ 1 ] . expanduser () . resolve (), ) return None","title":"HTTPRequestSchema"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.basic_auth","text":"Basic Auth authentication for the HTTP call","title":"basic_auth"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.bearer_token","text":"Bearer token authentication for the HTTP call","title":"bearer_token"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.cert","text":"The certificate to be sent for HTTP call. The tuple should contain Certificate and Key File path","title":"cert"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.headers","text":"Headers to be sent with the request","title":"headers"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.method","text":"HTTP method to be used","title":"method"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.params","text":"Query params to be sent with the request","title":"params"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.timeout","text":"Timeout in milliseconds at which the HTTP requests will timeout","title":"timeout"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.verify","text":"Verify the target URL SSL certificates","title":"verify"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestSchema.get_request_cert","text":"Returns the resolved Certificate Paths by expanding the user path (~). Source code in testplan/verification/__init__.py def get_request_cert ( self ) -> Optional [ Tuple [ Path , Path ]]: \"\"\" Returns the resolved Certificate Paths by expanding the user path (~). \"\"\" if self . cert : return ( self . cert [ 0 ] . expanduser () . resolve (), self . cert [ 1 ] . expanduser () . resolve (), ) return None","title":"get_request_cert()"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestVerification","text":"Makes requests to the specified endpoints and verifies that the service is returning a valid response along with verifying the response time of the service being less than latency field. The user can also specify a count attribute requesting the tool to make count number of requests to the same endpoints. Source code in testplan/verification/__init__.py class HTTPRequestVerification ( HTTPRequestSchema ): \"\"\" Makes requests to the specified endpoints and verifies that the service is returning a valid response along with verifying the response time of the service being less than `latency` field. The user can also specify a `count` attribute requesting the tool to make `count` number of requests to the same endpoints. \"\"\" count : int = Field ( default = 1 , description = \"Number of HTTP calls to be sent to each of the URL\" , ge = 1 , ) latency : int = Field ( default = 50 , description = \"Expected Latency in ms. A latency below this value indicates successful verification\" , ge = 1 , ) status_codes : List [ int ] = Field ( default_factory = functools . partial ( list , range ( 200 , 300 )), description = \"The list of status code which will be the comparison factor for the HTTP responses\" , ) urls : List [ AnyHttpUrl ] = Field ( default = list (), description = \"List of HTTP/s URLs to be requested\" )","title":"HTTPRequestVerification"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestVerification.count","text":"Number of HTTP calls to be sent to each of the URL","title":"count"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestVerification.latency","text":"Expected Latency in ms. A latency below this value indicates successful verification","title":"latency"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestVerification.status_codes","text":"The list of status code which will be the comparison factor for the HTTP responses","title":"status_codes"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.HTTPRequestVerification.urls","text":"List of HTTP/s URLs to be requested","title":"urls"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.OpenTSDBVerification","text":"The OpenTSDB Verification Plugin gets the metrics from an OpenTSDB server and compares it with the provided comparison parameters in the testplan. If the condition passes Source code in testplan/verification/__init__.py class OpenTSDBVerification ( HTTPRequestSchema ): \"\"\" The OpenTSDB Verification Plugin gets the metrics from an OpenTSDB server and compares it with the provided comparison parameters in the testplan. If the condition passes \"\"\" url : AnyHttpUrl = Field ( ... , description = \"The OpenTSDB server URL to get the metrics from\" ) # Override method to change default value method : str = Field ( default = \"POST\" , description = \"HTTP method to be used\" ) query : Dict [ str , Any ] = Field ( default = dict (), description = \"The OpenTSDB query sent to the server.\" ) criteria : List [ MultipleConditionalsMetricsVerificationCriteria ] = Field ( default = list (), description = ( \"Metrics verification criteria without state information.\" \"All the criteria part of this list must pass for the verification to be successful\" ), ) state_bound_criteria : List [ StateBoundMetricsVerificationCriteria ] = Field ( default = list (), description = ( \"Metrics verification criteria with state.\" \"All the criteria part of this list must pass for the verification to be successful\" ), ) @validator ( \"state_bound_criteria\" , pre = True , always = True ) def _criteria_validation ( cls , v , values ): # The input must contain at least one of \"criteria\" or \"state_bound_criteria\" if not v and not values . get ( \"criteria\" , list ()): raise ValueError ( \"Either criteria or state_bound_criteria must be present for this configuration.\" ) return v _validate_method = validator ( \"method\" , pre = True , allow_reuse = True )( BuiltinUtils . Request . validate_method )","title":"OpenTSDBVerification"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.OpenTSDBVerification.criteria","text":"Metrics verification criteria without state information.All the criteria part of this list must pass for the verification to be successful","title":"criteria"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.OpenTSDBVerification.query","text":"The OpenTSDB query sent to the server.","title":"query"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.OpenTSDBVerification.state_bound_criteria","text":"Metrics verification criteria with state.All the criteria part of this list must pass for the verification to be successful","title":"state_bound_criteria"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.OpenTSDBVerification.url","text":"The OpenTSDB server URL to get the metrics from","title":"url"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.PythonModuleVerification","text":"The Python Module verification. Runs an custom python script given the path of the script. The executable of the script is set to sys.executable by default which can be overridden by a custom executable. The script can also be passed a list of arguments that are provided in the arguments argument which are passed to the script by separating each element of the argument by space. The user of this plugin takes the entire responsibility of the script executed. YChaos is only responsible of running the script and collecting the exitcode of the script with which the state of the system is verified/monitored. Source code in testplan/verification/__init__.py class PythonModuleVerification ( SchemaModel ): \"\"\" The Python Module verification. Runs an custom python script given the path of the script. The executable of the script is set to `sys.executable` by default which can be overridden by a custom executable. The script can also be passed a list of arguments that are provided in the arguments argument which are passed to the script by separating each element of the argument by space. The user of this plugin takes the entire responsibility of the script executed. YChaos is only responsible of running the script and collecting the exitcode of the script with which the state of the system is verified/monitored. \"\"\" path : Path = Field ( ... , description = \"The absolute path of the python script\" ) executable : str = Field ( default = sys . executable , description = \"The python shell to be used for executing the script\" , ) arguments : List [ str ] = Field ( default = list (), description = \"List of arguments to be sent to the script. The arguments in the list will be sent to the script space separated\" , ) def safe_arguments ( self ): return [ shlex . quote ( x ) for x in self . arguments ]","title":"PythonModuleVerification"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.PythonModuleVerification.arguments","text":"List of arguments to be sent to the script. The arguments in the list will be sent to the script space separated","title":"arguments"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.PythonModuleVerification.executable","text":"The python shell to be used for executing the script","title":"executable"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.PythonModuleVerification.path","text":"The absolute path of the python script","title":"path"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification","text":"The SDV4VerificationPlugin offers the user of YChaos to configure a 3 rd party Screwdriver Job that is triggered remotely by YChaos and upon the successful completion of that SDv4 job, the verification is marked as successful. If the SDv4 job fails/is aborted, the verification is marked as failure. Know more about Screwdriver CI/CD Source code in testplan/verification/__init__.py class SDv4Verification ( SchemaModel ): \"\"\" The SDV4VerificationPlugin offers the user of YChaos to configure a 3rd party Screwdriver Job that is triggered remotely by YChaos and upon the successful completion of that SDv4 job, the verification is marked as successful. If the SDv4 job fails/is aborted, the verification is marked as failure. [Know more about Screwdriver CI/CD](https://screwdriver.cd/) \"\"\" pipeline_id : int = Field ( ... , description = \"SDv4 pipeline ID\" , examples = [ 123456 , 1041241 ] ) job_name : str = Field ( ... , description = \"Job name in the pipeline\" , examples = [ \"test_validation\" , \"state_verification\" ], ) sd_api_url : AnyHttpUrl = Field ( ... , description = \"SDv4 API URL\" ) sd_api_token : Union [ SecretStr , Secret ] = Field ( ... , description = \"The Screwdriver pipeline/user access token to be able to start the jon in the pipeline\" , ) job_timeout : PositiveInt = Field ( default = 3600 , description = \"Job Timeout in seconds\" )","title":"SDv4Verification"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification.job_name","text":"Job name in the pipeline","title":"job_name"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification.job_timeout","text":"Job Timeout in seconds","title":"job_timeout"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification.pipeline_id","text":"SDv4 pipeline ID","title":"pipeline_id"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification.sd_api_token","text":"The Screwdriver pipeline/user access token to be able to start the jon in the pipeline","title":"sd_api_token"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.SDv4Verification.sd_api_url","text":"SDv4 API URL","title":"sd_api_url"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig","text":"The verification configuration that is executed during some state of the system to verify the system is in a favorable conditions or not. Source code in testplan/verification/__init__.py class VerificationConfig ( SchemaModel ): \"\"\" The verification configuration that is executed during some state of the system to verify the system is in a favorable conditions or not. \"\"\" delay_before : float = Field ( default = 0 , description = \"delay (in ms) to be introduced before running this plugin\" , ) delay_after : float = Field ( default = 0 , description = \"delay (in ms) to be introduced after running this plugin\" , ) states : Union [ SystemState , List [ SystemState ]] = Field ( ... , description = \"A system state or a list of system states in which this verification plugin should be executed.\" , ) type : VerificationType = Field ( ... , description = \"The verification type to be used.\" ) strict : bool = Field ( default = True , description = ( \"Setting this value to false implies the overall verification\" \" does not fail because of the failure of this test.\" ), ) config : Dict [ str , Any ] = Field ( ... , description = \"The verification type configuration\" ) def get_verification_config ( self ): return self . type . metadata . schema ( ** self . config ) @validator ( \"states\" , pre = True ) def _parse_states_to_list ( cls , v ): \"\"\" Parses the state object to List of states to keep the access consistent Args: v: SystemState object/ List of SystemState Returns: List of SystemState \"\"\" return BuiltinUtils . wrap_if_non_iterable ( v ) @validator ( \"config\" , pre = True ) def _parse_plugin_configuration ( cls , v , values ): \"\"\" Validates the plugin configuration to match with the mapper class of the plugin. Args: v: Plugin configuration values: verification configuration Returns: Parsed mapper object \"\"\" if \"type\" in values : return VerificationType ( values [ \"type\" ]) . metadata . schema ( ** v ) else : return v","title":"VerificationConfig"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.config","text":"The verification type configuration","title":"config"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.delay_after","text":"delay (in ms) to be introduced after running this plugin","title":"delay_after"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.delay_before","text":"delay (in ms) to be introduced before running this plugin","title":"delay_before"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.states","text":"A system state or a list of system states in which this verification plugin should be executed.","title":"states"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.strict","text":"Setting this value to false implies the overall verification does not fail because of the failure of this test.","title":"strict"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationConfig.type","text":"The verification type to be used.","title":"type"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.VerificationType","text":"Defines the Type of plugin to be used for verification. Source code in testplan/verification/__init__.py class VerificationType ( AEnum ): \"\"\" Defines the Type of plugin to be used for verification. \"\"\" # The metadata object will contain the following attributes # 1. schema : The Schema class of the VerificationType PYTHON_MODULE = \"python_module\" , SimpleNamespace ( schema = PythonModuleVerification ) HTTP_REQUEST = \"http_request\" , SimpleNamespace ( schema = HTTPRequestVerification ) SDV4_VERIFICATION = ( \"sdv4\" , SimpleNamespace ( schema = SDv4Verification ), ) OPENTSDB_VERIFICATION = \"tsdb\" , SimpleNamespace ( schema = OpenTSDBVerification ) # For Testing purpose, cannot be used by users. NOOP = \"noop\" , SimpleNamespace ( schema = NoOpConfig )","title":"VerificationType"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.plugins","text":"","title":"plugins"},{"location":"package_docs/testplan/verification/#ychaos.testplan.verification.plugins.metrics","text":"","title":"metrics"},{"location":"package_docs/testplan/verification/plugins/metrics/","text":"ComparisonCondition ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/verification/plugins/metrics.py class ComparisonCondition ( SchemaModel ): comparator : MetricsComparator = Field ( ... , description = \"Comparison condition to compare between the metrics data and fetched value\" , ) value : Union [ float , Tuple ] = Field ( ... , description = \"Numerical value/range to be used for comparison\" ) # Resolve Aliases @validator ( \"comparator\" , pre = True ) def resolve_comparator ( cls , v , values ): values [ \"_comparator\" ] = v # Store the actual value in a private attribute return v comparator : MetricsComparator pydantic-field required \u00b6 Comparison condition to compare between the metrics data and fetched value value : Union [ float , Tuple ] pydantic-field required \u00b6 Numerical value/range to be used for comparison MetricsAggregator ( AEnum ) \u00b6 The Metrics aggregator options. Allows the user to transform a time series data into comparable data. Source code in testplan/verification/plugins/metrics.py class MetricsAggregator ( AEnum ): \"\"\" The Metrics aggregator options. Allows the user to transform a time series data into comparable data. \"\"\" AVG = \"avg\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . avg , __desc__ = \"Gets the Average of all valid datapoints\" , ) LATEST = \"latest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . latest , __desc__ = \"Gets the latest valid datapoint\" , ) OLDEST = \"oldest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . oldest , __desc__ = \"Gets the oldest valid datapoint\" , ) RANDOM = \"random\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . random , __desc__ = \"Gets a random valid datapoint\" , ) MAX = \"max\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . max , __desc__ = \"Gets the largest valid datapoint\" , ) MIN = \"min\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . min , __desc__ = \"Gets the smallest valid datapoint\" , ) SLOPE = \"slope\" , SimpleNamespace ( aggregate = lambda data : BuiltinUtils . raise_error ( NotImplementedError ( \"This aggregator is not implemented\" ) ), __desc__ = \"Gets the slope of the datapoints\" , ) MetricsComparator ( AEnum ) \u00b6 An enumeration. Source code in testplan/verification/plugins/metrics.py class MetricsComparator ( AEnum ): LT = \"lt\" , SimpleNamespace ( __aliases__ = ( \"<\" ,), compare = lambda data , expected : data < expected , relational = True , ) LE = \"le\" , SimpleNamespace ( __aliases__ = ( \"<=\" ,), compare = lambda data , expected : data <= expected , relational = True , ) GT = \"gt\" , SimpleNamespace ( __aliases__ = ( \">\" ,), compare = lambda data , expected : data > expected , relational = True , ) GE = \"ge\" , SimpleNamespace ( __aliases__ = ( \">=\" ,), compare = lambda data , expected : data >= expected , relational = True , ) EQ = \"eq\" , SimpleNamespace ( __aliases__ = ( \"==\" ,), compare = lambda data , expected : data == expected , relational = True , ) NEQ = \"neq\" , SimpleNamespace ( __aliases__ = ( \"!=\" ,), compare = lambda data , expected : data != expected , relational = True , ) RANGE = \"range\" , SimpleNamespace ( __aliases__ = ( \"()\" , \"(]\" , \"[)\" , \"[]\" ), compare = lambda range_type , data , expected_range : MetricsComparator . range_compare ( # type: ignore range_type , data , expected_range ), relational = False , ) # The below comparators can only be used for state bound criteria PCT = \"pct\" , SimpleNamespace ( __aliases__ = ( \" %% \" ,), compare = lambda new_data , old_data , expected : MetricsComparator . pct_compare ( # type: ignore new_data , old_data , expected ), relational = False , ) @classmethod @validate_arguments def pct_compare ( cls , new_data : float , old_data : float , expected : Union [ float , Tuple ] ) -> bool : \"\"\" Calculate the percentage variation from new_val and old_val Args: new_data: New Value from data old_data: Old value from saved data expected: Expected percentage change Returns: True if the condition meets \"\"\" pct_change = (( new_data - old_data ) / old_data ) * 100 if isinstance ( expected , tuple ): return ( BuiltinUtils . Float . parse ( expected [ 0 ], - math . inf ) <= pct_change <= BuiltinUtils . Float . parse ( expected [ 1 ], math . inf ) ) else : return pct_change == expected @classmethod @validate_arguments def range_compare ( cls , range_type : str , data : float , expected_range : Tuple , ) -> bool : \"\"\" Args: range_type: The range type that depicts inclusiveness data: Data to be compared expected_range: Expected range for the data to be within Returns: \"\"\" if range_type == MetricsComparator . RANGE . value : range_type = \"()\" if range_type == \"()\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"[)\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"(]\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) else : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) MultipleConditionalsMetricsVerificationCriteria ( SchemaModel ) pydantic-model \u00b6 Defines the Metrics Verification criteria Source code in testplan/verification/plugins/metrics.py class MultipleConditionalsMetricsVerificationCriteria ( SchemaModel ): \"\"\" Defines the Metrics Verification criteria \"\"\" aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) conditionals : List [ ComparisonCondition ] = Field ( default = list (), description = \"The conditionals out of which any one needs to pass for the criteria to be marked as passed\" , ) aggeragator : MetricsAggregator pydantic-field \u00b6 Data aggregator conditionals : List [ ychaos . testplan . verification . plugins . metrics . ComparisonCondition ] pydantic-field \u00b6 The conditionals out of which any one needs to pass for the criteria to be marked as passed StateBoundMetricsVerificationCriteria ( SchemaModel ) pydantic-model \u00b6 Source code in testplan/verification/plugins/metrics.py class StateBoundMetricsVerificationCriteria ( SchemaModel ): aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) criteria : Dict [ SystemState , ComparisonCondition ] = Field ( ... , description = \"Metrics verification criteria with state.\" , ) def get_criteria ( self , state : SystemState ): return self . criteria [ state . value ] # type: ignore class Config : use_enum_values = True # To make the model JSON serializable aggeragator : MetricsAggregator pydantic-field \u00b6 Data aggregator criteria : Dict [ ychaos . testplan . SystemState , ychaos . testplan . verification . plugins . metrics . ComparisonCondition ] pydantic-field required \u00b6 Metrics verification criteria with state. TimeSeriesDataAggregator \u00b6 The class containing the implementations of different Time Series data Aggregator Source code in testplan/verification/plugins/metrics.py class TimeSeriesDataAggregator : \"\"\" The class containing the implementations of different Time Series data Aggregator \"\"\" @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )]) @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , ) @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , ) avg ( data ) classmethod \u00b6 Returns the Average value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Average value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , ) get_filtered_data ( data ) classmethod \u00b6 Filter the time series data by removing NAN data Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description Dict[datetime.datetime, float] Filtered data Source code in testplan/verification/plugins/metrics.py @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )]) latest ( data ) classmethod \u00b6 Returns the latest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) max ( data ) classmethod \u00b6 Returns the max value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Max value Source code in testplan/verification/plugins/metrics.py @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) min ( data ) classmethod \u00b6 Returns the min value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Min value Source code in testplan/verification/plugins/metrics.py @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) oldest ( data ) classmethod \u00b6 Returns the oldest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) random ( data ) classmethod \u00b6 Returns the random value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Random value Source code in testplan/verification/plugins/metrics.py @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , )","title":"metrics"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.ComparisonCondition","text":"Source code in testplan/verification/plugins/metrics.py class ComparisonCondition ( SchemaModel ): comparator : MetricsComparator = Field ( ... , description = \"Comparison condition to compare between the metrics data and fetched value\" , ) value : Union [ float , Tuple ] = Field ( ... , description = \"Numerical value/range to be used for comparison\" ) # Resolve Aliases @validator ( \"comparator\" , pre = True ) def resolve_comparator ( cls , v , values ): values [ \"_comparator\" ] = v # Store the actual value in a private attribute return v","title":"ComparisonCondition"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.ComparisonCondition.comparator","text":"Comparison condition to compare between the metrics data and fetched value","title":"comparator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.ComparisonCondition.value","text":"Numerical value/range to be used for comparison","title":"value"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.MetricsAggregator","text":"The Metrics aggregator options. Allows the user to transform a time series data into comparable data. Source code in testplan/verification/plugins/metrics.py class MetricsAggregator ( AEnum ): \"\"\" The Metrics aggregator options. Allows the user to transform a time series data into comparable data. \"\"\" AVG = \"avg\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . avg , __desc__ = \"Gets the Average of all valid datapoints\" , ) LATEST = \"latest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . latest , __desc__ = \"Gets the latest valid datapoint\" , ) OLDEST = \"oldest\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . oldest , __desc__ = \"Gets the oldest valid datapoint\" , ) RANDOM = \"random\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . random , __desc__ = \"Gets a random valid datapoint\" , ) MAX = \"max\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . max , __desc__ = \"Gets the largest valid datapoint\" , ) MIN = \"min\" , SimpleNamespace ( aggregate = TimeSeriesDataAggregator . min , __desc__ = \"Gets the smallest valid datapoint\" , ) SLOPE = \"slope\" , SimpleNamespace ( aggregate = lambda data : BuiltinUtils . raise_error ( NotImplementedError ( \"This aggregator is not implemented\" ) ), __desc__ = \"Gets the slope of the datapoints\" , )","title":"MetricsAggregator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.MetricsComparator","text":"An enumeration. Source code in testplan/verification/plugins/metrics.py class MetricsComparator ( AEnum ): LT = \"lt\" , SimpleNamespace ( __aliases__ = ( \"<\" ,), compare = lambda data , expected : data < expected , relational = True , ) LE = \"le\" , SimpleNamespace ( __aliases__ = ( \"<=\" ,), compare = lambda data , expected : data <= expected , relational = True , ) GT = \"gt\" , SimpleNamespace ( __aliases__ = ( \">\" ,), compare = lambda data , expected : data > expected , relational = True , ) GE = \"ge\" , SimpleNamespace ( __aliases__ = ( \">=\" ,), compare = lambda data , expected : data >= expected , relational = True , ) EQ = \"eq\" , SimpleNamespace ( __aliases__ = ( \"==\" ,), compare = lambda data , expected : data == expected , relational = True , ) NEQ = \"neq\" , SimpleNamespace ( __aliases__ = ( \"!=\" ,), compare = lambda data , expected : data != expected , relational = True , ) RANGE = \"range\" , SimpleNamespace ( __aliases__ = ( \"()\" , \"(]\" , \"[)\" , \"[]\" ), compare = lambda range_type , data , expected_range : MetricsComparator . range_compare ( # type: ignore range_type , data , expected_range ), relational = False , ) # The below comparators can only be used for state bound criteria PCT = \"pct\" , SimpleNamespace ( __aliases__ = ( \" %% \" ,), compare = lambda new_data , old_data , expected : MetricsComparator . pct_compare ( # type: ignore new_data , old_data , expected ), relational = False , ) @classmethod @validate_arguments def pct_compare ( cls , new_data : float , old_data : float , expected : Union [ float , Tuple ] ) -> bool : \"\"\" Calculate the percentage variation from new_val and old_val Args: new_data: New Value from data old_data: Old value from saved data expected: Expected percentage change Returns: True if the condition meets \"\"\" pct_change = (( new_data - old_data ) / old_data ) * 100 if isinstance ( expected , tuple ): return ( BuiltinUtils . Float . parse ( expected [ 0 ], - math . inf ) <= pct_change <= BuiltinUtils . Float . parse ( expected [ 1 ], math . inf ) ) else : return pct_change == expected @classmethod @validate_arguments def range_compare ( cls , range_type : str , data : float , expected_range : Tuple , ) -> bool : \"\"\" Args: range_type: The range type that depicts inclusiveness data: Data to be compared expected_range: Expected range for the data to be within Returns: \"\"\" if range_type == MetricsComparator . RANGE . value : range_type = \"()\" if range_type == \"()\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"[)\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data < BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) elif range_type == \"(]\" : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) < data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) ) else : return ( BuiltinUtils . Float . parse ( expected_range [ 0 ], - math . inf ) <= data <= BuiltinUtils . Float . parse ( expected_range [ 1 ], math . inf ) )","title":"MetricsComparator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.MultipleConditionalsMetricsVerificationCriteria","text":"Defines the Metrics Verification criteria Source code in testplan/verification/plugins/metrics.py class MultipleConditionalsMetricsVerificationCriteria ( SchemaModel ): \"\"\" Defines the Metrics Verification criteria \"\"\" aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) conditionals : List [ ComparisonCondition ] = Field ( default = list (), description = \"The conditionals out of which any one needs to pass for the criteria to be marked as passed\" , )","title":"MultipleConditionalsMetricsVerificationCriteria"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.MultipleConditionalsMetricsVerificationCriteria.aggeragator","text":"Data aggregator","title":"aggeragator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.MultipleConditionalsMetricsVerificationCriteria.conditionals","text":"The conditionals out of which any one needs to pass for the criteria to be marked as passed","title":"conditionals"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.StateBoundMetricsVerificationCriteria","text":"Source code in testplan/verification/plugins/metrics.py class StateBoundMetricsVerificationCriteria ( SchemaModel ): aggeragator : MetricsAggregator = Field ( default = MetricsAggregator . AVG , description = \"Data aggregator\" ) criteria : Dict [ SystemState , ComparisonCondition ] = Field ( ... , description = \"Metrics verification criteria with state.\" , ) def get_criteria ( self , state : SystemState ): return self . criteria [ state . value ] # type: ignore class Config : use_enum_values = True # To make the model JSON serializable","title":"StateBoundMetricsVerificationCriteria"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.StateBoundMetricsVerificationCriteria.aggeragator","text":"Data aggregator","title":"aggeragator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.StateBoundMetricsVerificationCriteria.criteria","text":"Metrics verification criteria with state.","title":"criteria"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator","text":"The class containing the implementations of different Time Series data Aggregator Source code in testplan/verification/plugins/metrics.py class TimeSeriesDataAggregator : \"\"\" The class containing the implementations of different Time Series data Aggregator \"\"\" @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )]) @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , ) @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN ) @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , )","title":"TimeSeriesDataAggregator"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.avg","text":"Returns the Average value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Average value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def avg ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the Average value of a time series data filtering out NAN Args: data: Time series data Returns: Average value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( sum ( _filtered_data . values ()) / len ( _filtered_data ), _filtered_data , BuiltinUtils . Float . NAN , )","title":"avg()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.get_filtered_data","text":"Filter the time series data by removing NAN data Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description Dict[datetime.datetime, float] Filtered data Source code in testplan/verification/plugins/metrics.py @classmethod def get_filtered_data ( cls , data : Dict [ datetime , float ]) -> Dict [ datetime , float ]: \"\"\" Filter the time series data by removing NAN data Args: data: Time series data Returns: Filtered data \"\"\" return dict ([( _k , _v ) for _k , _v in data . items () if not math . isnan ( _v )])","title":"get_filtered_data()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.latest","text":"Returns the latest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def latest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the latest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ max ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN )","title":"latest()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.max","text":"Returns the max value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Max value Source code in testplan/verification/plugins/metrics.py @classmethod def max ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the max value of a time series data filtering out NAN Args: data: Time series data Returns: Max value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( max ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN )","title":"max()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.min","text":"Returns the min value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Min value Source code in testplan/verification/plugins/metrics.py @classmethod def min ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the min value of a time series data filtering out NAN Args: data: Time series data Returns: Min value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( min ( _filtered_data . values ()), _filtered_data , BuiltinUtils . Float . NAN )","title":"min()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.oldest","text":"Returns the oldest value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Latest value over the time Source code in testplan/verification/plugins/metrics.py @classmethod def oldest ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the oldest value of a time series data filtering out NAN Args: data: Time series data Returns: Latest value over the time \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( _filtered_data [ min ( _filtered_data )], _filtered_data , BuiltinUtils . Float . NAN )","title":"oldest()"},{"location":"package_docs/testplan/verification/plugins/metrics/#ychaos.testplan.verification.plugins.metrics.TimeSeriesDataAggregator.random","text":"Returns the random value of a time series data filtering out NAN Parameters: Name Type Description Default data Dict[datetime.datetime, float] Time series data required Returns: Type Description float Random value Source code in testplan/verification/plugins/metrics.py @classmethod def random ( cls , data : Dict [ datetime , float ]) -> float : \"\"\" Returns the random value of a time series data filtering out NAN Args: data: Time series data Returns: Random value \"\"\" _filtered_data = cls . get_filtered_data ( data ) return BuiltinUtils . return_if_true ( random . choice ( # nosec : Not using for Crypto purpose list ( _filtered_data . values ()) ), _filtered_data , BuiltinUtils . Float . NAN , )","title":"random()"},{"location":"package_docs/utils/dependency/","text":"DependencyUtils \u00b6 DependencyUtils provides utility methods to handle and import optional dependencies in the YChaos package. Source code in utils/dependency.py class DependencyUtils : \"\"\" DependencyUtils provides utility methods to handle and import optional dependencies in the YChaos package. \"\"\" @classmethod def import_module ( cls , name : str , message : str = None , raise_error : bool = True , warn : bool = True ) -> Optional [ Any ]: \"\"\" Calling this method with a module name is similar to calling `import ...`. This can be used to import optional dependencies in the package. Args: name: Module name message: Error message to be printed on console when the import fails raise_error: Raise an error if the import fails warn: Raise warning if the import fails Raises: ImportError: when `raise_error` is True and the module is not present Returns: Optional Module \"\"\" try : module = importlib . import_module ( name ) except ImportError as import_error : if not message : message = f \"Dependency { name } is not installed.\" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : return None return module @classmethod @validate_arguments def import_from ( cls , module_name : str , attrs : Tuple [ str , ... ], message : str = None , raise_error : bool = True , warn : bool = True , ) -> Tuple [ Any , ... ]: \"\"\" Calling this method with a module and an attribute is similar to calling `from ... import ...`. This can be used to import optional dependency in the package. Examples: ```python from ychaos.utils.dependency import DependencyHandler BaseModel, Field = DependencyHandler.import_from(\"pydantic\", (\"BaseModel\", \"Field\")) ``` The above code snippet is same as ```python from pydantic import BaseModel, Field ``` Args: module_name: Valid Python Module name attrs: Tuple of attribute names from the module message: message to be printed in case of an error raise_error: Raise an error if the import fails warn: Throw a warning if the import fails Raises: ImportError: when `raise_error` is true and `attr_name` cannot be imported from the `module_name` Returns: An attribute from module_name if exists, None otherwise \"\"\" module = cls . import_module ( name = module_name , message = message , raise_error = raise_error , warn = warn ) if not module : return ( None ,) * len ( attrs ) else : _attr_list = list () for _attr_name in attrs : try : attr = getattr ( module , _attr_name ) _attr_list . append ( attr ) except AttributeError as attr_error : if not message : message = f \"cannot import { _attr_name } from { module_name } \" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : _attr_list . append ( None ) return tuple ( _attr_list ) import_from ( cls , module_name , attrs , message = None , raise_error = True , warn = True ) classmethod \u00b6 Calling this method with a module and an attribute is similar to calling from ... import ... . This can be used to import optional dependency in the package. Examples: from ychaos.utils.dependency import DependencyHandler BaseModel , Field = DependencyHandler . import_from ( \"pydantic\" , ( \"BaseModel\" , \"Field\" )) The above code snippet is same as from pydantic import BaseModel , Field Parameters: Name Type Description Default module_name str Valid Python Module name required attrs Tuple[str, ...] Tuple of attribute names from the module required message str message to be printed in case of an error None raise_error bool Raise an error if the import fails True warn bool Throw a warning if the import fails True Exceptions: Type Description ImportError when raise_error is true and attr_name cannot be imported from the module_name Returns: Type Description Tuple[Any, ...] An attribute from module_name if exists, None otherwise Source code in utils/dependency.py @classmethod @validate_arguments def import_from ( cls , module_name : str , attrs : Tuple [ str , ... ], message : str = None , raise_error : bool = True , warn : bool = True , ) -> Tuple [ Any , ... ]: \"\"\" Calling this method with a module and an attribute is similar to calling `from ... import ...`. This can be used to import optional dependency in the package. Examples: ```python from ychaos.utils.dependency import DependencyHandler BaseModel, Field = DependencyHandler.import_from(\"pydantic\", (\"BaseModel\", \"Field\")) ``` The above code snippet is same as ```python from pydantic import BaseModel, Field ``` Args: module_name: Valid Python Module name attrs: Tuple of attribute names from the module message: message to be printed in case of an error raise_error: Raise an error if the import fails warn: Throw a warning if the import fails Raises: ImportError: when `raise_error` is true and `attr_name` cannot be imported from the `module_name` Returns: An attribute from module_name if exists, None otherwise \"\"\" module = cls . import_module ( name = module_name , message = message , raise_error = raise_error , warn = warn ) if not module : return ( None ,) * len ( attrs ) else : _attr_list = list () for _attr_name in attrs : try : attr = getattr ( module , _attr_name ) _attr_list . append ( attr ) except AttributeError as attr_error : if not message : message = f \"cannot import { _attr_name } from { module_name } \" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : _attr_list . append ( None ) return tuple ( _attr_list ) import_module ( name , message = None , raise_error = True , warn = True ) classmethod \u00b6 Calling this method with a module name is similar to calling import ... . This can be used to import optional dependencies in the package. Parameters: Name Type Description Default name str Module name required message str Error message to be printed on console when the import fails None raise_error bool Raise an error if the import fails True warn bool Raise warning if the import fails True Exceptions: Type Description ImportError when raise_error is True and the module is not present Returns: Type Description Optional[Any] Optional Module Source code in utils/dependency.py @classmethod def import_module ( cls , name : str , message : str = None , raise_error : bool = True , warn : bool = True ) -> Optional [ Any ]: \"\"\" Calling this method with a module name is similar to calling `import ...`. This can be used to import optional dependencies in the package. Args: name: Module name message: Error message to be printed on console when the import fails raise_error: Raise an error if the import fails warn: Raise warning if the import fails Raises: ImportError: when `raise_error` is True and the module is not present Returns: Optional Module \"\"\" try : module = importlib . import_module ( name ) except ImportError as import_error : if not message : message = f \"Dependency { name } is not installed.\" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : return None return module","title":"dependency"},{"location":"package_docs/utils/dependency/#ychaos.utils.dependency.DependencyUtils","text":"DependencyUtils provides utility methods to handle and import optional dependencies in the YChaos package. Source code in utils/dependency.py class DependencyUtils : \"\"\" DependencyUtils provides utility methods to handle and import optional dependencies in the YChaos package. \"\"\" @classmethod def import_module ( cls , name : str , message : str = None , raise_error : bool = True , warn : bool = True ) -> Optional [ Any ]: \"\"\" Calling this method with a module name is similar to calling `import ...`. This can be used to import optional dependencies in the package. Args: name: Module name message: Error message to be printed on console when the import fails raise_error: Raise an error if the import fails warn: Raise warning if the import fails Raises: ImportError: when `raise_error` is True and the module is not present Returns: Optional Module \"\"\" try : module = importlib . import_module ( name ) except ImportError as import_error : if not message : message = f \"Dependency { name } is not installed.\" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : return None return module @classmethod @validate_arguments def import_from ( cls , module_name : str , attrs : Tuple [ str , ... ], message : str = None , raise_error : bool = True , warn : bool = True , ) -> Tuple [ Any , ... ]: \"\"\" Calling this method with a module and an attribute is similar to calling `from ... import ...`. This can be used to import optional dependency in the package. Examples: ```python from ychaos.utils.dependency import DependencyHandler BaseModel, Field = DependencyHandler.import_from(\"pydantic\", (\"BaseModel\", \"Field\")) ``` The above code snippet is same as ```python from pydantic import BaseModel, Field ``` Args: module_name: Valid Python Module name attrs: Tuple of attribute names from the module message: message to be printed in case of an error raise_error: Raise an error if the import fails warn: Throw a warning if the import fails Raises: ImportError: when `raise_error` is true and `attr_name` cannot be imported from the `module_name` Returns: An attribute from module_name if exists, None otherwise \"\"\" module = cls . import_module ( name = module_name , message = message , raise_error = raise_error , warn = warn ) if not module : return ( None ,) * len ( attrs ) else : _attr_list = list () for _attr_name in attrs : try : attr = getattr ( module , _attr_name ) _attr_list . append ( attr ) except AttributeError as attr_error : if not message : message = f \"cannot import { _attr_name } from { module_name } \" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : _attr_list . append ( None ) return tuple ( _attr_list )","title":"DependencyUtils"},{"location":"package_docs/utils/dependency/#ychaos.utils.dependency.DependencyUtils.import_from","text":"Calling this method with a module and an attribute is similar to calling from ... import ... . This can be used to import optional dependency in the package. Examples: from ychaos.utils.dependency import DependencyHandler BaseModel , Field = DependencyHandler . import_from ( \"pydantic\" , ( \"BaseModel\" , \"Field\" )) The above code snippet is same as from pydantic import BaseModel , Field Parameters: Name Type Description Default module_name str Valid Python Module name required attrs Tuple[str, ...] Tuple of attribute names from the module required message str message to be printed in case of an error None raise_error bool Raise an error if the import fails True warn bool Throw a warning if the import fails True Exceptions: Type Description ImportError when raise_error is true and attr_name cannot be imported from the module_name Returns: Type Description Tuple[Any, ...] An attribute from module_name if exists, None otherwise Source code in utils/dependency.py @classmethod @validate_arguments def import_from ( cls , module_name : str , attrs : Tuple [ str , ... ], message : str = None , raise_error : bool = True , warn : bool = True , ) -> Tuple [ Any , ... ]: \"\"\" Calling this method with a module and an attribute is similar to calling `from ... import ...`. This can be used to import optional dependency in the package. Examples: ```python from ychaos.utils.dependency import DependencyHandler BaseModel, Field = DependencyHandler.import_from(\"pydantic\", (\"BaseModel\", \"Field\")) ``` The above code snippet is same as ```python from pydantic import BaseModel, Field ``` Args: module_name: Valid Python Module name attrs: Tuple of attribute names from the module message: message to be printed in case of an error raise_error: Raise an error if the import fails warn: Throw a warning if the import fails Raises: ImportError: when `raise_error` is true and `attr_name` cannot be imported from the `module_name` Returns: An attribute from module_name if exists, None otherwise \"\"\" module = cls . import_module ( name = module_name , message = message , raise_error = raise_error , warn = warn ) if not module : return ( None ,) * len ( attrs ) else : _attr_list = list () for _attr_name in attrs : try : attr = getattr ( module , _attr_name ) _attr_list . append ( attr ) except AttributeError as attr_error : if not message : message = f \"cannot import { _attr_name } from { module_name } \" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : _attr_list . append ( None ) return tuple ( _attr_list )","title":"import_from()"},{"location":"package_docs/utils/dependency/#ychaos.utils.dependency.DependencyUtils.import_module","text":"Calling this method with a module name is similar to calling import ... . This can be used to import optional dependencies in the package. Parameters: Name Type Description Default name str Module name required message str Error message to be printed on console when the import fails None raise_error bool Raise an error if the import fails True warn bool Raise warning if the import fails True Exceptions: Type Description ImportError when raise_error is True and the module is not present Returns: Type Description Optional[Any] Optional Module Source code in utils/dependency.py @classmethod def import_module ( cls , name : str , message : str = None , raise_error : bool = True , warn : bool = True ) -> Optional [ Any ]: \"\"\" Calling this method with a module name is similar to calling `import ...`. This can be used to import optional dependencies in the package. Args: name: Module name message: Error message to be printed on console when the import fails raise_error: Raise an error if the import fails warn: Raise warning if the import fails Raises: ImportError: when `raise_error` is True and the module is not present Returns: Optional Module \"\"\" try : module = importlib . import_module ( name ) except ImportError as import_error : if not message : message = f \"Dependency { name } is not installed.\" if warn : warnings . warn ( message ) if raise_error : raise ImportError ( message ) from None else : return None return module","title":"import_module()"},{"location":"package_docs/utils/hooks/","text":"EventHook \u00b6 Source code in utils/hooks.py class EventHook ( object ): @classmethod def CallableType ( cls , * arg_types ): \"\"\" Returns an Alias of Callable that takes in `arg_types` \"\"\" # IGNORE: `Callable' must be used as 'Callable[[arg, ...], result]` # The Argument types are casted to List before passing. return Callable [ list ( arg_types ), None ] __hook_events__ : Dict [ str , Callable [ ... , None ]] = dict () \"\"\" Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The `register_hook()` method checks this list for the hooks that are being registered. \"\"\" def __init__ ( self ): \"\"\" Initializes an event hook object \"\"\" self . hooks : Dict [ str , List [ Callable ]] = collections . defaultdict ( list ) def register_hook ( self , event_name : str , hook : Callable ) -> None : \"\"\" Register a hook to be executed at a certain event `event_name` Args: event_name: Event name hook: A callable Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) self . hooks [ event_name ] . append ( hook ) def execute_hooks ( self , event_name : str , * args ) -> None : \"\"\" Execute all the hooks registered for a particular event Args: event_name: Event name *args: The arguments that should be passed to the hook Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) for hook in self . hooks [ event_name ]: try : if getattr ( hook , \"active\" , True ): hook ( * args ) except Exception as hook_error : # nosec if getattr ( hook , \"raise_error\" , False ): raise hook_error __hook_events__ : Dict [ str , Callable [ ... , NoneType ]] special \u00b6 Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered. CallableType ( * arg_types ) classmethod \u00b6 Returns an Alias of Callable that takes in arg_types Source code in utils/hooks.py @classmethod def CallableType ( cls , * arg_types ): \"\"\" Returns an Alias of Callable that takes in `arg_types` \"\"\" # IGNORE: `Callable' must be used as 'Callable[[arg, ...], result]` # The Argument types are casted to List before passing. return Callable [ list ( arg_types ), None ] __init__ ( self ) special \u00b6 Initializes an event hook object Source code in utils/hooks.py def __init__ ( self ): \"\"\" Initializes an event hook object \"\"\" self . hooks : Dict [ str , List [ Callable ]] = collections . defaultdict ( list ) execute_hooks ( self , event_name , * args ) \u00b6 Execute all the hooks registered for a particular event Parameters: Name Type Description Default event_name str Event name required *args The arguments that should be passed to the hook () Returns: Type Description None None Source code in utils/hooks.py def execute_hooks ( self , event_name : str , * args ) -> None : \"\"\" Execute all the hooks registered for a particular event Args: event_name: Event name *args: The arguments that should be passed to the hook Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) for hook in self . hooks [ event_name ]: try : if getattr ( hook , \"active\" , True ): hook ( * args ) except Exception as hook_error : # nosec if getattr ( hook , \"raise_error\" , False ): raise hook_error register_hook ( self , event_name , hook ) \u00b6 Register a hook to be executed at a certain event event_name Parameters: Name Type Description Default event_name str Event name required hook Callable A callable required Returns: Type Description None None Source code in utils/hooks.py def register_hook ( self , event_name : str , hook : Callable ) -> None : \"\"\" Register a hook to be executed at a certain event `event_name` Args: event_name: Event name hook: A callable Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) self . hooks [ event_name ] . append ( hook )","title":"hooks"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook","text":"Source code in utils/hooks.py class EventHook ( object ): @classmethod def CallableType ( cls , * arg_types ): \"\"\" Returns an Alias of Callable that takes in `arg_types` \"\"\" # IGNORE: `Callable' must be used as 'Callable[[arg, ...], result]` # The Argument types are casted to List before passing. return Callable [ list ( arg_types ), None ] __hook_events__ : Dict [ str , Callable [ ... , None ]] = dict () \"\"\" Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The `register_hook()` method checks this list for the hooks that are being registered. \"\"\" def __init__ ( self ): \"\"\" Initializes an event hook object \"\"\" self . hooks : Dict [ str , List [ Callable ]] = collections . defaultdict ( list ) def register_hook ( self , event_name : str , hook : Callable ) -> None : \"\"\" Register a hook to be executed at a certain event `event_name` Args: event_name: Event name hook: A callable Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) self . hooks [ event_name ] . append ( hook ) def execute_hooks ( self , event_name : str , * args ) -> None : \"\"\" Execute all the hooks registered for a particular event Args: event_name: Event name *args: The arguments that should be passed to the hook Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) for hook in self . hooks [ event_name ]: try : if getattr ( hook , \"active\" , True ): hook ( * args ) except Exception as hook_error : # nosec if getattr ( hook , \"raise_error\" , False ): raise hook_error","title":"EventHook"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook.__hook_events__","text":"Lists the valid hooks (and corresponding valid Callable mapping) that can be registered for this particular object. The register_hook() method checks this list for the hooks that are being registered.","title":"__hook_events__"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook.CallableType","text":"Returns an Alias of Callable that takes in arg_types Source code in utils/hooks.py @classmethod def CallableType ( cls , * arg_types ): \"\"\" Returns an Alias of Callable that takes in `arg_types` \"\"\" # IGNORE: `Callable' must be used as 'Callable[[arg, ...], result]` # The Argument types are casted to List before passing. return Callable [ list ( arg_types ), None ]","title":"CallableType()"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook.__init__","text":"Initializes an event hook object Source code in utils/hooks.py def __init__ ( self ): \"\"\" Initializes an event hook object \"\"\" self . hooks : Dict [ str , List [ Callable ]] = collections . defaultdict ( list )","title":"__init__()"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook.execute_hooks","text":"Execute all the hooks registered for a particular event Parameters: Name Type Description Default event_name str Event name required *args The arguments that should be passed to the hook () Returns: Type Description None None Source code in utils/hooks.py def execute_hooks ( self , event_name : str , * args ) -> None : \"\"\" Execute all the hooks registered for a particular event Args: event_name: Event name *args: The arguments that should be passed to the hook Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) for hook in self . hooks [ event_name ]: try : if getattr ( hook , \"active\" , True ): hook ( * args ) except Exception as hook_error : # nosec if getattr ( hook , \"raise_error\" , False ): raise hook_error","title":"execute_hooks()"},{"location":"package_docs/utils/hooks/#ychaos.utils.hooks.EventHook.register_hook","text":"Register a hook to be executed at a certain event event_name Parameters: Name Type Description Default event_name str Event name required hook Callable A callable required Returns: Type Description None None Source code in utils/hooks.py def register_hook ( self , event_name : str , hook : Callable ) -> None : \"\"\" Register a hook to be executed at a certain event `event_name` Args: event_name: Event name hook: A callable Returns: None \"\"\" if event_name not in self . __hook_events__ : raise InvalidEventHookError ( event_name ) self . hooks [ event_name ] . append ( hook )","title":"register_hook()"},{"location":"testplan/","text":"The test plan is a structured document in JSON/YAML format that represents the configuration for the attack. It consists of various properties starting from verification to the attack that is to be performed. The test plan follows a Schema which is available here . You can also view a human readable documentation of the schema by visiting here Validation \u00b6 Python To validate a JSON/YAML test plan file, use the TestPlanValidator.validate_file() method. The method can take both JSON and YAML files as input and validate whether the file is a valid Test Plan or not. from ychaos.testplan.validator import TestPlanValidator TestPlanValidator . validate_file ( \"/path/to/your/file.json\" ) The above script on successful validation should not raise any exceptions. For an invalid test plan, the above code snippet should raise pydantic's ValidationError. To validate a dictionary, use the TestPlanValidator.validate() method. from ychaos.testplan.validator import TestPlanValidator data = dict () TestPlanValidator . validate ( data ) YChaos CLI To validate a test plan file from the YChaos CLI, use the subcommand validate under testplan . The usage of the subcommand is given below. The CLI takes a list of space separated file/directory paths. If the path given is a valid directory, the CLI recursively finds YAML/JSON files inside the directory and validates each one of them. On successful validation, the CLI exits with a exitcode=0 otherwise, exits with exitcode=1 . $ ychaos testplan validate -h usage: ychaos testplan validate [-h] paths [paths ...] positional arguments: paths Space separated list of file/directory paths to validate optional arguments: -h, --help show this help message and exit Example Run - Valid Test Plans $ ychaos testplan validate tests/resources/testplans/valid/ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos, The resilience testing framework \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos CLI configuration \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Configuration \u2503 Value \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 _command_ \u2502 ychaos \u27a1 testplan \u27a1 validate \u2502 \u2502 config \u2502 prod \u2502 \u2502 paths \u2502 tests/resources/testplans/valid \u2502 \u2502 verbose \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 [18:15:30] Starting app main.py:125 Getting Test plans validate.py:75 Validating Test plans validate.py:86 \u2705 tests/resources/testplans/valid/testplan1.json \u2705 tests/resources/testplans/valid/testplan1.yaml \u2705 tests/resources/testplans/valid/testplan2.yaml Exiting with exitcode=0 main.py:176 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2600 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Example Run - Invalid Test Plans $ ychaos testplan validate \\ tests/resources/testplans/valid/ \\ tests/resources/testplans/valid/testplan4.json \\ tests/resources/testplans/invalid/ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos, The resilience testing framework \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos CLI configuration \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Configuration \u2503 Value \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 _command_ \u2502 ychaos \u27a1 testplan \u27a1 validate \u2502 \u2502 config \u2502 prod \u2502 \u2502 paths \u2502 tests/resources/testplans/valid \u2502 \u2502 \u2502 tests/resources/testplans/valid/testplan4.json \u2502 \u2502 \u2502 tests/resources/testplans/invalid \u2502 \u2502 verbose \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 [18:16:08] Starting app main.py:125 Getting Test plans validate.py:75 Validating Test plans validate.py:86 \u2757 tests/resources/testplans/invalid/testplan1.yaml \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Validation Error \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 1 validation error for TestPlan \u2502 \u2502 verification -> 0 -> type \u2502 \u2502 field required (type=value_error.missing) \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2705 tests/resources/testplans/valid/testplan1.json \u2705 tests/resources/testplans/valid/testplan1.yaml \u2705 tests/resources/testplans/valid/testplan2.yaml \ud83d\udd0d tests/resources/testplans/valid/testplan4.json not found Exiting with exitcode=1 main.py:176 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2600 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Test Plan"},{"location":"testplan/#validation","text":"Python To validate a JSON/YAML test plan file, use the TestPlanValidator.validate_file() method. The method can take both JSON and YAML files as input and validate whether the file is a valid Test Plan or not. from ychaos.testplan.validator import TestPlanValidator TestPlanValidator . validate_file ( \"/path/to/your/file.json\" ) The above script on successful validation should not raise any exceptions. For an invalid test plan, the above code snippet should raise pydantic's ValidationError. To validate a dictionary, use the TestPlanValidator.validate() method. from ychaos.testplan.validator import TestPlanValidator data = dict () TestPlanValidator . validate ( data ) YChaos CLI To validate a test plan file from the YChaos CLI, use the subcommand validate under testplan . The usage of the subcommand is given below. The CLI takes a list of space separated file/directory paths. If the path given is a valid directory, the CLI recursively finds YAML/JSON files inside the directory and validates each one of them. On successful validation, the CLI exits with a exitcode=0 otherwise, exits with exitcode=1 . $ ychaos testplan validate -h usage: ychaos testplan validate [-h] paths [paths ...] positional arguments: paths Space separated list of file/directory paths to validate optional arguments: -h, --help show this help message and exit Example Run - Valid Test Plans $ ychaos testplan validate tests/resources/testplans/valid/ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos, The resilience testing framework \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos CLI configuration \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Configuration \u2503 Value \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 _command_ \u2502 ychaos \u27a1 testplan \u27a1 validate \u2502 \u2502 config \u2502 prod \u2502 \u2502 paths \u2502 tests/resources/testplans/valid \u2502 \u2502 verbose \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 [18:15:30] Starting app main.py:125 Getting Test plans validate.py:75 Validating Test plans validate.py:86 \u2705 tests/resources/testplans/valid/testplan1.json \u2705 tests/resources/testplans/valid/testplan1.yaml \u2705 tests/resources/testplans/valid/testplan2.yaml Exiting with exitcode=0 main.py:176 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2600 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Example Run - Invalid Test Plans $ ychaos testplan validate \\ tests/resources/testplans/valid/ \\ tests/resources/testplans/valid/testplan4.json \\ tests/resources/testplans/invalid/ \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos, The resilience testing framework \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 YChaos CLI configuration \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Configuration \u2503 Value \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 _command_ \u2502 ychaos \u27a1 testplan \u27a1 validate \u2502 \u2502 config \u2502 prod \u2502 \u2502 paths \u2502 tests/resources/testplans/valid \u2502 \u2502 \u2502 tests/resources/testplans/valid/testplan4.json \u2502 \u2502 \u2502 tests/resources/testplans/invalid \u2502 \u2502 verbose \u2502 0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 [18:16:08] Starting app main.py:125 Getting Test plans validate.py:75 Validating Test plans validate.py:86 \u2757 tests/resources/testplans/invalid/testplan1.yaml \u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Validation Error \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e \u2502 1 validation error for TestPlan \u2502 \u2502 verification -> 0 -> type \u2502 \u2502 field required (type=value_error.missing) \u2502 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2705 tests/resources/testplans/valid/testplan1.json \u2705 tests/resources/testplans/valid/testplan1.yaml \u2705 tests/resources/testplans/valid/testplan2.yaml \ud83d\udd0d tests/resources/testplans/valid/testplan4.json not found Exiting with exitcode=1 main.py:176 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2600 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500","title":"Validation"},{"location":"testplan/sample_test_plan/","text":"This section of the document contains some example testplans for you to get started quickly on the project CPU Burn \u00b6 description : Increase CPU utilisation on all the cores for 60 seconds for a target host attack : target_type : machine target_config : blast_radius : 100 ssh_config : user : testUser password : testUserPassword hostnames : - mocktargethost.namespace.cloud report_dir : \"./\" agents : - type : cpu_burn config : start_delay : 10 # Start Burn CPU with 10s delay duration : 60 # Burn CPU for 60s description : Increase CPU utilisation on all the cores for 60 seconds on local machine attack : target_type : self # target_config not needed for this target_type agents : - type : cpu_burn config : duration : 60 # Burn CPU for 60s Disable Ping \u00b6 description : Disable ping response for 60 seconds attack : target_type : machine agents : - type : disable_ping config : duration : 60 start_delay : 0 Block Ports \u00b6 description : Block inbound and outbound connections on port 80 and 8080 for 60 seconds attack : target_type : machine agents : - type : iptables_block config : start_delay : 0 duration : 60 incoming_ports : - 80 - 8080 destination_ports : - 80 - 8080 Block Endpoints \u00b6 description : Block incoming and outgoing connections for the hostnames for 60 seconds attack : target_type : machine agents : - type : iptables_block config : start_delay : 0 duration : 60 incoming_endpoints : - \"203.0.113.0\" - \"https://yahoo.com:443\" outgoing_endpoints : - \"203.0.113.0\" - \"https://yahoo.com:443\" Block DNS Requests \u00b6 description : Block DNS requests for 60 seconds attack : target_type : machine agents : - type : dns_block config : start_delay : 0 duration : 60 Block Traffic \u00b6 description : Block Requests to hostnames for 60 seconds attack : target_type : machine agents : - type : traffic_block config : start_delay : 0 duration : 60 hosts : - \"https://api.screwdriver.cd\" - \"https://api.nationalize.io\" Endpoint Certificate Validation \u00b6 description : Verify endpoint cert expire date attack : target_type : machine agents : - type : server_cert_validation config : expiry_threshold : 7 # check if cert expire date is more that 7days urls : - \"https://www.techcrunch.com\" - \"https://www.aol.com\" For more information on attack agents refer HTTP Request Verification Plugin \u00b6 description : Verify Steady state by checking Request latency is below 100ms verification : - delay_before : 10000 states : - 'STEADY' type : 'http_request' config : latency : 100 urls : - 'https://api.nationalize.io' method : 'GET' params : name : 'india' status_codes : - 200 count : 10 attack : target_type : machine agents : - type : no_op Screwdriver V4 Verification Plugin \u00b6 description : Use Screwdriver job to verify Steady state verification : - delay_before : 10000 states : - 'STEADY' type : 'sdv4' config : sd_api_url : 'https://api.screwdriver.cd' pipeline_id : 123123 # SD pipeline id job_name : 'Run_FT' # SD job name sd_api_token : # Refer Screwdriver Docs type : env id : SD_API_TOKEN attack : target_type : machine agents : - type : no_op For more information on verification plugins refer","title":"Sample Test Plan"},{"location":"testplan/target_spec/","text":"Target Type and Configuration \u00b6 The attack configuration defined in Testplan takes 2 required attributes target_type and target_config that defines the type of target the tool is intended to attack. Each of the target_type defines what are the configuration attributes needed for target_config . In other words, the schema of target_config depends upon the type of target defined. This document provides schema and definition for each of the target types available in the package. Machine ( machine ) \u00b6 Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, target_type should be equal to machine Attributes: Name Type Description blast_radius int The percentage of targets to be attacked. This is a required field ssh_config SSHConfig The SSH Configuration to be used while logging into the hosts. See SSHConfig hostnames List[ychaos.utils.builtins.FQDN] List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns List[str] List of Host patterns with a single number range within the pattern hostfiles List[pydantic.types.FilePath] List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude List[ychaos.utils.builtins.FQDN] List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning Testplan validator will not be able to validate each of the host entries if the targets are provided using hostfiles . The tool will dynamically validate each of the entry while reading the files. Source code in testplan/attack.py class MachineTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, `target_type` should be equal to `machine` Attributes: blast_radius: The percentage of targets to be attacked. **This is a required field** ssh_config: The SSH Configuration to be used while logging into the hosts. See [SSHConfig][ychaos.testplan.attack.SSHConfig] hostnames: List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns: List of Host patterns with a single number range within the pattern hostfiles: List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude: List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning: Testplan validator will not be able to validate each of the host entries if the targets are provided using `hostfiles`. The tool will dynamically validate each of the entry while reading the files. \"\"\" blast_radius : int = Field ( ... , description = \"The percentage of targets to be attacked\" , ge = 0 , le = 100 ) ssh_config : SSHConfig = Field ( default = SSHConfig (), description = \"The configuration used to SSH to the target machines.\" , ) hostnames : List [ FQDN ] = Field ( default = list (), description = \"List of hosts as targets to run the agents on. These should be valid FQDNs.\" , examples = [ [ \"myhost01.yahoo.com\" , \"myhost02.yahoo.com\" , \"mockhost.web.fe.yahoo.com\" ], ], ) hostpatterns : List [ str ] = Field ( default = list (), description = \"List of Host patterns with a single number range within the pattern\" , examples = [ [ \"myhost[12-34].yahoo.com\" , \"hostpattern[00-10].mock.yahoo.com\" ], ], ) hostfiles : List [ FilePath ] = Field ( default = list (), description = ( \"List of files containing hostnames separated by a newline\" \"The path provided can be an absolute path or a relative path from which the tool is invoked.\" \"Note that the testplan will not validate each file during static validation.\" ), examples = [ [ \"/home/awesomeuser/hostlist.txt\" , \"/home/awesomeuser/tmp/inventory.txt\" ] ], ) exclude : List [ FQDN ] = Field ( default = list (), description = ( \"List of hosts to be always excluded out of the attack.\" \"The filtering criteria will always exclude the hosts in this list\" ), ) def iterate_hostfiles ( self ): for file in self . hostfiles : for host in file . read_text () . strip () . splitlines (): yield FQDN ( host ) def iterate_hostpattern ( self ): for v in self . hostpatterns : match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : yield FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): yield FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) def expand_hostpatterns ( self ) -> List [ FQDN ]: expanded_list = list () for hostname in self . iterate_hostpattern (): expanded_list . append ( hostname ) return expanded_list def expand_hostfiles ( self ): expanded_list = list () for host in self . iterate_hostfiles (): expanded_list . append ( host ) return expanded_list def get_effective_hosts ( self ): return list ( set ( self . expand_hostpatterns () + self . expand_hostfiles () + self . hostnames ) . difference ( set ( self . exclude )) ) @validator ( \"hostpatterns\" , pre = True , each_item = True ) def validate_hostpatterns ( cls , v ): match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) return v Self ( self ) \u00b6 Represents the configuration when the target is your local machine . To use this as a target, target_type should be equal to self . You can avoid specifying target_config for this target type. Source code in testplan/attack.py class SelfTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is your local machine . To use this as a target, `target_type` should be equal to `self`. You can avoid specifying `target_config` for this target type. \"\"\" pass","title":"Target Specification"},{"location":"testplan/target_spec/#target-type-and-configuration","text":"The attack configuration defined in Testplan takes 2 required attributes target_type and target_config that defines the type of target the tool is intended to attack. Each of the target_type defines what are the configuration attributes needed for target_config . In other words, the schema of target_config depends upon the type of target defined. This document provides schema and definition for each of the target types available in the package.","title":"Target Type and Configuration"},{"location":"testplan/target_spec/#machine-machine","text":"Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, target_type should be equal to machine Attributes: Name Type Description blast_radius int The percentage of targets to be attacked. This is a required field ssh_config SSHConfig The SSH Configuration to be used while logging into the hosts. See SSHConfig hostnames List[ychaos.utils.builtins.FQDN] List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns List[str] List of Host patterns with a single number range within the pattern hostfiles List[pydantic.types.FilePath] List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude List[ychaos.utils.builtins.FQDN] List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning Testplan validator will not be able to validate each of the host entries if the targets are provided using hostfiles . The tool will dynamically validate each of the entry while reading the files. Source code in testplan/attack.py class MachineTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is a Virtual machine or Baremetal. To use this as a target, `target_type` should be equal to `machine` Attributes: blast_radius: The percentage of targets to be attacked. **This is a required field** ssh_config: The SSH Configuration to be used while logging into the hosts. See [SSHConfig][ychaos.testplan.attack.SSHConfig] hostnames: List of hosts as targets to run the agents on. These should be valid FQDNs. hostpatterns: List of Host patterns with a single number range within the pattern hostfiles: List of files containing hostnames separated by a newline The path provided can be an absolute path or a relative path from which the tool is invoked. exclude: List of hosts to be always excluded out of the attack. The filtering criteria will always exclude the hosts in this list Warning: Testplan validator will not be able to validate each of the host entries if the targets are provided using `hostfiles`. The tool will dynamically validate each of the entry while reading the files. \"\"\" blast_radius : int = Field ( ... , description = \"The percentage of targets to be attacked\" , ge = 0 , le = 100 ) ssh_config : SSHConfig = Field ( default = SSHConfig (), description = \"The configuration used to SSH to the target machines.\" , ) hostnames : List [ FQDN ] = Field ( default = list (), description = \"List of hosts as targets to run the agents on. These should be valid FQDNs.\" , examples = [ [ \"myhost01.yahoo.com\" , \"myhost02.yahoo.com\" , \"mockhost.web.fe.yahoo.com\" ], ], ) hostpatterns : List [ str ] = Field ( default = list (), description = \"List of Host patterns with a single number range within the pattern\" , examples = [ [ \"myhost[12-34].yahoo.com\" , \"hostpattern[00-10].mock.yahoo.com\" ], ], ) hostfiles : List [ FilePath ] = Field ( default = list (), description = ( \"List of files containing hostnames separated by a newline\" \"The path provided can be an absolute path or a relative path from which the tool is invoked.\" \"Note that the testplan will not validate each file during static validation.\" ), examples = [ [ \"/home/awesomeuser/hostlist.txt\" , \"/home/awesomeuser/tmp/inventory.txt\" ] ], ) exclude : List [ FQDN ] = Field ( default = list (), description = ( \"List of hosts to be always excluded out of the attack.\" \"The filtering criteria will always exclude the hosts in this list\" ), ) def iterate_hostfiles ( self ): for file in self . hostfiles : for host in file . read_text () . strip () . splitlines (): yield FQDN ( host ) def iterate_hostpattern ( self ): for v in self . hostpatterns : match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : yield FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): yield FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) def expand_hostpatterns ( self ) -> List [ FQDN ]: expanded_list = list () for hostname in self . iterate_hostpattern (): expanded_list . append ( hostname ) return expanded_list def expand_hostfiles ( self ): expanded_list = list () for host in self . iterate_hostfiles (): expanded_list . append ( host ) return expanded_list def get_effective_hosts ( self ): return list ( set ( self . expand_hostpatterns () + self . expand_hostfiles () + self . hostnames ) . difference ( set ( self . exclude )) ) @validator ( \"hostpatterns\" , pre = True , each_item = True ) def validate_hostpatterns ( cls , v ): match = re . search ( r \"\\[((\\d+)-(\\d+))\\]\" , v ) if match is None : FQDN ( v ) else : range_start = match . group ( 2 ) range_end = match . group ( 3 ) for num in range ( int ( range_start ), int ( range_end ) + 1 ): FQDN ( v [: match . start ()] + str ( num ) . zfill ( len ( range_start )) + v [ match . end () :] ) return v","title":"Machine (machine)"},{"location":"testplan/target_spec/#self-self","text":"Represents the configuration when the target is your local machine . To use this as a target, target_type should be equal to self . You can avoid specifying target_config for this target type. Source code in testplan/attack.py class SelfTargetDefinition ( TargetDefinition ): \"\"\" Represents the configuration when the target is your local machine . To use this as a target, `target_type` should be equal to `self`. You can avoid specifying `target_config` for this target type. \"\"\" pass","title":"Self (self)"},{"location":"verification/","text":"Verification \u00b6 One of the important aspect of Chaos Testing is the ability to verify the system's state before/during/after the attack. The user of the tool should have the ability to verify if the system under experiment is in a steady state before actually performing the attack. YChaos' verifcation component, does just that. It provides the user with various plugins that can be integrated within their YChaos Testplan to verify the system is in a state that it is expected to be in. A simple example of this would be the HTTP Request plugin. The user of YChaos provides a list of HTTP endpoints to be hit with certain status codes and latency with which the user of YChaos can assert the system is in a good state before performing the attack. A sample testplan with HTTP verification plugin integrated is provided below. The configuration of http_request plugin is here . description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - yourawesomeservice1.com:4443/path - yourawesomeservice2.com:4443/path params : key1 : \"value1\" key2 : \"value2\" count : 3 # Number of HTTP calls to be made to these endpoints latency : 1000 # If your services return a valid response with latency>1000ms # the verification fails. attack : target_type : machine agents : - type : no_op When run with CLI, ychaos verify -t testplan.yaml --state steady YChaos makes HTTP calls to these endpoints count times and verifies that the services return a valid response along with verifying that the response time is less than what is mentioned in latency field. YChaos also provides 2 other plugins out of the box namely [SDV4VerificationPlugin]ychaos.testplan.verification.SDv4Verification] and PythonModuleVerificationPlugin YChaos Verification Architecture \u00b6 Following diagram illustrates the code architecture of YChaos' verification component","title":"Home"},{"location":"verification/#verification","text":"One of the important aspect of Chaos Testing is the ability to verify the system's state before/during/after the attack. The user of the tool should have the ability to verify if the system under experiment is in a steady state before actually performing the attack. YChaos' verifcation component, does just that. It provides the user with various plugins that can be integrated within their YChaos Testplan to verify the system is in a state that it is expected to be in. A simple example of this would be the HTTP Request plugin. The user of YChaos provides a list of HTTP endpoints to be hit with certain status codes and latency with which the user of YChaos can assert the system is in a good state before performing the attack. A sample testplan with HTTP verification plugin integrated is provided below. The configuration of http_request plugin is here . description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - yourawesomeservice1.com:4443/path - yourawesomeservice2.com:4443/path params : key1 : \"value1\" key2 : \"value2\" count : 3 # Number of HTTP calls to be made to these endpoints latency : 1000 # If your services return a valid response with latency>1000ms # the verification fails. attack : target_type : machine agents : - type : no_op When run with CLI, ychaos verify -t testplan.yaml --state steady YChaos makes HTTP calls to these endpoints count times and verifies that the services return a valid response along with verifying that the response time is less than what is mentioned in latency field. YChaos also provides 2 other plugins out of the box namely [SDV4VerificationPlugin]ychaos.testplan.verification.SDv4Verification] and PythonModuleVerificationPlugin","title":"Verification"},{"location":"verification/#ychaos-verification-architecture","text":"Following diagram illustrates the code architecture of YChaos' verification component","title":"YChaos Verification Architecture"},{"location":"verification/plugins/http_request/","text":"HTTP Request Verification Plugin \u00b6 The HTTP Request Verification plugin is defined to make request calls to a particular endpoint and verify that the response from the server reaches the controller within an expected latency. This can be used to measure the latency of the server before, during and post the attack to montior the behaviour of your service during the phases of chaos testing. The plugin provides a number of configurations like Auth, Certificate, Headers etc. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. Note YChaos does not log any basic auth credentials/bearer tokens used during configurations. Example Testplans \u00b6 This section provides some example testplans with HTTP request plugins configured. Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path and https://yourawesomeservice2.com:4443/path with a set of query params 3 times and verifies if the latency is within 1000ms description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path - https://yourawesomeservice2.com:4443/path params : key1 : \"value1\" key2 : \"value2\" count : 3 # Number of HTTP calls to be made to these endpoints latency : 1000 # If your services return a valid response with latency>1000ms # the verification fails. attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path with a set of query params 3 times and verifies if the latency is within 1000ms but ignores the validity of the SSL certificate presented by the server. description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 verify : False # Ignores the Validity of SSL certificate presented by the server attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path 3 times with certain basic Auth credentials and verifies if the latency is within 1000ms description : A Demo Testplan verification : - states : - STEADY type : http_request config : # Provide Basic Auth credentials in the form of username, Environment variable basic_auth : - username - type : env id : PASSWORD urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path 3 times and verifies if the latency is within 1000ms and verifies if the status code is either 200(OK)/302(FOUND) description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 status_codes : [ 200 , 302 ] attack : target_type : machine agents : - type : no_op","title":"HTTP Request Plugin"},{"location":"verification/plugins/http_request/#http-request-verification-plugin","text":"The HTTP Request Verification plugin is defined to make request calls to a particular endpoint and verify that the response from the server reaches the controller within an expected latency. This can be used to measure the latency of the server before, during and post the attack to montior the behaviour of your service during the phases of chaos testing. The plugin provides a number of configurations like Auth, Certificate, Headers etc. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. Note YChaos does not log any basic auth credentials/bearer tokens used during configurations.","title":"HTTP Request Verification Plugin"},{"location":"verification/plugins/http_request/#example-testplans","text":"This section provides some example testplans with HTTP request plugins configured. Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path and https://yourawesomeservice2.com:4443/path with a set of query params 3 times and verifies if the latency is within 1000ms description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path - https://yourawesomeservice2.com:4443/path params : key1 : \"value1\" key2 : \"value2\" count : 3 # Number of HTTP calls to be made to these endpoints latency : 1000 # If your services return a valid response with latency>1000ms # the verification fails. attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path with a set of query params 3 times and verifies if the latency is within 1000ms but ignores the validity of the SSL certificate presented by the server. description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 verify : False # Ignores the Validity of SSL certificate presented by the server attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path 3 times with certain basic Auth credentials and verifies if the latency is within 1000ms description : A Demo Testplan verification : - states : - STEADY type : http_request config : # Provide Basic Auth credentials in the form of username, Environment variable basic_auth : - username - type : env id : PASSWORD urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 attack : target_type : machine agents : - type : no_op Testplan with http_request plugin configured that calls https://yourawesomeservice1.com:4443/path 3 times and verifies if the latency is within 1000ms and verifies if the status code is either 200(OK)/302(FOUND) description : A Demo Testplan verification : - states : - STEADY type : http_request config : urls : - https://yourawesomeservice1.com:4443/path count : 3 latency : 1000 status_codes : [ 200 , 302 ] attack : target_type : machine agents : - type : no_op","title":"Example Testplans"},{"location":"verification/plugins/opentsdb/","text":"OpenTSDB Metrics Verification Plugin \u00b6 The Metrics verification plugin allows the users of YChaos to verify the state of the system using OpenTSDB Metrics. If a particular infrastructure is sending the metrics to an OpenTSDB server, then YChaos can be used to request the metrics and compare it with a particular comparison logic to assert if the system is in an expected state To view the configurations available for OpenTSDB Verification plugin, visit the schema definition available here in package documentation. Tip OpenTSDB is a scalable Time Series Database. To know more about OpenTSDB, visit http://opentsdb.net/ Example Testplans \u00b6 A demo testplan description : A Demo Testplan verification : - states : - STEADY type : tsdb config : url : https://tsdb.ychaos.yahoo.com/api/query criteria : # All the Criterion must pass for YChaos to mark the state as expected (Boolean AND) - aggregator : avg conditionals : # Any of the conditional can pass for YChaos to mark this criteria passed (Boolean OR) - comparator : == value : 30.56 # Refer to docs http://opentsdb.net/docs/build/html/api_http/query/index.html query : { \"start\" : 1356998400 , \"end\" : 1356998460 , \"queries\" : [ { \"aggregator\" : \"sum\" , \"metric\" : \"sys.cpu.0\" , \"rate\" : \"true\" , \"tags\" : { \"host\" : \"*\" , \"dc\" : \"lga\" } } ] } attack : target_type : machine agents : - type : no_op","title":"OpenTSDB Metrics Plugin"},{"location":"verification/plugins/opentsdb/#opentsdb-metrics-verification-plugin","text":"The Metrics verification plugin allows the users of YChaos to verify the state of the system using OpenTSDB Metrics. If a particular infrastructure is sending the metrics to an OpenTSDB server, then YChaos can be used to request the metrics and compare it with a particular comparison logic to assert if the system is in an expected state To view the configurations available for OpenTSDB Verification plugin, visit the schema definition available here in package documentation. Tip OpenTSDB is a scalable Time Series Database. To know more about OpenTSDB, visit http://opentsdb.net/","title":"OpenTSDB Metrics Verification Plugin"},{"location":"verification/plugins/opentsdb/#example-testplans","text":"A demo testplan description : A Demo Testplan verification : - states : - STEADY type : tsdb config : url : https://tsdb.ychaos.yahoo.com/api/query criteria : # All the Criterion must pass for YChaos to mark the state as expected (Boolean AND) - aggregator : avg conditionals : # Any of the conditional can pass for YChaos to mark this criteria passed (Boolean OR) - comparator : == value : 30.56 # Refer to docs http://opentsdb.net/docs/build/html/api_http/query/index.html query : { \"start\" : 1356998400 , \"end\" : 1356998460 , \"queries\" : [ { \"aggregator\" : \"sum\" , \"metric\" : \"sys.cpu.0\" , \"rate\" : \"true\" , \"tags\" : { \"host\" : \"*\" , \"dc\" : \"lga\" } } ] } attack : target_type : machine agents : - type : no_op","title":"Example Testplans"},{"location":"verification/plugins/python_module/","text":"Python Module Verification Plugin \u00b6 YChaos allows users to write their own plugins for verification and use it with YChaos infrastructure. You can use the python_module verification plugin for this purpose. You can write your own python file with the program logic of what you want to be verified and configure the testplans in the below fashion. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. description : A Demo Testplan verification : - states : - STEADY - CHAOS type : python_module config : path : /path/to/your/python/file.py executable : /usr/bin/python # You can ignore this to use `sys.executable` arguments : - \"--argument1 value1\" - \"--argument2 value2\" attack : target_type : machine agents : - type : no_op With the above testplan, you can run the verify subcommand of YChaos to run your custom python script with some arguments and YChaos will check for the return value of the script to assert that the system state is as expected. Note Here is a sample YChaos CLI command that can be used with the above testplan ychaos verify -t testplan.yaml --state STEADY","title":"Python Module Plugin"},{"location":"verification/plugins/python_module/#python-module-verification-plugin","text":"YChaos allows users to write their own plugins for verification and use it with YChaos infrastructure. You can use the python_module verification plugin for this purpose. You can write your own python file with the program logic of what you want to be verified and configure the testplans in the below fashion. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. description : A Demo Testplan verification : - states : - STEADY - CHAOS type : python_module config : path : /path/to/your/python/file.py executable : /usr/bin/python # You can ignore this to use `sys.executable` arguments : - \"--argument1 value1\" - \"--argument2 value2\" attack : target_type : machine agents : - type : no_op With the above testplan, you can run the verify subcommand of YChaos to run your custom python script with some arguments and YChaos will check for the return value of the script to assert that the system state is as expected. Note Here is a sample YChaos CLI command that can be used with the above testplan ychaos verify -t testplan.yaml --state STEADY","title":"Python Module Verification Plugin"},{"location":"verification/plugins/sdv4/","text":"Screwdriver Build Verification Plugin \u00b6 Screwdriver is an open source build platform designed for Continuous Delivery by Yahoo. A CI/CD pipeline can be configured with a particular job that will be triggered remotely from YChaos and the status of the build is verified to ensure the system is in expected state. As a user of YChaos, you can configure your own scripts to run inside the Screwdriver build. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. Note To know more about Screwdriver CI/CD visit the official site of Screwdriver Example Testplan \u00b6 This section provides some example testplans with Screwdriver Build configured. description : A Demo Testplan verification : - states : - STEADY - CHAOS type : sdv4 config : pipeline_id : 7419 # Configure a Job `verify_ychaos_state` in Pipeline 1032344 job_name : verify_ychaos_state # For self hosted build cluster, provide your API URL # Eg: https://api.screwdriver.mycompany.com sd_api_url : https://api.cd.screwdriver.cd sd_api_token : type : env id : SD_API_TOKEN attack : target_type : machine agents : - type : no_op","title":"Screwdriver Build Plugin"},{"location":"verification/plugins/sdv4/#screwdriver-build-verification-plugin","text":"Screwdriver is an open source build platform designed for Continuous Delivery by Yahoo. A CI/CD pipeline can be configured with a particular job that will be triggered remotely from YChaos and the status of the build is verified to ensure the system is in expected state. As a user of YChaos, you can configure your own scripts to run inside the Screwdriver build. To view the schema of the configurations available for the plugin, visit Verification Plugin in package documentation. Note To know more about Screwdriver CI/CD visit the official site of Screwdriver","title":"Screwdriver Build Verification Plugin"},{"location":"verification/plugins/sdv4/#example-testplan","text":"This section provides some example testplans with Screwdriver Build configured. description : A Demo Testplan verification : - states : - STEADY - CHAOS type : sdv4 config : pipeline_id : 7419 # Configure a Job `verify_ychaos_state` in Pipeline 1032344 job_name : verify_ychaos_state # For self hosted build cluster, provide your API URL # Eg: https://api.screwdriver.mycompany.com sd_api_url : https://api.cd.screwdriver.cd sd_api_token : type : env id : SD_API_TOKEN attack : target_type : machine agents : - type : no_op","title":"Example Testplan"}]}